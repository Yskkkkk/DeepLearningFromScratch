{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## train_convent.py",
   "id": "b8ca9d56219c460b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-19T10:00:46.649160Z",
     "start_time": "2025-08-19T09:46:01.501582Z"
    }
   },
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 读入数据\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 处理花费时间较长的情况下减少数据\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28),\n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 保存参数\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 绘制图形\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3000520635718886\n",
      "=== epoch:1, train acc:0.22, test acc:0.242 ===\n",
      "train loss:2.2969542135270866\n",
      "train loss:2.293725852157383\n",
      "train loss:2.2864744818291527\n",
      "train loss:2.279362592476977\n",
      "train loss:2.2677316080327445\n",
      "train loss:2.2537077412835513\n",
      "train loss:2.2285476350498823\n",
      "train loss:2.215704813230564\n",
      "train loss:2.193907379806898\n",
      "train loss:2.1486634183882116\n",
      "train loss:2.107316955799155\n",
      "train loss:2.0860921013486164\n",
      "train loss:2.0070134842300886\n",
      "train loss:1.9398554391629483\n",
      "train loss:1.8925770012620198\n",
      "train loss:1.8370809161902302\n",
      "train loss:1.7120945446118592\n",
      "train loss:1.6251536954002601\n",
      "train loss:1.657768063931095\n",
      "train loss:1.4909584692905242\n",
      "train loss:1.4493013218813422\n",
      "train loss:1.262679964783186\n",
      "train loss:1.3102980153817787\n",
      "train loss:1.1723391004730683\n",
      "train loss:1.3397060484469698\n",
      "train loss:1.0255930792494674\n",
      "train loss:0.8181109265151706\n",
      "train loss:0.89285289207723\n",
      "train loss:0.8454450019476628\n",
      "train loss:0.8906714097799808\n",
      "train loss:0.7705274795229562\n",
      "train loss:0.8895810990489472\n",
      "train loss:0.8365118945239837\n",
      "train loss:0.6689122939846023\n",
      "train loss:0.7453874767601364\n",
      "train loss:0.6586480970904712\n",
      "train loss:0.6471837043734854\n",
      "train loss:0.7514582854669435\n",
      "train loss:0.49133119260302466\n",
      "train loss:0.6883222702048709\n",
      "train loss:0.6319002342282929\n",
      "train loss:0.67379198336162\n",
      "train loss:0.7002102056971095\n",
      "train loss:0.7458660750926138\n",
      "train loss:0.5705315601774148\n",
      "train loss:0.5801385735283463\n",
      "train loss:0.6415502378762341\n",
      "train loss:0.45566915639974037\n",
      "train loss:0.4499881546551597\n",
      "train loss:0.5460572510070202\n",
      "train loss:0.5509708297304102\n",
      "train loss:0.49980231786653845\n",
      "train loss:0.5440796545472425\n",
      "train loss:0.4785104999766884\n",
      "train loss:0.7456373187115658\n",
      "train loss:0.4701998441092154\n",
      "train loss:0.448326825064617\n",
      "train loss:0.3979904665297928\n",
      "train loss:0.6470540049726493\n",
      "train loss:0.3928986692073245\n",
      "train loss:0.5063944107746909\n",
      "train loss:0.40268565706578613\n",
      "train loss:0.41080037312113776\n",
      "train loss:0.5985824879049332\n",
      "train loss:0.36753146051045765\n",
      "train loss:0.6395450576950951\n",
      "train loss:0.3874015235533097\n",
      "train loss:0.4170396939199776\n",
      "train loss:0.4637816180647167\n",
      "train loss:0.4204602214525143\n",
      "train loss:0.39652984696112986\n",
      "train loss:0.4113879771560043\n",
      "train loss:0.505695845239919\n",
      "train loss:0.3546769289640532\n",
      "train loss:0.5301466594113993\n",
      "train loss:0.396197969617446\n",
      "train loss:0.4354526470798686\n",
      "train loss:0.41651448007317754\n",
      "train loss:0.5070576738854571\n",
      "train loss:0.3533875240318827\n",
      "train loss:0.4298650851933628\n",
      "train loss:0.3028500144877178\n",
      "train loss:0.4987701386217075\n",
      "train loss:0.43558819170666363\n",
      "train loss:0.42672450398042405\n",
      "train loss:0.3751654119768963\n",
      "train loss:0.5088840176242302\n",
      "train loss:0.3108143086755627\n",
      "train loss:0.31370416397997963\n",
      "train loss:0.501694252751917\n",
      "train loss:0.4681434450911498\n",
      "train loss:0.28954173212537265\n",
      "train loss:0.47023897911000156\n",
      "train loss:0.3672208918317207\n",
      "train loss:0.5265510028836399\n",
      "train loss:0.6010367639054441\n",
      "train loss:0.4613316821430767\n",
      "train loss:0.298163048806426\n",
      "train loss:0.4553346239067564\n",
      "train loss:0.37054365977564674\n",
      "train loss:0.5502186379987949\n",
      "train loss:0.321818645895531\n",
      "train loss:0.38801497077211594\n",
      "train loss:0.4375455751707345\n",
      "train loss:0.3845931166656905\n",
      "train loss:0.5434891221895167\n",
      "train loss:0.31287465434165634\n",
      "train loss:0.3044422954274153\n",
      "train loss:0.282426320895815\n",
      "train loss:0.37990504786057744\n",
      "train loss:0.48346623293298285\n",
      "train loss:0.5739260674065423\n",
      "train loss:0.32914040262164007\n",
      "train loss:0.3261090870472583\n",
      "train loss:0.40213788027637665\n",
      "train loss:0.24698696358197822\n",
      "train loss:0.4483227928758005\n",
      "train loss:0.39134103369834206\n",
      "train loss:0.35049503280349087\n",
      "train loss:0.2996142060431964\n",
      "train loss:0.4865409178133436\n",
      "train loss:0.41763095403337913\n",
      "train loss:0.255301244559843\n",
      "train loss:0.44889738031318016\n",
      "train loss:0.3671699712747411\n",
      "train loss:0.3051499965856885\n",
      "train loss:0.32824624710142336\n",
      "train loss:0.23011514038540765\n",
      "train loss:0.3023902548776721\n",
      "train loss:0.46531587299881205\n",
      "train loss:0.30191285778608856\n",
      "train loss:0.5070712982176133\n",
      "train loss:0.32647591240238377\n",
      "train loss:0.23520869256478774\n",
      "train loss:0.35454929744954056\n",
      "train loss:0.17816091949436616\n",
      "train loss:0.4216033132516263\n",
      "train loss:0.4761994365956968\n",
      "train loss:0.30605886117507475\n",
      "train loss:0.21910241782211387\n",
      "train loss:0.204755264704794\n",
      "train loss:0.39166648365821727\n",
      "train loss:0.26072084397313927\n",
      "train loss:0.43827955586192274\n",
      "train loss:0.6015922336233601\n",
      "train loss:0.40477781993447254\n",
      "train loss:0.1720680877893644\n",
      "train loss:0.30065922274268775\n",
      "train loss:0.41441430595182416\n",
      "train loss:0.240263547359567\n",
      "train loss:0.2940788296994245\n",
      "train loss:0.28167369774863965\n",
      "train loss:0.35289265839523176\n",
      "train loss:0.321357891365707\n",
      "train loss:0.5217960940727039\n",
      "train loss:0.3935982743117952\n",
      "train loss:0.2088555676718036\n",
      "train loss:0.533158417601978\n",
      "train loss:0.34282044365120456\n",
      "train loss:0.24528806585295354\n",
      "train loss:0.35059383375524283\n",
      "train loss:0.34500322594999344\n",
      "train loss:0.3093633472847343\n",
      "train loss:0.23593462315114425\n",
      "train loss:0.3046316274735675\n",
      "train loss:0.19799844933494548\n",
      "train loss:0.3659820771870514\n",
      "train loss:0.23961687988057231\n",
      "train loss:0.2568696925839094\n",
      "train loss:0.2246067412054773\n",
      "train loss:0.4147650095194792\n",
      "train loss:0.32089366824385607\n",
      "train loss:0.18706661650009354\n",
      "train loss:0.22628045469771588\n",
      "train loss:0.25611947038106403\n",
      "train loss:0.2633870011163832\n",
      "train loss:0.3337292382341108\n",
      "train loss:0.2777460730998982\n",
      "train loss:0.20626077121507558\n",
      "train loss:0.2129065208916241\n",
      "train loss:0.2424332234020499\n",
      "train loss:0.3812544205484864\n",
      "train loss:0.38698342707059796\n",
      "train loss:0.14537050895854498\n",
      "train loss:0.27461213618089353\n",
      "train loss:0.2582949453691128\n",
      "train loss:0.28323785902395743\n",
      "train loss:0.23787428786579098\n",
      "train loss:0.26102978551385286\n",
      "train loss:0.1881690955993093\n",
      "train loss:0.18818715376932643\n",
      "train loss:0.2689171856214462\n",
      "train loss:0.17903439641080038\n",
      "train loss:0.5502941065710624\n",
      "train loss:0.2895847526559356\n",
      "train loss:0.30553438864806653\n",
      "train loss:0.3300819420494607\n",
      "train loss:0.23166639421539276\n",
      "train loss:0.3559360810145472\n",
      "train loss:0.19119292502193416\n",
      "train loss:0.4234082761795551\n",
      "train loss:0.2896681660885905\n",
      "train loss:0.21591294675876818\n",
      "train loss:0.27299058550905364\n",
      "train loss:0.2923138545322866\n",
      "train loss:0.23515174930607746\n",
      "train loss:0.3158438230423435\n",
      "train loss:0.19385744371591393\n",
      "train loss:0.5077429886948304\n",
      "train loss:0.2842589256431503\n",
      "train loss:0.2379046088725267\n",
      "train loss:0.2027316479085606\n",
      "train loss:0.4250451625101773\n",
      "train loss:0.488637383282709\n",
      "train loss:0.39124556008986827\n",
      "train loss:0.23659130871830208\n",
      "train loss:0.21820785995632094\n",
      "train loss:0.325863298355475\n",
      "train loss:0.3372388693282317\n",
      "train loss:0.14153556304970302\n",
      "train loss:0.25912323746739646\n",
      "train loss:0.15880428844725394\n",
      "train loss:0.17335484448965313\n",
      "train loss:0.36669542650432274\n",
      "train loss:0.23434535234077877\n",
      "train loss:0.3272633774923458\n",
      "train loss:0.414197509142232\n",
      "train loss:0.3456710761800761\n",
      "train loss:0.3896677254518661\n",
      "train loss:0.38342976237517834\n",
      "train loss:0.3217795944818219\n",
      "train loss:0.40181064982813813\n",
      "train loss:0.3367666253134157\n",
      "train loss:0.3591783014542492\n",
      "train loss:0.28494366042665137\n",
      "train loss:0.34408660325764856\n",
      "train loss:0.23185129557030124\n",
      "train loss:0.35385964274696013\n",
      "train loss:0.20964658762744745\n",
      "train loss:0.2481840032861397\n",
      "train loss:0.3749255914137208\n",
      "train loss:0.2816342938558523\n",
      "train loss:0.21902373856094037\n",
      "train loss:0.2277721336425427\n",
      "train loss:0.23106948228205135\n",
      "train loss:0.15852828104706063\n",
      "train loss:0.2112550062552265\n",
      "train loss:0.22775422207967455\n",
      "train loss:0.222618768161978\n",
      "train loss:0.26544874547320224\n",
      "train loss:0.3036621459095468\n",
      "train loss:0.21160885399591264\n",
      "train loss:0.27691443730883025\n",
      "train loss:0.21046194303990318\n",
      "train loss:0.2639539818868468\n",
      "train loss:0.3148490151708111\n",
      "train loss:0.32009932750304915\n",
      "train loss:0.2356167673470676\n",
      "train loss:0.2369838318267181\n",
      "train loss:0.35123878847380907\n",
      "train loss:0.3898480237527206\n",
      "train loss:0.20847077375529374\n",
      "train loss:0.36385123010549186\n",
      "train loss:0.18200021509628644\n",
      "train loss:0.2717565741033862\n",
      "train loss:0.2893050609055028\n",
      "train loss:0.33680344102435344\n",
      "train loss:0.22748283309414025\n",
      "train loss:0.2235976728986575\n",
      "train loss:0.36834564807488085\n",
      "train loss:0.30835703339290954\n",
      "train loss:0.23645137758130422\n",
      "train loss:0.4801921990217279\n",
      "train loss:0.20648520569202394\n",
      "train loss:0.15998426848913241\n",
      "train loss:0.20754515585521296\n",
      "train loss:0.2415540212910991\n",
      "train loss:0.29269048033380385\n",
      "train loss:0.31013499364401526\n",
      "train loss:0.35974302511984185\n",
      "train loss:0.17069469821139768\n",
      "train loss:0.1665211959461031\n",
      "train loss:0.15870437485196803\n",
      "train loss:0.15657327936638363\n",
      "train loss:0.18159744523091856\n",
      "train loss:0.15815360561227862\n",
      "train loss:0.35906638724584555\n",
      "train loss:0.36915749231989603\n",
      "train loss:0.3360627518050675\n",
      "train loss:0.24712433067337491\n",
      "train loss:0.1849005517342911\n",
      "train loss:0.22671713920298756\n",
      "train loss:0.2726092134516672\n",
      "train loss:0.187296230251455\n",
      "train loss:0.19349755909398436\n",
      "train loss:0.23553681988213998\n",
      "train loss:0.2676389433496984\n",
      "train loss:0.25075662814237204\n",
      "train loss:0.24825908211086264\n",
      "train loss:0.15977191201297125\n",
      "train loss:0.21530602490014628\n",
      "train loss:0.17820866869240423\n",
      "train loss:0.277506940288546\n",
      "train loss:0.36407357089693443\n",
      "train loss:0.21496939511575128\n",
      "train loss:0.2342872890638228\n",
      "train loss:0.2454025695497658\n",
      "train loss:0.18907700119892276\n",
      "train loss:0.14746843278265276\n",
      "train loss:0.27188998508401824\n",
      "train loss:0.2269558499688406\n",
      "train loss:0.196459199660087\n",
      "train loss:0.17202852975734198\n",
      "train loss:0.14202573957128825\n",
      "train loss:0.278202770381738\n",
      "train loss:0.19951127655765344\n",
      "train loss:0.21128065134560622\n",
      "train loss:0.18954091756017669\n",
      "train loss:0.16223477659105717\n",
      "train loss:0.2168452816862269\n",
      "train loss:0.20352019408613276\n",
      "train loss:0.11264457017775234\n",
      "train loss:0.14838153715434857\n",
      "train loss:0.13502975403433332\n",
      "train loss:0.3278837215307409\n",
      "train loss:0.21634769455989405\n",
      "train loss:0.11842875344295\n",
      "train loss:0.2424193859818581\n",
      "train loss:0.14832633914603094\n",
      "train loss:0.26189948937488844\n",
      "train loss:0.16123672038416711\n",
      "train loss:0.18723269037403728\n",
      "train loss:0.1520517084492212\n",
      "train loss:0.19965968357369973\n",
      "train loss:0.283529615705218\n",
      "train loss:0.12564237756986021\n",
      "train loss:0.13851429144169491\n",
      "train loss:0.17126894438293835\n",
      "train loss:0.2278830811727182\n",
      "train loss:0.13814785375946553\n",
      "train loss:0.1180459260225133\n",
      "train loss:0.164597327336913\n",
      "train loss:0.26624309253591155\n",
      "train loss:0.30993935433712105\n",
      "train loss:0.21035620112036107\n",
      "train loss:0.15777381430284768\n",
      "train loss:0.1942943666679504\n",
      "train loss:0.14389013544322257\n",
      "train loss:0.17623164370767438\n",
      "train loss:0.25131587994758187\n",
      "train loss:0.3079455751583543\n",
      "train loss:0.1929614069350524\n",
      "train loss:0.16742046568588426\n",
      "train loss:0.1698638713306847\n",
      "train loss:0.22926862941489945\n",
      "train loss:0.1739780231999461\n",
      "train loss:0.13868796966789018\n",
      "train loss:0.2639297773544088\n",
      "train loss:0.2491964362147826\n",
      "train loss:0.28824491725051826\n",
      "train loss:0.1921905289942465\n",
      "train loss:0.16945027176426064\n",
      "train loss:0.13765502051880701\n",
      "train loss:0.12785475282002395\n",
      "train loss:0.16857648930240923\n",
      "train loss:0.26049598113648725\n",
      "train loss:0.14105282421850704\n",
      "train loss:0.20439018842527457\n",
      "train loss:0.25363166571256146\n",
      "train loss:0.18374564691549708\n",
      "train loss:0.2051031449903335\n",
      "train loss:0.2566135557652214\n",
      "train loss:0.1424016264101073\n",
      "train loss:0.1284269056276149\n",
      "train loss:0.08746017102071381\n",
      "train loss:0.193560098792929\n",
      "train loss:0.11219422309935626\n",
      "train loss:0.07822177665686104\n",
      "train loss:0.17582787336410216\n",
      "train loss:0.20031815498141786\n",
      "train loss:0.19217380061381065\n",
      "train loss:0.399186221268736\n",
      "train loss:0.11259027128203679\n",
      "train loss:0.19835756735157697\n",
      "train loss:0.2473002491504303\n",
      "train loss:0.24508820721572577\n",
      "train loss:0.18731985854630603\n",
      "train loss:0.3799813798492269\n",
      "train loss:0.15478044644623215\n",
      "train loss:0.22028194414468022\n",
      "train loss:0.23106017087346417\n",
      "train loss:0.17713102976098016\n",
      "train loss:0.19739137989428443\n",
      "train loss:0.08789488557856547\n",
      "train loss:0.12039650996603733\n",
      "train loss:0.21048279710394666\n",
      "train loss:0.3168640206560393\n",
      "train loss:0.22536615214434763\n",
      "train loss:0.28420276930719707\n",
      "train loss:0.25731408299909014\n",
      "train loss:0.17357076901587232\n",
      "train loss:0.1536828532194618\n",
      "train loss:0.23615454134590852\n",
      "train loss:0.20636271749348228\n",
      "train loss:0.17825744301256122\n",
      "train loss:0.19859964803938024\n",
      "train loss:0.2503457839288713\n",
      "train loss:0.05341829085558111\n",
      "train loss:0.19785975627049995\n",
      "train loss:0.15309804596188867\n",
      "train loss:0.1621793209580925\n",
      "train loss:0.19027806832713318\n",
      "train loss:0.10351314681855327\n",
      "train loss:0.11549874632867936\n",
      "train loss:0.1778104738022038\n",
      "train loss:0.20526908425946305\n",
      "train loss:0.23737078059308556\n",
      "train loss:0.3048084271130302\n",
      "train loss:0.167400379940635\n",
      "train loss:0.1830039297818458\n",
      "train loss:0.18645480944077406\n",
      "train loss:0.12386672694582111\n",
      "train loss:0.0991574906675832\n",
      "train loss:0.26504860814739434\n",
      "train loss:0.11606448470823266\n",
      "train loss:0.15665302225184496\n",
      "train loss:0.12677626001399292\n",
      "train loss:0.24650036977647904\n",
      "train loss:0.08472195296972475\n",
      "train loss:0.15985152151577794\n",
      "train loss:0.18855565558202206\n",
      "train loss:0.10673830046340324\n",
      "train loss:0.14851251170697097\n",
      "train loss:0.19666978046937234\n",
      "train loss:0.10816057436433918\n",
      "train loss:0.05789950176938052\n",
      "train loss:0.125236344148606\n",
      "train loss:0.18082109110913763\n",
      "train loss:0.2464276141831596\n",
      "train loss:0.18525628806806313\n",
      "train loss:0.2422937499660848\n",
      "train loss:0.1934334682570972\n",
      "train loss:0.2253090350476744\n",
      "train loss:0.12778282586221093\n",
      "train loss:0.24123895211735819\n",
      "train loss:0.22274457789418442\n",
      "train loss:0.14170561024294467\n",
      "train loss:0.1596800947299757\n",
      "train loss:0.1745347938713416\n",
      "train loss:0.2325984170384361\n",
      "train loss:0.18305901299370192\n",
      "train loss:0.12105263844643738\n",
      "train loss:0.10284491802263986\n",
      "train loss:0.15468015070782695\n",
      "train loss:0.25202457275505397\n",
      "train loss:0.15153813143360928\n",
      "train loss:0.08913977664959985\n",
      "train loss:0.19949618229313756\n",
      "train loss:0.20015002514670116\n",
      "train loss:0.08458212484434043\n",
      "train loss:0.23732055209935335\n",
      "train loss:0.09009964269241204\n",
      "train loss:0.16339171990003767\n",
      "train loss:0.09331458282508559\n",
      "train loss:0.15346422194319084\n",
      "train loss:0.13004073060866364\n",
      "train loss:0.1481456924493244\n",
      "train loss:0.20892913772518024\n",
      "train loss:0.17362990777362192\n",
      "train loss:0.1637525893728628\n",
      "train loss:0.11251434199007884\n",
      "train loss:0.08690566233390302\n",
      "train loss:0.17364981475412533\n",
      "train loss:0.21853863624734365\n",
      "train loss:0.14246562038738675\n",
      "train loss:0.1607433653469684\n",
      "train loss:0.17055271655438226\n",
      "train loss:0.07103387444628863\n",
      "train loss:0.18141804760160352\n",
      "train loss:0.15496657955187365\n",
      "train loss:0.20641074832654563\n",
      "train loss:0.17883014405973577\n",
      "train loss:0.16188105772454756\n",
      "train loss:0.10667229972833345\n",
      "train loss:0.23144311680549534\n",
      "train loss:0.10958558453121967\n",
      "train loss:0.11047453899536741\n",
      "train loss:0.09686158052758734\n",
      "train loss:0.12075542578730179\n",
      "train loss:0.13809033976207957\n",
      "train loss:0.13603748313696137\n",
      "train loss:0.0468709154666894\n",
      "train loss:0.1454333634632799\n",
      "train loss:0.17569029138838194\n",
      "train loss:0.10125144732107838\n",
      "train loss:0.15282974674921923\n",
      "train loss:0.123915145443918\n",
      "train loss:0.10841308143150567\n",
      "train loss:0.13666861795005836\n",
      "train loss:0.16244789286568329\n",
      "train loss:0.16718224774570462\n",
      "train loss:0.197235250611158\n",
      "train loss:0.10333777468339159\n",
      "train loss:0.13202940172309008\n",
      "train loss:0.12761442570633916\n",
      "train loss:0.17265563412546833\n",
      "train loss:0.1466257885536088\n",
      "train loss:0.12589095811652082\n",
      "train loss:0.09991660851489258\n",
      "train loss:0.08776225103655234\n",
      "train loss:0.1874163129128625\n",
      "train loss:0.10210934692932051\n",
      "train loss:0.13269906336227041\n",
      "train loss:0.07638296360744853\n",
      "train loss:0.08058048390805007\n",
      "train loss:0.20216562430104923\n",
      "train loss:0.15383098579756962\n",
      "train loss:0.12560078207161382\n",
      "train loss:0.12684648162466064\n",
      "train loss:0.10242655808800721\n",
      "train loss:0.0920435887730335\n",
      "train loss:0.06735837258533867\n",
      "train loss:0.21255351920926302\n",
      "train loss:0.11923336013277559\n",
      "train loss:0.12307970676743579\n",
      "train loss:0.16677993947853342\n",
      "train loss:0.18983244251027764\n",
      "train loss:0.1274660896671988\n",
      "train loss:0.11862067940683152\n",
      "train loss:0.2377456881850042\n",
      "train loss:0.22942430180727158\n",
      "train loss:0.21104114412266387\n",
      "train loss:0.17014531559860901\n",
      "train loss:0.1379268400002991\n",
      "train loss:0.15086469735371996\n",
      "train loss:0.09436009114205046\n",
      "train loss:0.13472077835452353\n",
      "train loss:0.17091587568737465\n",
      "train loss:0.0963111470688813\n",
      "train loss:0.10661722083834045\n",
      "train loss:0.12394649644821262\n",
      "train loss:0.15761473391612096\n",
      "train loss:0.0926391672631151\n",
      "train loss:0.13575354072093007\n",
      "train loss:0.06712843260706368\n",
      "train loss:0.20736654026408152\n",
      "train loss:0.0473612865508061\n",
      "train loss:0.1231396327063292\n",
      "train loss:0.03343019391892475\n",
      "train loss:0.14609622801399957\n",
      "train loss:0.13492113026556052\n",
      "train loss:0.05950499304896139\n",
      "train loss:0.2199013142845443\n",
      "train loss:0.1591185239942068\n",
      "train loss:0.14051035293785846\n",
      "train loss:0.11504177438604123\n",
      "train loss:0.17794585155144677\n",
      "train loss:0.06616742559460245\n",
      "train loss:0.17031353455144416\n",
      "train loss:0.12577878841351034\n",
      "train loss:0.16184010258164958\n",
      "train loss:0.1560887573734839\n",
      "train loss:0.18186913925901482\n",
      "train loss:0.0867571637434326\n",
      "train loss:0.08518808516150607\n",
      "train loss:0.31334190785080873\n",
      "train loss:0.0642757797658431\n",
      "train loss:0.24111366521584088\n",
      "train loss:0.13120711958622017\n",
      "train loss:0.12629508380905582\n",
      "train loss:0.11267920264411826\n",
      "train loss:0.330948945649975\n",
      "train loss:0.10376226269482394\n",
      "train loss:0.10467921050736527\n",
      "train loss:0.1968513604129043\n",
      "train loss:0.15121486715733723\n",
      "train loss:0.12337498342276232\n",
      "train loss:0.22497556623577417\n",
      "train loss:0.08135225780632743\n",
      "train loss:0.15516544714591832\n",
      "train loss:0.10908725991633025\n",
      "train loss:0.0676634190712229\n",
      "train loss:0.15490327959483752\n",
      "train loss:0.1111400335900097\n",
      "train loss:0.15451021840873527\n",
      "train loss:0.09036449336321929\n",
      "train loss:0.10095079374565227\n",
      "train loss:0.1393134247974881\n",
      "train loss:0.11564953138912559\n",
      "train loss:0.09292644996974954\n",
      "train loss:0.12763414100070464\n",
      "train loss:0.11470541040943973\n",
      "train loss:0.23075465599607992\n",
      "train loss:0.08293057484296128\n",
      "train loss:0.0888810830426796\n",
      "train loss:0.19454291556865866\n",
      "train loss:0.05845310704422577\n",
      "train loss:0.2021912692989099\n",
      "train loss:0.0954378087522284\n",
      "train loss:0.09546078571596549\n",
      "=== epoch:2, train acc:0.962, test acc:0.954 ===\n",
      "train loss:0.13363364906190583\n",
      "train loss:0.12346056917463598\n",
      "train loss:0.11303927015305382\n",
      "train loss:0.09761958899359295\n",
      "train loss:0.0872438883665998\n",
      "train loss:0.09024040260300291\n",
      "train loss:0.11293340177573442\n",
      "train loss:0.08877284487499443\n",
      "train loss:0.18253614086628558\n",
      "train loss:0.12588082766789166\n",
      "train loss:0.08983952502811032\n",
      "train loss:0.19766567527097856\n",
      "train loss:0.09697364209994656\n",
      "train loss:0.1571249074150069\n",
      "train loss:0.1597747290352477\n",
      "train loss:0.10560270305788624\n",
      "train loss:0.216713826047407\n",
      "train loss:0.17130797206341544\n",
      "train loss:0.13814325503101155\n",
      "train loss:0.12072486696743216\n",
      "train loss:0.22332955580236036\n",
      "train loss:0.13125520145686956\n",
      "train loss:0.11906319559057696\n",
      "train loss:0.10681047773832705\n",
      "train loss:0.13602130205045707\n",
      "train loss:0.13332254537120192\n",
      "train loss:0.08362677160169531\n",
      "train loss:0.16043613329559037\n",
      "train loss:0.12989876735205122\n",
      "train loss:0.18260317622242642\n",
      "train loss:0.2257942061611891\n",
      "train loss:0.1553589603704369\n",
      "train loss:0.1391361942300618\n",
      "train loss:0.11130037126330049\n",
      "train loss:0.0810594417289846\n",
      "train loss:0.11131675867472181\n",
      "train loss:0.043205031474378666\n",
      "train loss:0.100123224096087\n",
      "train loss:0.06640529035787082\n",
      "train loss:0.11440321977136181\n",
      "train loss:0.24813280137977226\n",
      "train loss:0.18436755547929676\n",
      "train loss:0.17131351443025283\n",
      "train loss:0.06369034216850503\n",
      "train loss:0.263015861460376\n",
      "train loss:0.1560692739555657\n",
      "train loss:0.10471703250559569\n",
      "train loss:0.1086236111626737\n",
      "train loss:0.09139498750183568\n",
      "train loss:0.11289758057765993\n",
      "train loss:0.17794350283780083\n",
      "train loss:0.09365621115129581\n",
      "train loss:0.050172809433063244\n",
      "train loss:0.10481104399237112\n",
      "train loss:0.09301342786605181\n",
      "train loss:0.0836218974774015\n",
      "train loss:0.07900047734619359\n",
      "train loss:0.055445230123334514\n",
      "train loss:0.07670669168969853\n",
      "train loss:0.09531445283938471\n",
      "train loss:0.06215017504917038\n",
      "train loss:0.07428328186145933\n",
      "train loss:0.19035334552887953\n",
      "train loss:0.12898205200660418\n",
      "train loss:0.1275209602638106\n",
      "train loss:0.07178748476138046\n",
      "train loss:0.12036254208826731\n",
      "train loss:0.08593145847749963\n",
      "train loss:0.15679547383558393\n",
      "train loss:0.15159393932323512\n",
      "train loss:0.17592622273010972\n",
      "train loss:0.0992219977315449\n",
      "train loss:0.08939066851866016\n",
      "train loss:0.11081680027372197\n",
      "train loss:0.06448137111852678\n",
      "train loss:0.11863803326371584\n",
      "train loss:0.13139659079369992\n",
      "train loss:0.10664718013001043\n",
      "train loss:0.0769893087731408\n",
      "train loss:0.15840141402540917\n",
      "train loss:0.17221655928205892\n",
      "train loss:0.15567696022565444\n",
      "train loss:0.08585696923770955\n",
      "train loss:0.0422964729036586\n",
      "train loss:0.14897750074312388\n",
      "train loss:0.06214144865906524\n",
      "train loss:0.23186325159335866\n",
      "train loss:0.10510394168544987\n",
      "train loss:0.13079977093646933\n",
      "train loss:0.13452403245034603\n",
      "train loss:0.0900348905085297\n",
      "train loss:0.1216664301325409\n",
      "train loss:0.12935040892236255\n",
      "train loss:0.06352549543160423\n",
      "train loss:0.07213921223298027\n",
      "train loss:0.1402022900931707\n",
      "train loss:0.18490525162460839\n",
      "train loss:0.08261018547671135\n",
      "train loss:0.08198253245492787\n",
      "train loss:0.0883975498526948\n",
      "train loss:0.12399348434676968\n",
      "train loss:0.12334559749329425\n",
      "train loss:0.09524927124781567\n",
      "train loss:0.05667171897342305\n",
      "train loss:0.22135398310483625\n",
      "train loss:0.14600570503478422\n",
      "train loss:0.09188152453543781\n",
      "train loss:0.09044647550374134\n",
      "train loss:0.0786484810701143\n",
      "train loss:0.18618150178997975\n",
      "train loss:0.125964006650528\n",
      "train loss:0.07210482116583035\n",
      "train loss:0.08015039618784799\n",
      "train loss:0.044310521683051614\n",
      "train loss:0.09407987278550951\n",
      "train loss:0.23457564220258842\n",
      "train loss:0.0976435227351675\n",
      "train loss:0.0687654269235038\n",
      "train loss:0.09367251782950645\n",
      "train loss:0.19276180961161365\n",
      "train loss:0.11357520604588131\n",
      "train loss:0.07171932832747481\n",
      "train loss:0.07589268813686982\n",
      "train loss:0.092774695134729\n",
      "train loss:0.14089758925985524\n",
      "train loss:0.07709585572644509\n",
      "train loss:0.15520171445790043\n",
      "train loss:0.1204105227596245\n",
      "train loss:0.0884936172428713\n",
      "train loss:0.06818509751491862\n",
      "train loss:0.04271892385755532\n",
      "train loss:0.07621592443656881\n",
      "train loss:0.15429134860578983\n",
      "train loss:0.10715345793891733\n",
      "train loss:0.1547941433000164\n",
      "train loss:0.09222925013762433\n",
      "train loss:0.1073625920840077\n",
      "train loss:0.13868040342223897\n",
      "train loss:0.06097617906408561\n",
      "train loss:0.12673068474605437\n",
      "train loss:0.12939336865409473\n",
      "train loss:0.06356857480744821\n",
      "train loss:0.04160744291164106\n",
      "train loss:0.08533824481905178\n",
      "train loss:0.08687079696526208\n",
      "train loss:0.058876629546400744\n",
      "train loss:0.25181714783958464\n",
      "train loss:0.10076012717908721\n",
      "train loss:0.03723947104640086\n",
      "train loss:0.18414046833731032\n",
      "train loss:0.15531140317877803\n",
      "train loss:0.08703169681027836\n",
      "train loss:0.07284694099955323\n",
      "train loss:0.15125478881152568\n",
      "train loss:0.12472320181383155\n",
      "train loss:0.1238937935720275\n",
      "train loss:0.1389964657211998\n",
      "train loss:0.1227939900791371\n",
      "train loss:0.07693362258217668\n",
      "train loss:0.042225945735521346\n",
      "train loss:0.05794092476501895\n",
      "train loss:0.10718750132173616\n",
      "train loss:0.11261487758498312\n",
      "train loss:0.20624345980200975\n",
      "train loss:0.14973352615323965\n",
      "train loss:0.10394677787703081\n",
      "train loss:0.0896960043691484\n",
      "train loss:0.09982337653317713\n",
      "train loss:0.09296020099204055\n",
      "train loss:0.17641999549416837\n",
      "train loss:0.14721829116785737\n",
      "train loss:0.10284175058485323\n",
      "train loss:0.07636228053584265\n",
      "train loss:0.06783982468012419\n",
      "train loss:0.054620083422275166\n",
      "train loss:0.1354653114258157\n",
      "train loss:0.06333132264343452\n",
      "train loss:0.09906730240402858\n",
      "train loss:0.06091774135329972\n",
      "train loss:0.15720903101905637\n",
      "train loss:0.1080179269082832\n",
      "train loss:0.0582614510988146\n",
      "train loss:0.08472508735267743\n",
      "train loss:0.05712777845990395\n",
      "train loss:0.11726953822356555\n",
      "train loss:0.10423882017978467\n",
      "train loss:0.10446337901828512\n",
      "train loss:0.07242111601674642\n",
      "train loss:0.11513510956398992\n",
      "train loss:0.04680396766835779\n",
      "train loss:0.114412050906099\n",
      "train loss:0.16726685888036996\n",
      "train loss:0.10691310619592366\n",
      "train loss:0.10358188358670976\n",
      "train loss:0.1774362150511312\n",
      "train loss:0.199248492406719\n",
      "train loss:0.13623389586405943\n",
      "train loss:0.13330503778637814\n",
      "train loss:0.02572901037704645\n",
      "train loss:0.07920813654955533\n",
      "train loss:0.0785176540083849\n",
      "train loss:0.33876595762508654\n",
      "train loss:0.10468562545662012\n",
      "train loss:0.18390392031231656\n",
      "train loss:0.16718483476146415\n",
      "train loss:0.05438878118927699\n",
      "train loss:0.11152914604067654\n",
      "train loss:0.13573077388806212\n",
      "train loss:0.03529694054508573\n",
      "train loss:0.18487391716228296\n",
      "train loss:0.08186790058169438\n",
      "train loss:0.10694762308932929\n",
      "train loss:0.16843497029666324\n",
      "train loss:0.10106395152250759\n",
      "train loss:0.11974603472508444\n",
      "train loss:0.08827925699186108\n",
      "train loss:0.10932021757539408\n",
      "train loss:0.11315618330963256\n",
      "train loss:0.08302596725692883\n",
      "train loss:0.14721030914586516\n",
      "train loss:0.18338689526687382\n",
      "train loss:0.09386459100301627\n",
      "train loss:0.06609205011277813\n",
      "train loss:0.06743800769359586\n",
      "train loss:0.04222622509817423\n",
      "train loss:0.09975868799122313\n",
      "train loss:0.05434286804420659\n",
      "train loss:0.02654590838392696\n",
      "train loss:0.09805003864114228\n",
      "train loss:0.18676272328327717\n",
      "train loss:0.10901207450608467\n",
      "train loss:0.09387949147391086\n",
      "train loss:0.09708335126298558\n",
      "train loss:0.056035485712386174\n",
      "train loss:0.04438879996956322\n",
      "train loss:0.09248964878238536\n",
      "train loss:0.13128465224304486\n",
      "train loss:0.10476346224066146\n",
      "train loss:0.06511305541262494\n",
      "train loss:0.12620273893535225\n",
      "train loss:0.0666068983302948\n",
      "train loss:0.055068039891180184\n",
      "train loss:0.09674149213085342\n",
      "train loss:0.02996358030688226\n",
      "train loss:0.053491709558380764\n",
      "train loss:0.11386449568156345\n",
      "train loss:0.09558761812757359\n",
      "train loss:0.08849937844382229\n",
      "train loss:0.03489578949142708\n",
      "train loss:0.06764128614421694\n",
      "train loss:0.11317367004934432\n",
      "train loss:0.08099737323761422\n",
      "train loss:0.16876135036386708\n",
      "train loss:0.06416956695807889\n",
      "train loss:0.1258550674908324\n",
      "train loss:0.05892393923321669\n",
      "train loss:0.08858695591213085\n",
      "train loss:0.06079855617013383\n",
      "train loss:0.10514469481759439\n",
      "train loss:0.07133930384150138\n",
      "train loss:0.06139454980241935\n",
      "train loss:0.08811298824739523\n",
      "train loss:0.05911900785986256\n",
      "train loss:0.09475099479375154\n",
      "train loss:0.08754596291297384\n",
      "train loss:0.05944288131226602\n",
      "train loss:0.05701315339421473\n",
      "train loss:0.08755487064936864\n",
      "train loss:0.07774505244879869\n",
      "train loss:0.16298980170371383\n",
      "train loss:0.14117781515508768\n",
      "train loss:0.07014288116251191\n",
      "train loss:0.10481325090590406\n",
      "train loss:0.10422727278357126\n",
      "train loss:0.17629610134257015\n",
      "train loss:0.052677366448374556\n",
      "train loss:0.09361772790782874\n",
      "train loss:0.07129503923607097\n",
      "train loss:0.06927885422990976\n",
      "train loss:0.12030736131986167\n",
      "train loss:0.028998633347657055\n",
      "train loss:0.10101996959514839\n",
      "train loss:0.06246409849188224\n",
      "train loss:0.16458396697343186\n",
      "train loss:0.07299260023033323\n",
      "train loss:0.02547080394803092\n",
      "train loss:0.03954201103678274\n",
      "train loss:0.09969147176631359\n",
      "train loss:0.09577059772598774\n",
      "train loss:0.07975269082872087\n",
      "train loss:0.04779709619611925\n",
      "train loss:0.08584657552654046\n",
      "train loss:0.04485384142620877\n",
      "train loss:0.07819279240833246\n",
      "train loss:0.12833231426956493\n",
      "train loss:0.03943710044655538\n",
      "train loss:0.0777043436520083\n",
      "train loss:0.16924406023259336\n",
      "train loss:0.07859524612154392\n",
      "train loss:0.11829287576198971\n",
      "train loss:0.0385600826164293\n",
      "train loss:0.07114688390821731\n",
      "train loss:0.07191635026900811\n",
      "train loss:0.05796425215791313\n",
      "train loss:0.08983068405659166\n",
      "train loss:0.0990997825319565\n",
      "train loss:0.06214030084829789\n",
      "train loss:0.18510546920642007\n",
      "train loss:0.08021011499095416\n",
      "train loss:0.05432108224832822\n",
      "train loss:0.10881054011887327\n",
      "train loss:0.15569519955936242\n",
      "train loss:0.06201136792077646\n",
      "train loss:0.10975249035395901\n",
      "train loss:0.06602174928469978\n",
      "train loss:0.12187829986038647\n",
      "train loss:0.02467608629874773\n",
      "train loss:0.02783566399606804\n",
      "train loss:0.040103999290532134\n",
      "train loss:0.0836856810224705\n",
      "train loss:0.14591885057358453\n",
      "train loss:0.12227712607829268\n",
      "train loss:0.10052664043023243\n",
      "train loss:0.09334384654277604\n",
      "train loss:0.030407145259052037\n",
      "train loss:0.10682636068049467\n",
      "train loss:0.15213205356647552\n",
      "train loss:0.17954479447802307\n",
      "train loss:0.07749896360360091\n",
      "train loss:0.0841854710725659\n",
      "train loss:0.06048616931189712\n",
      "train loss:0.0913064362172146\n",
      "train loss:0.07083654203615712\n",
      "train loss:0.06726411949647321\n",
      "train loss:0.03184867268461093\n",
      "train loss:0.07463477730276816\n",
      "train loss:0.07700688417779591\n",
      "train loss:0.039386197805563544\n",
      "train loss:0.15782997608932559\n",
      "train loss:0.12956447843327024\n",
      "train loss:0.21872771051996004\n",
      "train loss:0.08420057564200363\n",
      "train loss:0.08247268012111579\n",
      "train loss:0.08930465748406155\n",
      "train loss:0.13120602958965746\n",
      "train loss:0.05642512923046012\n",
      "train loss:0.03307475439547562\n",
      "train loss:0.055885707178653245\n",
      "train loss:0.12738635717505162\n",
      "train loss:0.09902044077505473\n",
      "train loss:0.07039868509325078\n",
      "train loss:0.13223428854370567\n",
      "train loss:0.0503365330090907\n",
      "train loss:0.03727651115539252\n",
      "train loss:0.04613649459333499\n",
      "train loss:0.07866789516523467\n",
      "train loss:0.03187972453704271\n",
      "train loss:0.06464084433922036\n",
      "train loss:0.09001647611018142\n",
      "train loss:0.11472868956732411\n",
      "train loss:0.022294039424738142\n",
      "train loss:0.11728217242311184\n",
      "train loss:0.10278284798063458\n",
      "train loss:0.039924817531775444\n",
      "train loss:0.10674985874063887\n",
      "train loss:0.09176816614589436\n",
      "train loss:0.07176989564387232\n",
      "train loss:0.1090606960173994\n",
      "train loss:0.10553779914640399\n",
      "train loss:0.039067349373648655\n",
      "train loss:0.05046132122180369\n",
      "train loss:0.13001931314838316\n",
      "train loss:0.0644317274629882\n",
      "train loss:0.038818384669303665\n",
      "train loss:0.039270936572380705\n",
      "train loss:0.058848439619696935\n",
      "train loss:0.08439857976337432\n",
      "train loss:0.06146527434622302\n",
      "train loss:0.04129139080755771\n",
      "train loss:0.08417174025959002\n",
      "train loss:0.15755515314689053\n",
      "train loss:0.049152286892658055\n",
      "train loss:0.07499037386013117\n",
      "train loss:0.08300549522611014\n",
      "train loss:0.11556174181504426\n",
      "train loss:0.14199536728732176\n",
      "train loss:0.11875669339817957\n",
      "train loss:0.06399948523406464\n",
      "train loss:0.033461673534220436\n",
      "train loss:0.04290659859253467\n",
      "train loss:0.05232021851689632\n",
      "train loss:0.03578875030251834\n",
      "train loss:0.09045193890806046\n",
      "train loss:0.08887351018746754\n",
      "train loss:0.07478340906352664\n",
      "train loss:0.09563323229805627\n",
      "train loss:0.05804704625856735\n",
      "train loss:0.05358255717169926\n",
      "train loss:0.10224396690021795\n",
      "train loss:0.07119415571109096\n",
      "train loss:0.08337052719376808\n",
      "train loss:0.06776306543724875\n",
      "train loss:0.11677342372896593\n",
      "train loss:0.03639514962564368\n",
      "train loss:0.08114764974904144\n",
      "train loss:0.0526435494741025\n",
      "train loss:0.12444168714921515\n",
      "train loss:0.04324504810297267\n",
      "train loss:0.263846787266385\n",
      "train loss:0.12140846074113684\n",
      "train loss:0.04029327446524245\n",
      "train loss:0.13414869846151953\n",
      "train loss:0.06234715142644925\n",
      "train loss:0.16118164361000173\n",
      "train loss:0.03258948921911788\n",
      "train loss:0.16297099840068674\n",
      "train loss:0.1392467432541686\n",
      "train loss:0.0487167585281196\n",
      "train loss:0.07815137536813188\n",
      "train loss:0.0946588630393561\n",
      "train loss:0.18739174251280777\n",
      "train loss:0.05107883255632012\n",
      "train loss:0.11793673156579143\n",
      "train loss:0.062407630673556654\n",
      "train loss:0.11278565459591595\n",
      "train loss:0.043897088913691346\n",
      "train loss:0.025870816459997236\n",
      "train loss:0.10215531478857026\n",
      "train loss:0.07481169642830747\n",
      "train loss:0.04161735591176719\n",
      "train loss:0.1119385542448004\n",
      "train loss:0.0827840410435056\n",
      "train loss:0.0654644013611555\n",
      "train loss:0.07633153590694938\n",
      "train loss:0.1051644177896817\n",
      "train loss:0.07396919878045842\n",
      "train loss:0.027825597041202358\n",
      "train loss:0.04096648571586394\n",
      "train loss:0.07435339483629277\n",
      "train loss:0.08216361047438603\n",
      "train loss:0.053925233472817725\n",
      "train loss:0.06711365037826615\n",
      "train loss:0.06647207830392947\n",
      "train loss:0.058373820206196504\n",
      "train loss:0.08426257592919802\n",
      "train loss:0.05240345553406493\n",
      "train loss:0.025871318938403234\n",
      "train loss:0.04668441397285429\n",
      "train loss:0.11532521738682332\n",
      "train loss:0.0910594243536675\n",
      "train loss:0.11720693241093072\n",
      "train loss:0.06274904446653008\n",
      "train loss:0.0677860729312509\n",
      "train loss:0.0905964892065014\n",
      "train loss:0.03858891929470018\n",
      "train loss:0.031109504736878638\n",
      "train loss:0.07571977039505462\n",
      "train loss:0.07851455423185189\n",
      "train loss:0.021512256201266476\n",
      "train loss:0.094980198940245\n",
      "train loss:0.07959920393318072\n",
      "train loss:0.07203239620172246\n",
      "train loss:0.05856321468326454\n",
      "train loss:0.09277464730489868\n",
      "train loss:0.046111968867539224\n",
      "train loss:0.06262928260966713\n",
      "train loss:0.11863200616283112\n",
      "train loss:0.20929069035139594\n",
      "train loss:0.06684639978290771\n",
      "train loss:0.07369661266538369\n",
      "train loss:0.08916091307627201\n",
      "train loss:0.059236667233833806\n",
      "train loss:0.04734608773545684\n",
      "train loss:0.10523868807780884\n",
      "train loss:0.0638467180974382\n",
      "train loss:0.26365496150031426\n",
      "train loss:0.17886792776450616\n",
      "train loss:0.11485539172450925\n",
      "train loss:0.03635424189668641\n",
      "train loss:0.07920087491152136\n",
      "train loss:0.0792487604959152\n",
      "train loss:0.048302230964461346\n",
      "train loss:0.06139809744652034\n",
      "train loss:0.1361556184124317\n",
      "train loss:0.13108262336878065\n",
      "train loss:0.2014475286921933\n",
      "train loss:0.11553131684202603\n",
      "train loss:0.10051828121816056\n",
      "train loss:0.06721876767502342\n",
      "train loss:0.054549946036312164\n",
      "train loss:0.08374486088100111\n",
      "train loss:0.05307433443146211\n",
      "train loss:0.07873517544526161\n",
      "train loss:0.06945757342586587\n",
      "train loss:0.04907615878931601\n",
      "train loss:0.10805457763626293\n",
      "train loss:0.08730238709908202\n",
      "train loss:0.06987452240463932\n",
      "train loss:0.0877861506857376\n",
      "train loss:0.045800970249216845\n",
      "train loss:0.07702209316357701\n",
      "train loss:0.07367123368782978\n",
      "train loss:0.11498046696760059\n",
      "train loss:0.09971894472774988\n",
      "train loss:0.10782651035612371\n",
      "train loss:0.09744161637326192\n",
      "train loss:0.06057004716619293\n",
      "train loss:0.043308832222303736\n",
      "train loss:0.0784172805727211\n",
      "train loss:0.14803140697197523\n",
      "train loss:0.13665935049367023\n",
      "train loss:0.08721431783050199\n",
      "train loss:0.07826921828920795\n",
      "train loss:0.07743778484735564\n",
      "train loss:0.07683790226780826\n",
      "train loss:0.09577351557477129\n",
      "train loss:0.08017590876907675\n",
      "train loss:0.03023542397771867\n",
      "train loss:0.025503947309728128\n",
      "train loss:0.12278954409495922\n",
      "train loss:0.08730243748390235\n",
      "train loss:0.09070207514717783\n",
      "train loss:0.06340753426257162\n",
      "train loss:0.03722728827208037\n",
      "train loss:0.09745348623767316\n",
      "train loss:0.0584990562001495\n",
      "train loss:0.07847135788842312\n",
      "train loss:0.12446044233539827\n",
      "train loss:0.0482118207675509\n",
      "train loss:0.0911899155722407\n",
      "train loss:0.06354992773747849\n",
      "train loss:0.09021419557716742\n",
      "train loss:0.056753872845651004\n",
      "train loss:0.03719847705020348\n",
      "train loss:0.07387444934208086\n",
      "train loss:0.04027274569792618\n",
      "train loss:0.0703135454505332\n",
      "train loss:0.06009560891969457\n",
      "train loss:0.08681792257753486\n",
      "train loss:0.07714979053556112\n",
      "train loss:0.06794658855845821\n",
      "train loss:0.06922621615523648\n",
      "train loss:0.018262555239164577\n",
      "train loss:0.062354625609659306\n",
      "train loss:0.07448361618663366\n",
      "train loss:0.07851874846536565\n",
      "train loss:0.0643424032604111\n",
      "train loss:0.08555426017471557\n",
      "train loss:0.11413218097084704\n",
      "train loss:0.1258421892988973\n",
      "train loss:0.031071291968120127\n",
      "train loss:0.058915231860843555\n",
      "train loss:0.05317564670657397\n",
      "train loss:0.059067594602437365\n",
      "train loss:0.07821048731926875\n",
      "train loss:0.0315453452247248\n",
      "train loss:0.04984723940650421\n",
      "train loss:0.026601154194456366\n",
      "train loss:0.0778639719455818\n",
      "train loss:0.08051911905399745\n",
      "train loss:0.08391035207644108\n",
      "train loss:0.14275229569941725\n",
      "train loss:0.02412119038919354\n",
      "train loss:0.025591470393048744\n",
      "train loss:0.024870235075589827\n",
      "train loss:0.029815997965277626\n",
      "train loss:0.09805939046574533\n",
      "train loss:0.051310081388106325\n",
      "train loss:0.04829981429289548\n",
      "train loss:0.026793629962962032\n",
      "train loss:0.0473552908194262\n",
      "train loss:0.09968889564308307\n",
      "train loss:0.030784319987027704\n",
      "train loss:0.0505037045770814\n",
      "train loss:0.19800503481655818\n",
      "train loss:0.050918557750197484\n",
      "train loss:0.08820873791089526\n",
      "train loss:0.06099160688032752\n",
      "train loss:0.02802059729029354\n",
      "train loss:0.013157889396562018\n",
      "train loss:0.027642449471340938\n",
      "train loss:0.027864996318456344\n",
      "train loss:0.08634519779871193\n",
      "train loss:0.11938944445973311\n",
      "train loss:0.028986157976129502\n",
      "train loss:0.053153235471816836\n",
      "train loss:0.057078232146745976\n",
      "train loss:0.03373835227008479\n",
      "train loss:0.034137284312010484\n",
      "train loss:0.054626591026439145\n",
      "train loss:0.10513161369087448\n",
      "train loss:0.11872371568526581\n",
      "train loss:0.08400581441653392\n",
      "train loss:0.07136172713240621\n",
      "train loss:0.02115552349865273\n",
      "train loss:0.03488831179927033\n",
      "train loss:0.033756708881666264\n",
      "train loss:0.08236812746559466\n",
      "train loss:0.026158968776197646\n",
      "train loss:0.08700634575750422\n",
      "=== epoch:3, train acc:0.977, test acc:0.981 ===\n",
      "train loss:0.08946554688541558\n",
      "train loss:0.030281073994472742\n",
      "train loss:0.05088878148937088\n",
      "train loss:0.102753934608476\n",
      "train loss:0.039488370417399984\n",
      "train loss:0.016344409201028767\n",
      "train loss:0.08111045100652667\n",
      "train loss:0.10555354801297133\n",
      "train loss:0.07258658224603295\n",
      "train loss:0.05452531458029209\n",
      "train loss:0.07816254618208676\n",
      "train loss:0.03636038262072037\n",
      "train loss:0.02314420971395868\n",
      "train loss:0.037629554264598145\n",
      "train loss:0.05230069678156078\n",
      "train loss:0.04335354521128762\n",
      "train loss:0.05156042323046616\n",
      "train loss:0.047415274211917796\n",
      "train loss:0.043729087615813185\n",
      "train loss:0.024177378249430777\n",
      "train loss:0.12313312958084077\n",
      "train loss:0.05491956751858523\n",
      "train loss:0.029771325793662227\n",
      "train loss:0.04578148938108801\n",
      "train loss:0.10477146851491159\n",
      "train loss:0.04987281991901225\n",
      "train loss:0.023067021586222113\n",
      "train loss:0.148584479364004\n",
      "train loss:0.047628647248119965\n",
      "train loss:0.047590234130837565\n",
      "train loss:0.05843173525243398\n",
      "train loss:0.06173707377589914\n",
      "train loss:0.24239617646840483\n",
      "train loss:0.08232786812734665\n",
      "train loss:0.059959126362286216\n",
      "train loss:0.10433619300688077\n",
      "train loss:0.030546483983166183\n",
      "train loss:0.04709320886903246\n",
      "train loss:0.07752742335890575\n",
      "train loss:0.11043234683867889\n",
      "train loss:0.0688907502028273\n",
      "train loss:0.0388521014029\n",
      "train loss:0.07847045305269966\n",
      "train loss:0.017000324134396068\n",
      "train loss:0.04386709125046275\n",
      "train loss:0.09971504968147286\n",
      "train loss:0.03470357089508572\n",
      "train loss:0.10461033110105591\n",
      "train loss:0.12307546251901502\n",
      "train loss:0.05081711483614673\n",
      "train loss:0.03952810538001971\n",
      "train loss:0.04705555912607196\n",
      "train loss:0.07345942417478764\n",
      "train loss:0.0863795292270196\n",
      "train loss:0.0336022258116275\n",
      "train loss:0.07227970996605645\n",
      "train loss:0.095947560562027\n",
      "train loss:0.039793016446488146\n",
      "train loss:0.10264153328344328\n",
      "train loss:0.12588118518745467\n",
      "train loss:0.06339498538098003\n",
      "train loss:0.11060544102925585\n",
      "train loss:0.0627397548946757\n",
      "train loss:0.022072904208029404\n",
      "train loss:0.06373870123527793\n",
      "train loss:0.06945359062855613\n",
      "train loss:0.07231720393878559\n",
      "train loss:0.02995096768281908\n",
      "train loss:0.04428734423468646\n",
      "train loss:0.04831958012622329\n",
      "train loss:0.06602473217994151\n",
      "train loss:0.06564452751896976\n",
      "train loss:0.031550530938989296\n",
      "train loss:0.027686035002900504\n",
      "train loss:0.05816203069804779\n",
      "train loss:0.07981285006639019\n",
      "train loss:0.10449875683668317\n",
      "train loss:0.02742544131397195\n",
      "train loss:0.07235649430929932\n",
      "train loss:0.03986800877903657\n",
      "train loss:0.03247703591654988\n",
      "train loss:0.09861868270956405\n",
      "train loss:0.04036513436298986\n",
      "train loss:0.10579483165938798\n",
      "train loss:0.049765133720948845\n",
      "train loss:0.06742109664565504\n",
      "train loss:0.05165501357587241\n",
      "train loss:0.03022806644466604\n",
      "train loss:0.0620439087193579\n",
      "train loss:0.029391695046938112\n",
      "train loss:0.04040232313549385\n",
      "train loss:0.04588722889847776\n",
      "train loss:0.011011893105724854\n",
      "train loss:0.05078559939184442\n",
      "train loss:0.017052798228826473\n",
      "train loss:0.04443444889719449\n",
      "train loss:0.09944543187475312\n",
      "train loss:0.10360598967644062\n",
      "train loss:0.09697657160414812\n",
      "train loss:0.034848722518509095\n",
      "train loss:0.02798939831736161\n",
      "train loss:0.05648767491875703\n",
      "train loss:0.026732951548551723\n",
      "train loss:0.047851905462621726\n",
      "train loss:0.060388307722801265\n",
      "train loss:0.03292536228714988\n",
      "train loss:0.05382442545324788\n",
      "train loss:0.03961371799032882\n",
      "train loss:0.10326493767605775\n",
      "train loss:0.05845783015150308\n",
      "train loss:0.027993812735241878\n",
      "train loss:0.05060799815746972\n",
      "train loss:0.032431288708211596\n",
      "train loss:0.04737494173580315\n",
      "train loss:0.08671247187170299\n",
      "train loss:0.09922444394938588\n",
      "train loss:0.03329494819358175\n",
      "train loss:0.13092145179946482\n",
      "train loss:0.1437361410496784\n",
      "train loss:0.029535905826395772\n",
      "train loss:0.07290250249158571\n",
      "train loss:0.056638152062770286\n",
      "train loss:0.036942211566839564\n",
      "train loss:0.08542390950136632\n",
      "train loss:0.018486065697131765\n",
      "train loss:0.040560531279778\n",
      "train loss:0.022550719400981797\n",
      "train loss:0.09826922796819577\n",
      "train loss:0.041255455101133105\n",
      "train loss:0.04630190936204323\n",
      "train loss:0.059596748429920236\n",
      "train loss:0.11635361146041039\n",
      "train loss:0.04022975610012172\n",
      "train loss:0.04656002227687667\n",
      "train loss:0.07027009122425935\n",
      "train loss:0.028169548659624895\n",
      "train loss:0.07213023404901393\n",
      "train loss:0.06350305346470217\n",
      "train loss:0.06293234818684067\n",
      "train loss:0.06939423952179284\n",
      "train loss:0.03499003802203106\n",
      "train loss:0.08665665070371611\n",
      "train loss:0.07668424257365149\n",
      "train loss:0.03678762386829655\n",
      "train loss:0.02254476336165874\n",
      "train loss:0.013369047672177286\n",
      "train loss:0.061152697598486155\n",
      "train loss:0.020245518274823678\n",
      "train loss:0.015980997876704803\n",
      "train loss:0.05184929401413819\n",
      "train loss:0.08319759845205821\n",
      "train loss:0.03864671305351294\n",
      "train loss:0.02405954382180872\n",
      "train loss:0.074016539568815\n",
      "train loss:0.06295056631985903\n",
      "train loss:0.07294542658496031\n",
      "train loss:0.06040244800360408\n",
      "train loss:0.04190569610389942\n",
      "train loss:0.024963760352648644\n",
      "train loss:0.027418000809723075\n",
      "train loss:0.11765376382767702\n",
      "train loss:0.052625347972403265\n",
      "train loss:0.051984480966751984\n",
      "train loss:0.06338141095041945\n",
      "train loss:0.025404334913008662\n",
      "train loss:0.05339799755360722\n",
      "train loss:0.09337559605052022\n",
      "train loss:0.03589286933534775\n",
      "train loss:0.07241829918317341\n",
      "train loss:0.15139841103437648\n",
      "train loss:0.02038827083933172\n",
      "train loss:0.04632707280822609\n",
      "train loss:0.01476432829375622\n",
      "train loss:0.05636565114206827\n",
      "train loss:0.025855488411189457\n",
      "train loss:0.044225865838188015\n",
      "train loss:0.04597716171503536\n",
      "train loss:0.05489743295028417\n",
      "train loss:0.09177356007734122\n",
      "train loss:0.0950160391199995\n",
      "train loss:0.012162234142733644\n",
      "train loss:0.057349369462275354\n",
      "train loss:0.071637333199863\n",
      "train loss:0.02738946131411797\n",
      "train loss:0.1077774290655518\n",
      "train loss:0.016435903445612927\n",
      "train loss:0.055026802738550915\n",
      "train loss:0.11401551690158977\n",
      "train loss:0.06197926265654338\n",
      "train loss:0.03058728629563683\n",
      "train loss:0.04521241470199799\n",
      "train loss:0.01154085641842352\n",
      "train loss:0.018374843766071795\n",
      "train loss:0.057091659447121926\n",
      "train loss:0.0948803310130027\n",
      "train loss:0.058777548469207\n",
      "train loss:0.033810405227154984\n",
      "train loss:0.04463627380564149\n",
      "train loss:0.044065661307911806\n",
      "train loss:0.07683274251937133\n",
      "train loss:0.06360442684845688\n",
      "train loss:0.13988477801482108\n",
      "train loss:0.08942596366894472\n",
      "train loss:0.05411990485940541\n",
      "train loss:0.13407169428450985\n",
      "train loss:0.06474966119729268\n",
      "train loss:0.05922295398291479\n",
      "train loss:0.10162351977830647\n",
      "train loss:0.07818956171680087\n",
      "train loss:0.06098600664695269\n",
      "train loss:0.033989322817465244\n",
      "train loss:0.019554638051584614\n",
      "train loss:0.05778663141670938\n",
      "train loss:0.047318996532965354\n",
      "train loss:0.026323467003856175\n",
      "train loss:0.0275586915519793\n",
      "train loss:0.07707434779545155\n",
      "train loss:0.07531123634197606\n",
      "train loss:0.043701692000796294\n",
      "train loss:0.09095858138759733\n",
      "train loss:0.06878859425726419\n",
      "train loss:0.019999689735575043\n",
      "train loss:0.07249426771339662\n",
      "train loss:0.03046541566071062\n",
      "train loss:0.05168498198275826\n",
      "train loss:0.028118189003131355\n",
      "train loss:0.04745399096128312\n",
      "train loss:0.12215261862875963\n",
      "train loss:0.09092330296057187\n",
      "train loss:0.017002609580815623\n",
      "train loss:0.10944763284739877\n",
      "train loss:0.02848359885771577\n",
      "train loss:0.04242914998114187\n",
      "train loss:0.013292295774234374\n",
      "train loss:0.03911157534899138\n",
      "train loss:0.0243842827619987\n",
      "train loss:0.06626088451248982\n",
      "train loss:0.05924740400727299\n",
      "train loss:0.05634665221850414\n",
      "train loss:0.010391961650807153\n",
      "train loss:0.03283864749527556\n",
      "train loss:0.018052626157457105\n",
      "train loss:0.012466909111890554\n",
      "train loss:0.07360603121153879\n",
      "train loss:0.03312048414408303\n",
      "train loss:0.029601368459025182\n",
      "train loss:0.06669770745100398\n",
      "train loss:0.07776509074072313\n",
      "train loss:0.030285654402583715\n",
      "train loss:0.07940163924153269\n",
      "train loss:0.03354664318760868\n",
      "train loss:0.06946202436367795\n",
      "train loss:0.07198861132751186\n",
      "train loss:0.037082594199972195\n",
      "train loss:0.17512952999206674\n",
      "train loss:0.060180818286078575\n",
      "train loss:0.024410002053922634\n",
      "train loss:0.04722759114003901\n",
      "train loss:0.05146927250059852\n",
      "train loss:0.04470006329746346\n",
      "train loss:0.17611420047748072\n",
      "train loss:0.05685973607368631\n",
      "train loss:0.07483618761030514\n",
      "train loss:0.01233124253992946\n",
      "train loss:0.1109641475927246\n",
      "train loss:0.10800159181928516\n",
      "train loss:0.023179374983401037\n",
      "train loss:0.10080653392786697\n",
      "train loss:0.0733990167023259\n",
      "train loss:0.08133459198021403\n",
      "train loss:0.05068015338609183\n",
      "train loss:0.024744774317725024\n",
      "train loss:0.05440279911049626\n",
      "train loss:0.08095931687564764\n",
      "train loss:0.03171283821181339\n",
      "train loss:0.06000039189909342\n",
      "train loss:0.06029140445929203\n",
      "train loss:0.06310547742537588\n",
      "train loss:0.06905129686292094\n",
      "train loss:0.03702062140850792\n",
      "train loss:0.0861045206091845\n",
      "train loss:0.08784422342027867\n",
      "train loss:0.0286959330971724\n",
      "train loss:0.050094550873602775\n",
      "train loss:0.02599491669644104\n",
      "train loss:0.026463796657158194\n",
      "train loss:0.042089204657329946\n",
      "train loss:0.05150843881732612\n",
      "train loss:0.021252306898761612\n",
      "train loss:0.09471590042692064\n",
      "train loss:0.018654236429878592\n",
      "train loss:0.04095087181027167\n",
      "train loss:0.11443537350797785\n",
      "train loss:0.06273316625269645\n",
      "train loss:0.07439122264867183\n",
      "train loss:0.030515815715790495\n",
      "train loss:0.1114364857085573\n",
      "train loss:0.053440449723105236\n",
      "train loss:0.05378942171928187\n",
      "train loss:0.07025990611239141\n",
      "train loss:0.04650507418963143\n",
      "train loss:0.031461504985897254\n",
      "train loss:0.049431613018796526\n",
      "train loss:0.021524301041000372\n",
      "train loss:0.11064557051006965\n",
      "train loss:0.018273861609211513\n",
      "train loss:0.07794391390600341\n",
      "train loss:0.05274135274311121\n",
      "train loss:0.058836483901817005\n",
      "train loss:0.08775533376069969\n",
      "train loss:0.047328207082721674\n",
      "train loss:0.09192449969903899\n",
      "train loss:0.019498714750201752\n",
      "train loss:0.05301013189128262\n",
      "train loss:0.02169447846115492\n",
      "train loss:0.017155512730749282\n",
      "train loss:0.014616102126398457\n",
      "train loss:0.01626438292580671\n",
      "train loss:0.012649204689338231\n",
      "train loss:0.023159333879493836\n",
      "train loss:0.13956677501443113\n",
      "train loss:0.03239272533589211\n",
      "train loss:0.06660014359862125\n",
      "train loss:0.041245851415094695\n",
      "train loss:0.05054602579112197\n",
      "train loss:0.13011384813801777\n",
      "train loss:0.017689725890850695\n",
      "train loss:0.020121526265140376\n",
      "train loss:0.034205411969044065\n",
      "train loss:0.039288369281206464\n",
      "train loss:0.08098279413714796\n",
      "train loss:0.022368660446519494\n",
      "train loss:0.08600640495749338\n",
      "train loss:0.0334492250409961\n",
      "train loss:0.019954593016006595\n",
      "train loss:0.021899036783076385\n",
      "train loss:0.08000412933584493\n",
      "train loss:0.08319354980803934\n",
      "train loss:0.11378472780576829\n",
      "train loss:0.054785980974769624\n",
      "train loss:0.12096032641266329\n",
      "train loss:0.026545719842441445\n",
      "train loss:0.04993402566544992\n",
      "train loss:0.021907362262837717\n",
      "train loss:0.042020657789847544\n",
      "train loss:0.02465141217062758\n",
      "train loss:0.07541013057112043\n",
      "train loss:0.03412378015867063\n",
      "train loss:0.010483822731034667\n",
      "train loss:0.05678965920190906\n",
      "train loss:0.03790270724591035\n",
      "train loss:0.051661699738210706\n",
      "train loss:0.03421842896076773\n",
      "train loss:0.057033524658022916\n",
      "train loss:0.03025826518748342\n",
      "train loss:0.03814078718542828\n",
      "train loss:0.03216042927210195\n",
      "train loss:0.010360463244691172\n",
      "train loss:0.023537680763367052\n",
      "train loss:0.11695794817986728\n",
      "train loss:0.06893817084381068\n",
      "train loss:0.032998958478794777\n",
      "train loss:0.030247339250977053\n",
      "train loss:0.061040732371597434\n",
      "train loss:0.033078660545168316\n",
      "train loss:0.06505626027469327\n",
      "train loss:0.09850560185023735\n",
      "train loss:0.012647469825896977\n",
      "train loss:0.014086021125727419\n",
      "train loss:0.08077455121015772\n",
      "train loss:0.02654458380225987\n",
      "train loss:0.07039235152046917\n",
      "train loss:0.019587000523765972\n",
      "train loss:0.03825932685058063\n",
      "train loss:0.12561493450914793\n",
      "train loss:0.026749427997290676\n",
      "train loss:0.08557178007805125\n",
      "train loss:0.04764753171327887\n",
      "train loss:0.13673386810373375\n",
      "train loss:0.03342602483374533\n",
      "train loss:0.03443079913038656\n",
      "train loss:0.06368051983292113\n",
      "train loss:0.020433505351080038\n",
      "train loss:0.022592381238030902\n",
      "train loss:0.07148109994291645\n",
      "train loss:0.038707972812146066\n",
      "train loss:0.06628600123322186\n",
      "train loss:0.03359499454749608\n",
      "train loss:0.01659200148403583\n",
      "train loss:0.0297307352518445\n",
      "train loss:0.07279804816475577\n",
      "train loss:0.04123786947989341\n",
      "train loss:0.03313705979069674\n",
      "train loss:0.06022272997545598\n",
      "train loss:0.15100779959217564\n",
      "train loss:0.019769097324804877\n",
      "train loss:0.032823073153183044\n",
      "train loss:0.10259473534204167\n",
      "train loss:0.09817520836608105\n",
      "train loss:0.060375387299133845\n",
      "train loss:0.025147990125147537\n",
      "train loss:0.10046631448675994\n",
      "train loss:0.05240772841555475\n",
      "train loss:0.03367500092826851\n",
      "train loss:0.07359637815669215\n",
      "train loss:0.049562263351652466\n",
      "train loss:0.017628064163518607\n",
      "train loss:0.027321783012240298\n",
      "train loss:0.08511178973910653\n",
      "train loss:0.05592246602323648\n",
      "train loss:0.022694533526125684\n",
      "train loss:0.01693127369553232\n",
      "train loss:0.017387910359616544\n",
      "train loss:0.023036296239238675\n",
      "train loss:0.019950761986716234\n",
      "train loss:0.03673481672596086\n",
      "train loss:0.07854138920854445\n",
      "train loss:0.08135505415327883\n",
      "train loss:0.02095007840587198\n",
      "train loss:0.04580816215108281\n",
      "train loss:0.04124156391606795\n",
      "train loss:0.03664719823364601\n",
      "train loss:0.07612240374589414\n",
      "train loss:0.11381027026833827\n",
      "train loss:0.009936651048258112\n",
      "train loss:0.12001066244421889\n",
      "train loss:0.06460494807389075\n",
      "train loss:0.0895920562744928\n",
      "train loss:0.04324158581544363\n",
      "train loss:0.018807539640945375\n",
      "train loss:0.036574911812014464\n",
      "train loss:0.06105228380527069\n",
      "train loss:0.05518367881770918\n",
      "train loss:0.04127231786662799\n",
      "train loss:0.02155070695300203\n",
      "train loss:0.06537611634136786\n",
      "train loss:0.009029220453025379\n",
      "train loss:0.02639160931474556\n",
      "train loss:0.07568604759262594\n",
      "train loss:0.027174954005451286\n",
      "train loss:0.0489608382712108\n",
      "train loss:0.10008458466065663\n",
      "train loss:0.03949462131237625\n",
      "train loss:0.030177547325026248\n",
      "train loss:0.03968974506243242\n",
      "train loss:0.0707835852579319\n",
      "train loss:0.04577294263523724\n",
      "train loss:0.05665044930437458\n",
      "train loss:0.026916931561643674\n",
      "train loss:0.015098829388031467\n",
      "train loss:0.04660434924145731\n",
      "train loss:0.035585420699185744\n",
      "train loss:0.027165012780755587\n",
      "train loss:0.01446994888688552\n",
      "train loss:0.12064426157725794\n",
      "train loss:0.017192822409553846\n",
      "train loss:0.028157506466230123\n",
      "train loss:0.006041739785005592\n",
      "train loss:0.03456481740084799\n",
      "train loss:0.047070904700692064\n",
      "train loss:0.06534359411278948\n",
      "train loss:0.05511716279075262\n",
      "train loss:0.029278018083893933\n",
      "train loss:0.020699569022602816\n",
      "train loss:0.032693557351240715\n",
      "train loss:0.028701306417892813\n",
      "train loss:0.013766495725527876\n",
      "train loss:0.012642977430772745\n",
      "train loss:0.08272159642522625\n",
      "train loss:0.03109971721567362\n",
      "train loss:0.04938909017400502\n",
      "train loss:0.03104903544185582\n",
      "train loss:0.07828072149553413\n",
      "train loss:0.028078788703831244\n",
      "train loss:0.07585298485924837\n",
      "train loss:0.12776880710618405\n",
      "train loss:0.11024994622764284\n",
      "train loss:0.11482984552366574\n",
      "train loss:0.056303728941893144\n",
      "train loss:0.03178352900367936\n",
      "train loss:0.058909737264465294\n",
      "train loss:0.05768152256689549\n",
      "train loss:0.04172618293065107\n",
      "train loss:0.03748663058291045\n",
      "train loss:0.07158548753763597\n",
      "train loss:0.03065244746490744\n",
      "train loss:0.018378968740916282\n",
      "train loss:0.024438597334455036\n",
      "train loss:0.014849117552398159\n",
      "train loss:0.04963594020050768\n",
      "train loss:0.028369421429067378\n",
      "train loss:0.015513080887171786\n",
      "train loss:0.06266893999149921\n",
      "train loss:0.036275226925599674\n",
      "train loss:0.013759815652819139\n",
      "train loss:0.03820454277915546\n",
      "train loss:0.06472610482695519\n",
      "train loss:0.034683978973084374\n",
      "train loss:0.05667535542029163\n",
      "train loss:0.011942276189929763\n",
      "train loss:0.03304926152713902\n",
      "train loss:0.12017220615448988\n",
      "train loss:0.04347700941947228\n",
      "train loss:0.03409549636766128\n",
      "train loss:0.04363424658887635\n",
      "train loss:0.02488207653023634\n",
      "train loss:0.046145526219053185\n",
      "train loss:0.08760809996834845\n",
      "train loss:0.0617213612356763\n",
      "train loss:0.06620475022863728\n",
      "train loss:0.01936590797126741\n",
      "train loss:0.02633038064643097\n",
      "train loss:0.047655327681782794\n",
      "train loss:0.02775244227096095\n",
      "train loss:0.013732126070951145\n",
      "train loss:0.07045512327042296\n",
      "train loss:0.059500402328048534\n",
      "train loss:0.03781845803109636\n",
      "train loss:0.03618023054252462\n",
      "train loss:0.07903370610932449\n",
      "train loss:0.01696986841662841\n",
      "train loss:0.08192429730442205\n",
      "train loss:0.01834125491005607\n",
      "train loss:0.0796110086511135\n",
      "train loss:0.07368268360039303\n",
      "train loss:0.025434804477486708\n",
      "train loss:0.03066986889970229\n",
      "train loss:0.032793563657898706\n",
      "train loss:0.025501478147961568\n",
      "train loss:0.031543854784351344\n",
      "train loss:0.024713050812279987\n",
      "train loss:0.05225129549190573\n",
      "train loss:0.03168322470486918\n",
      "train loss:0.03625209280709132\n",
      "train loss:0.09602140545395942\n",
      "train loss:0.01227930327089569\n",
      "train loss:0.07929022492711327\n",
      "train loss:0.051617436217127485\n",
      "train loss:0.013238999945169522\n",
      "train loss:0.07499751422753416\n",
      "train loss:0.01788582539073904\n",
      "train loss:0.05037007029850975\n",
      "train loss:0.059799781259781554\n",
      "train loss:0.015169049167487451\n",
      "train loss:0.02626812270682171\n",
      "train loss:0.04251947907451343\n",
      "train loss:0.04183419106840243\n",
      "train loss:0.05560990275199619\n",
      "train loss:0.04673616977942244\n",
      "train loss:0.01605172536413046\n",
      "train loss:0.08426378611350697\n",
      "train loss:0.09683476397369628\n",
      "train loss:0.048349829473431465\n",
      "train loss:0.018133156564371766\n",
      "train loss:0.08927093690993983\n",
      "train loss:0.019404945528947642\n",
      "train loss:0.0192953507035374\n",
      "train loss:0.025202435469567592\n",
      "train loss:0.07345411121457543\n",
      "train loss:0.013280041347306865\n",
      "train loss:0.0345213956847357\n",
      "train loss:0.01786241623583805\n",
      "train loss:0.012811914189557566\n",
      "train loss:0.03540294600954239\n",
      "train loss:0.0740623702255301\n",
      "train loss:0.03894333895300277\n",
      "train loss:0.03905735804805987\n",
      "train loss:0.060735733371468335\n",
      "train loss:0.021787572237763553\n",
      "train loss:0.033548221662817304\n",
      "train loss:0.08002563654174669\n",
      "train loss:0.02527517756790882\n",
      "train loss:0.026769493169466994\n",
      "train loss:0.0247601949688766\n",
      "train loss:0.010268583320268016\n",
      "train loss:0.10397385501429772\n",
      "train loss:0.03247728291167542\n",
      "train loss:0.03970757701426076\n",
      "train loss:0.03448321526644917\n",
      "train loss:0.048281254248251776\n",
      "train loss:0.0886612200854805\n",
      "train loss:0.02765284250055809\n",
      "train loss:0.027051337275690743\n",
      "train loss:0.1157435256613398\n",
      "train loss:0.01809797964220732\n",
      "train loss:0.0302801842196712\n",
      "train loss:0.012192655314250449\n",
      "train loss:0.05755657675118582\n",
      "train loss:0.01592489442515318\n",
      "train loss:0.051887724466767364\n",
      "train loss:0.04647256790261309\n",
      "train loss:0.04114877723719955\n",
      "train loss:0.034030997938592634\n",
      "train loss:0.06263599555225284\n",
      "train loss:0.03553505740567968\n",
      "train loss:0.024227135653266695\n",
      "train loss:0.007268584164232698\n",
      "train loss:0.041520432336985186\n",
      "train loss:0.029478756376071797\n",
      "train loss:0.021963608926035973\n",
      "=== epoch:4, train acc:0.986, test acc:0.983 ===\n",
      "train loss:0.04666589213371247\n",
      "train loss:0.03570305465645043\n",
      "train loss:0.013350400868103636\n",
      "train loss:0.017428221750892137\n",
      "train loss:0.016257491788604625\n",
      "train loss:0.09954127855644745\n",
      "train loss:0.0332165813660785\n",
      "train loss:0.0801130693875731\n",
      "train loss:0.03836707259471397\n",
      "train loss:0.04636063061514689\n",
      "train loss:0.03481415212144389\n",
      "train loss:0.03613167332057719\n",
      "train loss:0.07173896061436856\n",
      "train loss:0.01014997149018952\n",
      "train loss:0.010945478483582271\n",
      "train loss:0.031120888801460685\n",
      "train loss:0.02951881351160471\n",
      "train loss:0.03942169102521062\n",
      "train loss:0.015820276976260598\n",
      "train loss:0.0400962331435783\n",
      "train loss:0.009832779472067907\n",
      "train loss:0.021786476509501683\n",
      "train loss:0.06028963958531831\n",
      "train loss:0.037548858854810054\n",
      "train loss:0.022103211512161283\n",
      "train loss:0.05257253940494845\n",
      "train loss:0.05519007911607669\n",
      "train loss:0.06907312323732817\n",
      "train loss:0.05351896155064781\n",
      "train loss:0.11060815085588788\n",
      "train loss:0.0348144391438536\n",
      "train loss:0.02392141387599074\n",
      "train loss:0.06856609660370604\n",
      "train loss:0.018282339760873016\n",
      "train loss:0.030443831629084837\n",
      "train loss:0.06141748014679001\n",
      "train loss:0.021716427634538252\n",
      "train loss:0.062214284161224036\n",
      "train loss:0.015050170823615714\n",
      "train loss:0.07192249810639345\n",
      "train loss:0.014409473167589957\n",
      "train loss:0.016291166122804086\n",
      "train loss:0.027677118983913965\n",
      "train loss:0.04649983138611078\n",
      "train loss:0.053855720103755195\n",
      "train loss:0.040601314855789036\n",
      "train loss:0.053865113250807964\n",
      "train loss:0.03413677581595644\n",
      "train loss:0.09664407782259357\n",
      "train loss:0.21234831236465357\n",
      "train loss:0.10927915879470985\n",
      "train loss:0.019117002369837585\n",
      "train loss:0.027054265091175842\n",
      "train loss:0.03658274578063179\n",
      "train loss:0.036487392687704914\n",
      "train loss:0.06474786466588837\n",
      "train loss:0.013259155298036835\n",
      "train loss:0.06657459999215647\n",
      "train loss:0.012177397079974516\n",
      "train loss:0.04484585114673431\n",
      "train loss:0.031308616553089925\n",
      "train loss:0.07910935039140786\n",
      "train loss:0.05643528022837229\n",
      "train loss:0.06285782032143584\n",
      "train loss:0.01801768955324543\n",
      "train loss:0.01845309238620826\n",
      "train loss:0.010023679911702837\n",
      "train loss:0.014667410004160083\n",
      "train loss:0.03030011315177016\n",
      "train loss:0.045154745246981924\n",
      "train loss:0.02694302113995251\n",
      "train loss:0.04011099022648001\n",
      "train loss:0.050063686161121675\n",
      "train loss:0.014574717892299865\n",
      "train loss:0.09283943125773048\n",
      "train loss:0.027225963765208666\n",
      "train loss:0.00773924912830006\n",
      "train loss:0.113002846224618\n",
      "train loss:0.012676376244233779\n",
      "train loss:0.035674853476766376\n",
      "train loss:0.004094133517477286\n",
      "train loss:0.011197785905692051\n",
      "train loss:0.020367343657470328\n",
      "train loss:0.1008898632578381\n",
      "train loss:0.02415240112623041\n",
      "train loss:0.01767393999393909\n",
      "train loss:0.023439543499168845\n",
      "train loss:0.010521972950752603\n",
      "train loss:0.02974014193790307\n",
      "train loss:0.0656901997732578\n",
      "train loss:0.028438016186516785\n",
      "train loss:0.03646928711547706\n",
      "train loss:0.0626507851344821\n",
      "train loss:0.03926604864504188\n",
      "train loss:0.05932615014197079\n",
      "train loss:0.019757429028599463\n",
      "train loss:0.011559810306951367\n",
      "train loss:0.016103415324831373\n",
      "train loss:0.03260870208246414\n",
      "train loss:0.03898263562642016\n",
      "train loss:0.016807609392609363\n",
      "train loss:0.01129489331471448\n",
      "train loss:0.034996141855416524\n",
      "train loss:0.03822950769489151\n",
      "train loss:0.03908667963600572\n",
      "train loss:0.06645045442483485\n",
      "train loss:0.029940273677342456\n",
      "train loss:0.058526384400841375\n",
      "train loss:0.03729133053688407\n",
      "train loss:0.018524737284261857\n",
      "train loss:0.019524409004975072\n",
      "train loss:0.029394812452209488\n",
      "train loss:0.014585138898392485\n",
      "train loss:0.037296225623972605\n",
      "train loss:0.05220154856772686\n",
      "train loss:0.07015614366129545\n",
      "train loss:0.026106037951517592\n",
      "train loss:0.030821445466127667\n",
      "train loss:0.0636373449442617\n",
      "train loss:0.05644295793224249\n",
      "train loss:0.007608623962341221\n",
      "train loss:0.057613474825770734\n",
      "train loss:0.053688679828278636\n",
      "train loss:0.10351098602999813\n",
      "train loss:0.10734131808680754\n",
      "train loss:0.01622071274027883\n",
      "train loss:0.05654923410366509\n",
      "train loss:0.1167497818403852\n",
      "train loss:0.014316553539492469\n",
      "train loss:0.08376415097088516\n",
      "train loss:0.03413304019800306\n",
      "train loss:0.047934885798321315\n",
      "train loss:0.04828014618528915\n",
      "train loss:0.04872691288043451\n",
      "train loss:0.04141622304492237\n",
      "train loss:0.04804705817849844\n",
      "train loss:0.06776720726842238\n",
      "train loss:0.04159391838901584\n",
      "train loss:0.01602748840599258\n",
      "train loss:0.07478791144098343\n",
      "train loss:0.07508275800992571\n",
      "train loss:0.01749261186921937\n",
      "train loss:0.019288759260787144\n",
      "train loss:0.02844968413483592\n",
      "train loss:0.04553432033358344\n",
      "train loss:0.014156140619025048\n",
      "train loss:0.08819043271257854\n",
      "train loss:0.03016383879738968\n",
      "train loss:0.034963660122725226\n",
      "train loss:0.06319975443130607\n",
      "train loss:0.06442187561497989\n",
      "train loss:0.013155536174808495\n",
      "train loss:0.026024643481256205\n",
      "train loss:0.02880210927113358\n",
      "train loss:0.08101600414556423\n",
      "train loss:0.027712421880199352\n",
      "train loss:0.07875669778702779\n",
      "train loss:0.026990202110933975\n",
      "train loss:0.03452463464628106\n",
      "train loss:0.10909272350164137\n",
      "train loss:0.02731175761381967\n",
      "train loss:0.017663341958720866\n",
      "train loss:0.03280709942850894\n",
      "train loss:0.020364171756613\n",
      "train loss:0.03466934193194454\n",
      "train loss:0.017335183953098496\n",
      "train loss:0.06218155331765896\n",
      "train loss:0.023339300427156418\n",
      "train loss:0.009247019594798579\n",
      "train loss:0.07138105744134976\n",
      "train loss:0.010165704158819597\n",
      "train loss:0.049982345259370495\n",
      "train loss:0.015113509350762085\n",
      "train loss:0.03766753821222727\n",
      "train loss:0.03915056981530904\n",
      "train loss:0.027867333758051786\n",
      "train loss:0.0168818519358623\n",
      "train loss:0.07346267380171635\n",
      "train loss:0.04558639817640979\n",
      "train loss:0.026130215614204234\n",
      "train loss:0.04225226075340428\n",
      "train loss:0.017477928320360853\n",
      "train loss:0.016633244669627262\n",
      "train loss:0.02354370777015087\n",
      "train loss:0.03145353453611011\n",
      "train loss:0.03218454140339218\n",
      "train loss:0.029078474237198206\n",
      "train loss:0.019742571897452117\n",
      "train loss:0.07966533842450862\n",
      "train loss:0.028533735463934798\n",
      "train loss:0.11983039235589318\n",
      "train loss:0.021936046342700764\n",
      "train loss:0.02050942932687908\n",
      "train loss:0.01683256406095113\n",
      "train loss:0.01984886439375017\n",
      "train loss:0.022305683154021105\n",
      "train loss:0.040225360257519265\n",
      "train loss:0.07380126918515678\n",
      "train loss:0.026796038931559338\n",
      "train loss:0.005733713199430421\n",
      "train loss:0.023343602350763458\n",
      "train loss:0.1742647270616836\n",
      "train loss:0.014713380855224265\n",
      "train loss:0.030640509777308908\n",
      "train loss:0.03938159556597823\n",
      "train loss:0.01086385841653922\n",
      "train loss:0.010279195886205388\n",
      "train loss:0.06375022011670586\n",
      "train loss:0.013938100488688366\n",
      "train loss:0.017504855254753194\n",
      "train loss:0.03689695535797348\n",
      "train loss:0.021052716366598445\n",
      "train loss:0.022719370145677212\n",
      "train loss:0.03794889543523496\n",
      "train loss:0.006830542964652582\n",
      "train loss:0.031303599932333524\n",
      "train loss:0.040660596900263385\n",
      "train loss:0.029400635610079568\n",
      "train loss:0.035253649874260336\n",
      "train loss:0.09956012087161387\n",
      "train loss:0.02084307001428404\n",
      "train loss:0.06948725044558277\n",
      "train loss:0.06847713759856638\n",
      "train loss:0.12312153087791752\n",
      "train loss:0.036132121758585836\n",
      "train loss:0.020879941685644502\n",
      "train loss:0.007911022512710735\n",
      "train loss:0.025027652288239267\n",
      "train loss:0.0199919253649015\n",
      "train loss:0.008648949523074505\n",
      "train loss:0.025329915944073925\n",
      "train loss:0.037548932529323516\n",
      "train loss:0.04598157392214277\n",
      "train loss:0.012120747477384907\n",
      "train loss:0.007902983700266932\n",
      "train loss:0.07240683642142615\n",
      "train loss:0.022190680407682805\n",
      "train loss:0.027479028510075235\n",
      "train loss:0.029723192331243854\n",
      "train loss:0.031137040253498456\n",
      "train loss:0.017723257857962603\n",
      "train loss:0.061656485466823986\n",
      "train loss:0.11507116502184926\n",
      "train loss:0.026044029409803025\n",
      "train loss:0.02438777776287774\n",
      "train loss:0.025343949190600786\n",
      "train loss:0.015690212908472854\n",
      "train loss:0.022124015550414766\n",
      "train loss:0.05645648158966385\n",
      "train loss:0.042811539391717404\n",
      "train loss:0.06624741162097803\n",
      "train loss:0.059262452268792225\n",
      "train loss:0.010781812210931547\n",
      "train loss:0.026112304452785774\n",
      "train loss:0.04553249421875957\n",
      "train loss:0.016491330508898446\n",
      "train loss:0.02737448538506175\n",
      "train loss:0.026531514525369677\n",
      "train loss:0.01324392298547898\n",
      "train loss:0.0555393087316707\n",
      "train loss:0.03888619310922689\n",
      "train loss:0.003822964326488957\n",
      "train loss:0.04303533841663083\n",
      "train loss:0.07790710512267865\n",
      "train loss:0.0570101380754512\n",
      "train loss:0.09794410637562899\n",
      "train loss:0.07554885971367745\n",
      "train loss:0.007409209479498319\n",
      "train loss:0.0223564014224728\n",
      "train loss:0.042450931320288265\n",
      "train loss:0.04754586958187817\n",
      "train loss:0.08542462195663689\n",
      "train loss:0.0481765013891139\n",
      "train loss:0.027529579175571275\n",
      "train loss:0.12300801724562918\n",
      "train loss:0.01682714903692757\n",
      "train loss:0.021818017044459202\n",
      "train loss:0.03384572191524917\n",
      "train loss:0.10037314147911147\n",
      "train loss:0.033520600932662986\n",
      "train loss:0.02061594846294073\n",
      "train loss:0.09815384549051602\n",
      "train loss:0.1406822791789215\n",
      "train loss:0.03831311149444179\n",
      "train loss:0.03221964111247939\n",
      "train loss:0.010432024633692909\n",
      "train loss:0.05291619999172133\n",
      "train loss:0.04942384035544592\n",
      "train loss:0.02440576199067369\n",
      "train loss:0.014906534719332619\n",
      "train loss:0.004729784192817918\n",
      "train loss:0.06709814128668304\n",
      "train loss:0.024013488794671568\n",
      "train loss:0.006221536758102489\n",
      "train loss:0.12575357786955194\n",
      "train loss:0.014768073758194795\n",
      "train loss:0.017859259086405607\n",
      "train loss:0.020249914787065094\n",
      "train loss:0.06293286134226377\n",
      "train loss:0.025705983398796265\n",
      "train loss:0.008372135598982717\n",
      "train loss:0.021294863699438994\n",
      "train loss:0.017507613888530248\n",
      "train loss:0.026781226556649426\n",
      "train loss:0.010893385591595977\n",
      "train loss:0.109885174268727\n",
      "train loss:0.040604789352401784\n",
      "train loss:0.09429275773019137\n",
      "train loss:0.024095867859242254\n",
      "train loss:0.012100265534340054\n",
      "train loss:0.03424146042016985\n",
      "train loss:0.09156697765147367\n",
      "train loss:0.05500734032731395\n",
      "train loss:0.016194664581984545\n",
      "train loss:0.05111344243300871\n",
      "train loss:0.012151014389269164\n",
      "train loss:0.021567747393879535\n",
      "train loss:0.01031710921165363\n",
      "train loss:0.06620749720031566\n",
      "train loss:0.08987164839080668\n",
      "train loss:0.0711489337205806\n",
      "train loss:0.020008094326012863\n",
      "train loss:0.04518291101007639\n",
      "train loss:0.008820419515865034\n",
      "train loss:0.011317816539886706\n",
      "train loss:0.010904141555157655\n",
      "train loss:0.02585668784808879\n",
      "train loss:0.06605307556497673\n",
      "train loss:0.007334758120063522\n",
      "train loss:0.012802847335699773\n",
      "train loss:0.013152585664210228\n",
      "train loss:0.027062649389383468\n",
      "train loss:0.011933812483252084\n",
      "train loss:0.011302454735566762\n",
      "train loss:0.030289683378003217\n",
      "train loss:0.042134176455094395\n",
      "train loss:0.04209861649771785\n",
      "train loss:0.06245741169258868\n",
      "train loss:0.06651753020558368\n",
      "train loss:0.0073184967438667614\n",
      "train loss:0.009171161452976207\n",
      "train loss:0.03891006441850795\n",
      "train loss:0.036492442241704726\n",
      "train loss:0.06447932795379455\n",
      "train loss:0.025301351526941976\n",
      "train loss:0.008899932482154455\n",
      "train loss:0.05136268599808871\n",
      "train loss:0.04711329744231105\n",
      "train loss:0.035527460064216455\n",
      "train loss:0.03101351293465712\n",
      "train loss:0.010562272331202154\n",
      "train loss:0.05370541541872079\n",
      "train loss:0.005861378945793457\n",
      "train loss:0.015182486846401867\n",
      "train loss:0.11755501530900356\n",
      "train loss:0.07788130415494533\n",
      "train loss:0.029450416315662517\n",
      "train loss:0.07726211539948868\n",
      "train loss:0.07366435023138788\n",
      "train loss:0.03874784058665259\n",
      "train loss:0.02705540986636068\n",
      "train loss:0.01252144875501747\n",
      "train loss:0.024229866797546712\n",
      "train loss:0.040462699783338524\n",
      "train loss:0.049196914359763984\n",
      "train loss:0.04012323438369534\n",
      "train loss:0.029462243726597833\n",
      "train loss:0.012374146840282428\n",
      "train loss:0.01758044522150321\n",
      "train loss:0.07816907620369515\n",
      "train loss:0.01859155871352682\n",
      "train loss:0.009812314883428937\n",
      "train loss:0.05997011298711987\n",
      "train loss:0.03478913240880953\n",
      "train loss:0.03394322469136865\n",
      "train loss:0.06469167605481474\n",
      "train loss:0.02796755317579317\n",
      "train loss:0.012416887633393903\n",
      "train loss:0.0495626730852609\n",
      "train loss:0.061304132396029366\n",
      "train loss:0.010018276145101326\n",
      "train loss:0.02214510935999374\n",
      "train loss:0.00830021702927845\n",
      "train loss:0.03599738515597847\n",
      "train loss:0.027613026396191506\n",
      "train loss:0.0502458167053637\n",
      "train loss:0.010022398811283155\n",
      "train loss:0.07329361098948407\n",
      "train loss:0.023027815085079003\n",
      "train loss:0.07315102814352463\n",
      "train loss:0.05266703127271393\n",
      "train loss:0.05930229652995365\n",
      "train loss:0.011982641892958324\n",
      "train loss:0.028253773334203647\n",
      "train loss:0.03667253888322367\n",
      "train loss:0.0560160205265257\n",
      "train loss:0.02735453227195854\n",
      "train loss:0.038676292686035875\n",
      "train loss:0.011971330419917959\n",
      "train loss:0.0142189677273576\n",
      "train loss:0.015675758893052394\n",
      "train loss:0.0415654062056199\n",
      "train loss:0.017269726024778075\n",
      "train loss:0.0351451853477627\n",
      "train loss:0.01793082755069058\n",
      "train loss:0.02713355854804246\n",
      "train loss:0.06211957423001162\n",
      "train loss:0.09235189864735176\n",
      "train loss:0.017845747092750653\n",
      "train loss:0.026912386011199625\n",
      "train loss:0.16270767790008114\n",
      "train loss:0.011539660311710508\n",
      "train loss:0.007111026174397779\n",
      "train loss:0.07621111177361663\n",
      "train loss:0.040446533098476865\n",
      "train loss:0.07612418412801814\n",
      "train loss:0.026032713488583457\n",
      "train loss:0.006157746316793175\n",
      "train loss:0.013098857253111836\n",
      "train loss:0.07045933797478568\n",
      "train loss:0.013597232560322484\n",
      "train loss:0.06472737583828067\n",
      "train loss:0.009445362893556686\n",
      "train loss:0.02296259071583075\n",
      "train loss:0.0479203132868998\n",
      "train loss:0.06584856878753557\n",
      "train loss:0.05250738590146898\n",
      "train loss:0.01867333192690637\n",
      "train loss:0.004804872880156963\n",
      "train loss:0.07926646452956582\n",
      "train loss:0.0745202404396939\n",
      "train loss:0.047911331325588724\n",
      "train loss:0.07665180400095943\n",
      "train loss:0.050446479084652725\n",
      "train loss:0.026838873608615546\n",
      "train loss:0.05598249410272905\n",
      "train loss:0.007628427816056385\n",
      "train loss:0.03127370647013275\n",
      "train loss:0.04791392362206889\n",
      "train loss:0.0506771391586651\n",
      "train loss:0.043459749800784424\n",
      "train loss:0.05067499523962948\n",
      "train loss:0.061393099663994706\n",
      "train loss:0.06020728410501804\n",
      "train loss:0.028509395538003933\n",
      "train loss:0.06104696954435312\n",
      "train loss:0.02314409240517315\n",
      "train loss:0.012976533984472209\n",
      "train loss:0.018905972143117438\n",
      "train loss:0.1076180410015964\n",
      "train loss:0.0577214120578253\n",
      "train loss:0.022209198205140782\n",
      "train loss:0.02698391727523941\n",
      "train loss:0.04722495363709011\n",
      "train loss:0.07877048835303323\n",
      "train loss:0.012335060368659024\n",
      "train loss:0.03609966384791737\n",
      "train loss:0.05162135028174875\n",
      "train loss:0.04145385857348424\n",
      "train loss:0.11996418053313801\n",
      "train loss:0.005381373591083417\n",
      "train loss:0.011410485388497949\n",
      "train loss:0.04840535498956991\n",
      "train loss:0.02286055426699241\n",
      "train loss:0.06840235434035101\n",
      "train loss:0.01891660422868731\n",
      "train loss:0.041171645190348126\n",
      "train loss:0.02419293664718991\n",
      "train loss:0.03507660818912997\n",
      "train loss:0.04622915262120561\n",
      "train loss:0.016617838598930332\n",
      "train loss:0.00933791365794335\n",
      "train loss:0.02693564910761903\n",
      "train loss:0.04249895427517531\n",
      "train loss:0.04149300349165126\n",
      "train loss:0.023395023550299623\n",
      "train loss:0.04721737454718053\n",
      "train loss:0.08183225778995111\n",
      "train loss:0.02082780928299558\n",
      "train loss:0.021476404495021008\n",
      "train loss:0.011682853855155653\n",
      "train loss:0.0440341595701145\n",
      "train loss:0.017773035071337165\n",
      "train loss:0.018652371560648178\n",
      "train loss:0.017936617036339954\n",
      "train loss:0.010062614555375313\n",
      "train loss:0.006055544966697637\n",
      "train loss:0.012963791558381977\n",
      "train loss:0.03838729065960167\n",
      "train loss:0.038866965862781176\n",
      "train loss:0.0048778676343663955\n",
      "train loss:0.01282363107803961\n",
      "train loss:0.014563353665344371\n",
      "train loss:0.03787269137378042\n",
      "train loss:0.0441307098646789\n",
      "train loss:0.027580270096953324\n",
      "train loss:0.005132183598738028\n",
      "train loss:0.04852816558165288\n",
      "train loss:0.10671851696827904\n",
      "train loss:0.03167139703088467\n",
      "train loss:0.03345525501906926\n",
      "train loss:0.049727312776349925\n",
      "train loss:0.014507931868273554\n",
      "train loss:0.025422738092767294\n",
      "train loss:0.05948821151455128\n",
      "train loss:0.0075711498142006185\n",
      "train loss:0.05934023774615857\n",
      "train loss:0.022565664668400823\n",
      "train loss:0.10004327222691668\n",
      "train loss:0.01462358394740791\n",
      "train loss:0.019326424223248623\n",
      "train loss:0.027109926229057488\n",
      "train loss:0.04569904183853429\n",
      "train loss:0.023745666631662932\n",
      "train loss:0.04065037586988284\n",
      "train loss:0.17579375727954363\n",
      "train loss:0.04831931830203497\n",
      "train loss:0.008372582268807122\n",
      "train loss:0.016979110216841765\n",
      "train loss:0.050058524456814704\n",
      "train loss:0.058481058600129\n",
      "train loss:0.009491555136289513\n",
      "train loss:0.012566057134733542\n",
      "train loss:0.014265606142954019\n",
      "train loss:0.0425037583167057\n",
      "train loss:0.025943489265376946\n",
      "train loss:0.010939860932132667\n",
      "train loss:0.0371065119884269\n",
      "train loss:0.010468755175922542\n",
      "train loss:0.05401771169456194\n",
      "train loss:0.06854740748926261\n",
      "train loss:0.0176165692390976\n",
      "train loss:0.006213022483580701\n",
      "train loss:0.015935949454650846\n",
      "train loss:0.021517951179158654\n",
      "train loss:0.007130439098605066\n",
      "train loss:0.03791514048548887\n",
      "train loss:0.0244791998760807\n",
      "train loss:0.014921861390272587\n",
      "train loss:0.014152365200016427\n",
      "train loss:0.005934048331391384\n",
      "train loss:0.04316170858763\n",
      "train loss:0.05110191790680083\n",
      "train loss:0.02901333025784013\n",
      "train loss:0.02623835510407419\n",
      "train loss:0.011446573267986043\n",
      "train loss:0.022485825862969166\n",
      "train loss:0.03109275132685487\n",
      "train loss:0.024228047340912783\n",
      "train loss:0.048939578576623\n",
      "train loss:0.01165880999283806\n",
      "train loss:0.1804598127121335\n",
      "train loss:0.013586127014499691\n",
      "train loss:0.009314961158084022\n",
      "train loss:0.023333571902716982\n",
      "train loss:0.12886281058842194\n",
      "train loss:0.011966499701529425\n",
      "train loss:0.013689518652420024\n",
      "train loss:0.031151627224568653\n",
      "train loss:0.02622231428255\n",
      "train loss:0.050202907222755284\n",
      "train loss:0.0281755297943806\n",
      "train loss:0.006053331577180476\n",
      "train loss:0.013640130679026639\n",
      "train loss:0.02018221444101786\n",
      "train loss:0.016154185902481785\n",
      "train loss:0.022950270829079255\n",
      "train loss:0.013947201881915566\n",
      "train loss:0.007742304294528357\n",
      "train loss:0.040519086211227816\n",
      "train loss:0.03075379912323386\n",
      "train loss:0.04343865660631906\n",
      "train loss:0.013117153525651414\n",
      "train loss:0.011135968513887595\n",
      "train loss:0.013797522518759273\n",
      "train loss:0.0278331844173203\n",
      "train loss:0.02152970786620413\n",
      "train loss:0.020942280127992353\n",
      "train loss:0.04935913328771415\n",
      "train loss:0.011135592596745706\n",
      "train loss:0.01601597667355496\n",
      "train loss:0.0804087108182146\n",
      "train loss:0.039544676047512065\n",
      "train loss:0.07109765785898527\n",
      "train loss:0.04113252491724296\n",
      "train loss:0.08187529651018596\n",
      "train loss:0.05731481646957814\n",
      "train loss:0.021216476311760536\n",
      "train loss:0.030282299034853896\n",
      "train loss:0.013316324918608027\n",
      "train loss:0.008235464174067267\n",
      "train loss:0.016135898817772644\n",
      "train loss:0.06685755644898696\n",
      "train loss:0.05216411718575107\n",
      "train loss:0.032483879617197745\n",
      "train loss:0.010170844719096265\n",
      "train loss:0.08142353735320965\n",
      "train loss:0.021588924969045294\n",
      "train loss:0.021631686823273898\n",
      "train loss:0.040549792049740956\n",
      "=== epoch:5, train acc:0.986, test acc:0.985 ===\n",
      "train loss:0.006557702866286086\n",
      "train loss:0.04111158847506979\n",
      "train loss:0.027078730647746966\n",
      "train loss:0.07120837259231155\n",
      "train loss:0.03411005865707938\n",
      "train loss:0.025556652462558796\n",
      "train loss:0.0077283187201968705\n",
      "train loss:0.009998343188926806\n",
      "train loss:0.05442795577236259\n",
      "train loss:0.05196579474575849\n",
      "train loss:0.016232554527525853\n",
      "train loss:0.022472814235533982\n",
      "train loss:0.017569072216707175\n",
      "train loss:0.010871514453007209\n",
      "train loss:0.027454090590307224\n",
      "train loss:0.06967283983805123\n",
      "train loss:0.028982350981513038\n",
      "train loss:0.019631689354649495\n",
      "train loss:0.014982153145633831\n",
      "train loss:0.016706705786388033\n",
      "train loss:0.022320779678225277\n",
      "train loss:0.05113271228603459\n",
      "train loss:0.05415838628181265\n",
      "train loss:0.008814412531669093\n",
      "train loss:0.06027106650662935\n",
      "train loss:0.051887259800267274\n",
      "train loss:0.02149556408861456\n",
      "train loss:0.02758079096323358\n",
      "train loss:0.015147319715836584\n",
      "train loss:0.09855460633911907\n",
      "train loss:0.006786595973146214\n",
      "train loss:0.033485926961254776\n",
      "train loss:0.08643539634984293\n",
      "train loss:0.038975495516915815\n",
      "train loss:0.023898834550220575\n",
      "train loss:0.04948947408605538\n",
      "train loss:0.008025342628673446\n",
      "train loss:0.008514628845918516\n",
      "train loss:0.01917531576680845\n",
      "train loss:0.01097870925026982\n",
      "train loss:0.07803484075579747\n",
      "train loss:0.018980085066885744\n",
      "train loss:0.035250847123817666\n",
      "train loss:0.06700599878404653\n",
      "train loss:0.06808435489661709\n",
      "train loss:0.038201981950397076\n",
      "train loss:0.02855510114594411\n",
      "train loss:0.007247298967940741\n",
      "train loss:0.009504999308180858\n",
      "train loss:0.03330221534992803\n",
      "train loss:0.04014237888743308\n",
      "train loss:0.010561913846472554\n",
      "train loss:0.05229263446282826\n",
      "train loss:0.014655684747637773\n",
      "train loss:0.04478005888436737\n",
      "train loss:0.014273338604662535\n",
      "train loss:0.018122092359381902\n",
      "train loss:0.02113138877404165\n",
      "train loss:0.06819522773162776\n",
      "train loss:0.01741650939896098\n",
      "train loss:0.01085086489609305\n",
      "train loss:0.015564071538992044\n",
      "train loss:0.01667250373375069\n",
      "train loss:0.038603219661576677\n",
      "train loss:0.05075432793059005\n",
      "train loss:0.0394240036890135\n",
      "train loss:0.007363229753682925\n",
      "train loss:0.017984077456152398\n",
      "train loss:0.01908642047483811\n",
      "train loss:0.0436431261576281\n",
      "train loss:0.008034863894153367\n",
      "train loss:0.050275365119840335\n",
      "train loss:0.007136081044702227\n",
      "train loss:0.007155106433716089\n",
      "train loss:0.02089264716638718\n",
      "train loss:0.035150711601789834\n",
      "train loss:0.056023558022535454\n",
      "train loss:0.024849230568625296\n",
      "train loss:0.008523836596198844\n",
      "train loss:0.034730753771116236\n",
      "train loss:0.049973086233934864\n",
      "train loss:0.033029416157256256\n",
      "train loss:0.06159857078024274\n",
      "train loss:0.12438606919728944\n",
      "train loss:0.014437060901401066\n",
      "train loss:0.019985669531245812\n",
      "train loss:0.006689781938324161\n",
      "train loss:0.03567433627732666\n",
      "train loss:0.058834799113456925\n",
      "train loss:0.03643785608162879\n",
      "train loss:0.007347195484332116\n",
      "train loss:0.02982847779808229\n",
      "train loss:0.00856395223753727\n",
      "train loss:0.034332044324769447\n",
      "train loss:0.012846653483882628\n",
      "train loss:0.07363639842573674\n",
      "train loss:0.024337785496054583\n",
      "train loss:0.032369109535914244\n",
      "train loss:0.015039008048771531\n",
      "train loss:0.01583481673006006\n",
      "train loss:0.02470019923906857\n",
      "train loss:0.02221243081734776\n",
      "train loss:0.09073786801562189\n",
      "train loss:0.01714212812635663\n",
      "train loss:0.04495246149538445\n",
      "train loss:0.01696702087909249\n",
      "train loss:0.026511404123444948\n",
      "train loss:0.022455335056504072\n",
      "train loss:0.016030518896071735\n",
      "train loss:0.024366162983508098\n",
      "train loss:0.014546586742358638\n",
      "train loss:0.05434940836419564\n",
      "train loss:0.0061842392573310265\n",
      "train loss:0.023071439324568656\n",
      "train loss:0.008460532820328125\n",
      "train loss:0.05124679070193527\n",
      "train loss:0.05608737221166533\n",
      "train loss:0.02708103118925184\n",
      "train loss:0.04919006390310487\n",
      "train loss:0.02861367099094626\n",
      "train loss:0.06494596603885261\n",
      "train loss:0.015684012788613054\n",
      "train loss:0.01828665631521574\n",
      "train loss:0.02405232618949492\n",
      "train loss:0.015829094404265213\n",
      "train loss:0.021003477151565152\n",
      "train loss:0.03285334025257133\n",
      "train loss:0.06316566822551833\n",
      "train loss:0.06406720287167933\n",
      "train loss:0.010496993902657133\n",
      "train loss:0.030476411667009942\n",
      "train loss:0.03110952637427793\n",
      "train loss:0.022117837535015884\n",
      "train loss:0.0326031446608449\n",
      "train loss:0.008833629780299761\n",
      "train loss:0.010347661202042956\n",
      "train loss:0.06231054649989916\n",
      "train loss:0.04290810998713988\n",
      "train loss:0.058828511162638784\n",
      "train loss:0.03278452777946774\n",
      "train loss:0.025974826318628373\n",
      "train loss:0.017791019063494815\n",
      "train loss:0.01128444714517562\n",
      "train loss:0.06163675356008493\n",
      "train loss:0.074633622429908\n",
      "train loss:0.020675497143084726\n",
      "train loss:0.02056194747135317\n",
      "train loss:0.03884532543703538\n",
      "train loss:0.006366018024886527\n",
      "train loss:0.04888309085023119\n",
      "train loss:0.01640443423424255\n",
      "train loss:0.018976985278002314\n",
      "train loss:0.01809085703988854\n",
      "train loss:0.05679363155535229\n",
      "train loss:0.040588143580093355\n",
      "train loss:0.04065084007898693\n",
      "train loss:0.02376040754641546\n",
      "train loss:0.049276194080711405\n",
      "train loss:0.06591997513205224\n",
      "train loss:0.03341943906280031\n",
      "train loss:0.09304763615586731\n",
      "train loss:0.020943905522975915\n",
      "train loss:0.018205276194767212\n",
      "train loss:0.02041882406819345\n",
      "train loss:0.02319317795172834\n",
      "train loss:0.01897639104996023\n",
      "train loss:0.020469020588278423\n",
      "train loss:0.0377223532889123\n",
      "train loss:0.05085432173737825\n",
      "train loss:0.004915074657977635\n",
      "train loss:0.02418460154938361\n",
      "train loss:0.04959405094190949\n",
      "train loss:0.03224072461043517\n",
      "train loss:0.03752280468196071\n",
      "train loss:0.08111774611712319\n",
      "train loss:0.0342834526294026\n",
      "train loss:0.06304391823300123\n",
      "train loss:0.019959906594398048\n",
      "train loss:0.030113496972947695\n",
      "train loss:0.013694335591988344\n",
      "train loss:0.013522292104088514\n",
      "train loss:0.03126940894993575\n",
      "train loss:0.05317426379511453\n",
      "train loss:0.03740804513656016\n",
      "train loss:0.030103166115066405\n",
      "train loss:0.04896041088627611\n",
      "train loss:0.015369768075226737\n",
      "train loss:0.05260625574915363\n",
      "train loss:0.011831245149171015\n",
      "train loss:0.05172588189956111\n",
      "train loss:0.008316640908152331\n",
      "train loss:0.09167584332552117\n",
      "train loss:0.02290261517810444\n",
      "train loss:0.028651262775510423\n",
      "train loss:0.010776208581590133\n",
      "train loss:0.047963206542954696\n",
      "train loss:0.024569315229799583\n",
      "train loss:0.0044879512975572414\n",
      "train loss:0.007515567164369476\n",
      "train loss:0.014659374131443692\n",
      "train loss:0.012045219033154406\n",
      "train loss:0.019913251177422243\n",
      "train loss:0.03853480348477701\n",
      "train loss:0.022904327187617975\n",
      "train loss:0.026976976454132502\n",
      "train loss:0.032870654949324986\n",
      "train loss:0.028386578050929798\n",
      "train loss:0.06510364087878412\n",
      "train loss:0.02801919176965967\n",
      "train loss:0.011924461311094967\n",
      "train loss:0.04881149131956073\n",
      "train loss:0.011494068743141884\n",
      "train loss:0.05910024703797521\n",
      "train loss:0.006334463911362053\n",
      "train loss:0.015285681868296278\n",
      "train loss:0.04432114577684045\n",
      "train loss:0.09459019688821732\n",
      "train loss:0.01376588500621603\n",
      "train loss:0.020060528585806713\n",
      "train loss:0.06303014810229467\n",
      "train loss:0.03295380230041283\n",
      "train loss:0.0081745230639449\n",
      "train loss:0.021575625502477526\n",
      "train loss:0.01281403303308188\n",
      "train loss:0.0056027907300735804\n",
      "train loss:0.009687467537381696\n",
      "train loss:0.045506635321932803\n",
      "train loss:0.02071901973060162\n",
      "train loss:0.015574998758927459\n",
      "train loss:0.024276300837119482\n",
      "train loss:0.060611115740263566\n",
      "train loss:0.011316072701786943\n",
      "train loss:0.10043516221925669\n",
      "train loss:0.0587321130399071\n",
      "train loss:0.01134457199279834\n",
      "train loss:0.02959000173676217\n",
      "train loss:0.006094784162286338\n",
      "train loss:0.021055376713839027\n",
      "train loss:0.09368365112470597\n",
      "train loss:0.02350775938122712\n",
      "train loss:0.008349663828137422\n",
      "train loss:0.01901316044841419\n",
      "train loss:0.021269662553219573\n",
      "train loss:0.007611923123358546\n",
      "train loss:0.026815378075982124\n",
      "train loss:0.06374669095732743\n",
      "train loss:0.06176989779580217\n",
      "train loss:0.016854347822040937\n",
      "train loss:0.01436806395530245\n",
      "train loss:0.020183083141038546\n",
      "train loss:0.19367884352665643\n",
      "train loss:0.05591931416482948\n",
      "train loss:0.04648039503244392\n",
      "train loss:0.02813619215606854\n",
      "train loss:0.040758240970198846\n",
      "train loss:0.012370000654976041\n",
      "train loss:0.030930941301391957\n",
      "train loss:0.023049629055790496\n",
      "train loss:0.025262351825533137\n",
      "train loss:0.04930132007164869\n",
      "train loss:0.010683747900712826\n",
      "train loss:0.008083580589582641\n",
      "train loss:0.031236837628889753\n",
      "train loss:0.032453706782472634\n",
      "train loss:0.03295648615354495\n",
      "train loss:0.04445563277799989\n",
      "train loss:0.03306145876687616\n",
      "train loss:0.019696117590774567\n",
      "train loss:0.08044869066525015\n",
      "train loss:0.006677162655539165\n",
      "train loss:0.032326276577935575\n",
      "train loss:0.07452661247793965\n",
      "train loss:0.042272413760435786\n",
      "train loss:0.004225542057299961\n",
      "train loss:0.01879759067883625\n",
      "train loss:0.0440129091299535\n",
      "train loss:0.010327095495547065\n",
      "train loss:0.03391031476973428\n",
      "train loss:0.009476790480940288\n",
      "train loss:0.027895221987371065\n",
      "train loss:0.01564073114261609\n",
      "train loss:0.019252675963977308\n",
      "train loss:0.014278710300217056\n",
      "train loss:0.013685837250982713\n",
      "train loss:0.08645660178487033\n",
      "train loss:0.022301740142243353\n",
      "train loss:0.025632339774828913\n",
      "train loss:0.03432508038173161\n",
      "train loss:0.005324334245114398\n",
      "train loss:0.04614503924532251\n",
      "train loss:0.01939806986479932\n",
      "train loss:0.08888234023453082\n",
      "train loss:0.006202503321569921\n",
      "train loss:0.03611892286412032\n",
      "train loss:0.010494059746657888\n",
      "train loss:0.005227522869275183\n",
      "train loss:0.012463946036099434\n",
      "train loss:0.008630745405013199\n",
      "train loss:0.048456198795870264\n",
      "train loss:0.012428967240121427\n",
      "train loss:0.030467404629021106\n",
      "train loss:0.024260738492898448\n",
      "train loss:0.014096052312790397\n",
      "train loss:0.028003678073630123\n",
      "train loss:0.010072608486739848\n",
      "train loss:0.0350839575058693\n",
      "train loss:0.01470986120399737\n",
      "train loss:0.01946954430984978\n",
      "train loss:0.032395563877091804\n",
      "train loss:0.01445403796564921\n",
      "train loss:0.010368278514480961\n",
      "train loss:0.0068184263069492905\n",
      "train loss:0.04596822762699625\n",
      "train loss:0.018531131245105577\n",
      "train loss:0.03177506809119377\n",
      "train loss:0.006474936103738528\n",
      "train loss:0.013812860577821271\n",
      "train loss:0.06219067614084976\n",
      "train loss:0.01883999400220082\n",
      "train loss:0.04050841517877475\n",
      "train loss:0.015422407352676519\n",
      "train loss:0.045199083651593155\n",
      "train loss:0.014220767325542427\n",
      "train loss:0.0057348611866071975\n",
      "train loss:0.06148746028737133\n",
      "train loss:0.02406038638750395\n",
      "train loss:0.008542968396023315\n",
      "train loss:0.01468046537383735\n",
      "train loss:0.007563512133638048\n",
      "train loss:0.0027558429869184477\n",
      "train loss:0.0685378999290839\n",
      "train loss:0.022745104558471542\n",
      "train loss:0.013428075797042426\n",
      "train loss:0.01222577190917729\n",
      "train loss:0.03483549540298844\n",
      "train loss:0.019203855706728487\n",
      "train loss:0.01820080297168304\n",
      "train loss:0.025855650744144035\n",
      "train loss:0.034807349459854225\n",
      "train loss:0.006984451809250736\n",
      "train loss:0.0199370068524277\n",
      "train loss:0.012026862554498481\n",
      "train loss:0.06821325213305383\n",
      "train loss:0.008440441818549756\n",
      "train loss:0.010857017399094775\n",
      "train loss:0.010783634720197343\n",
      "train loss:0.008732564581807682\n",
      "train loss:0.009300797167315146\n",
      "train loss:0.023250251803151295\n",
      "train loss:0.05899711100103465\n",
      "train loss:0.009314278461251761\n",
      "train loss:0.04473230775669033\n",
      "train loss:0.03842729020829037\n",
      "train loss:0.01471863166265968\n",
      "train loss:0.11923744485069344\n",
      "train loss:0.013992811626407009\n",
      "train loss:0.029498983212619744\n",
      "train loss:0.12945712503828044\n",
      "train loss:0.01257258680804857\n",
      "train loss:0.007104353715471805\n",
      "train loss:0.03425928575147849\n",
      "train loss:0.03514258441915028\n",
      "train loss:0.034117715547810054\n",
      "train loss:0.038262544559356425\n",
      "train loss:0.018882596883343837\n",
      "train loss:0.008707073812016677\n",
      "train loss:0.01224900089884317\n",
      "train loss:0.040316384960001346\n",
      "train loss:0.09625588161757098\n",
      "train loss:0.02135797838947457\n",
      "train loss:0.05093588541355326\n",
      "train loss:0.03937163062290056\n",
      "train loss:0.01650873388759309\n",
      "train loss:0.010054430105932998\n",
      "train loss:0.03356337680720403\n",
      "train loss:0.03627291100377537\n",
      "train loss:0.015555244770277503\n",
      "train loss:0.01515000948375231\n",
      "train loss:0.017648575311192155\n",
      "train loss:0.022861687364038697\n",
      "train loss:0.03862969631125193\n",
      "train loss:0.022083231018955797\n",
      "train loss:0.02590981836399363\n",
      "train loss:0.01085371086079804\n",
      "train loss:0.03603170966222277\n",
      "train loss:0.030448313866279556\n",
      "train loss:0.041260518309171344\n",
      "train loss:0.05597836076036512\n",
      "train loss:0.007546659458122578\n",
      "train loss:0.027028771065250225\n",
      "train loss:0.006804905780776232\n",
      "train loss:0.05264925359036836\n",
      "train loss:0.011726015438920087\n",
      "train loss:0.014961520358250872\n",
      "train loss:0.03182668155749163\n",
      "train loss:0.015943155235223473\n",
      "train loss:0.027304611943131163\n",
      "train loss:0.04541609228213577\n",
      "train loss:0.017777325423655347\n",
      "train loss:0.05994094746605755\n",
      "train loss:0.07400324159943464\n",
      "train loss:0.05241420260018312\n",
      "train loss:0.10563308298241042\n",
      "train loss:0.01985197866274665\n",
      "train loss:0.009693135373186602\n",
      "train loss:0.04313862285684472\n",
      "train loss:0.04063792713054661\n",
      "train loss:0.029586162833769195\n",
      "train loss:0.015758266158437527\n",
      "train loss:0.014512503055336745\n",
      "train loss:0.033007978170542615\n",
      "train loss:0.029402808134891063\n",
      "train loss:0.003700445415521219\n",
      "train loss:0.03788405062373538\n",
      "train loss:0.017207993113275095\n",
      "train loss:0.030865677950931834\n",
      "train loss:0.025585371901467327\n",
      "train loss:0.014804953212613608\n",
      "train loss:0.004799343900803948\n",
      "train loss:0.012152400511873662\n",
      "train loss:0.08977068585323116\n",
      "train loss:0.039497331721294306\n",
      "train loss:0.009072856899048241\n",
      "train loss:0.01616682352177002\n",
      "train loss:0.02660999743361657\n",
      "train loss:0.018980433673716865\n",
      "train loss:0.01413477808353318\n",
      "train loss:0.01092755384963928\n",
      "train loss:0.020893123500992837\n",
      "train loss:0.04790328691623094\n",
      "train loss:0.025404293907123208\n",
      "train loss:0.04826330034919673\n",
      "train loss:0.018666117555111838\n",
      "train loss:0.009767674633368507\n",
      "train loss:0.04838247237355291\n",
      "train loss:0.009429376223707969\n",
      "train loss:0.016025556403988162\n",
      "train loss:0.04207229694263231\n",
      "train loss:0.018708545717099904\n",
      "train loss:0.018905003690490293\n",
      "train loss:0.029742501393412404\n",
      "train loss:0.026735901747469273\n",
      "train loss:0.040215821935081386\n",
      "train loss:0.020180098344985388\n",
      "train loss:0.04796204894256921\n",
      "train loss:0.007220060187354005\n",
      "train loss:0.015172664357391548\n",
      "train loss:0.013419391224468882\n",
      "train loss:0.07348401613845529\n",
      "train loss:0.04780146026620507\n",
      "train loss:0.026041915436656893\n",
      "train loss:0.042074162117342544\n",
      "train loss:0.01669519435735155\n",
      "train loss:0.021364033349000323\n",
      "train loss:0.01409114427396712\n",
      "train loss:0.027972256761567366\n",
      "train loss:0.006015948496954974\n",
      "train loss:0.005367622729203338\n",
      "train loss:0.030123010846444045\n",
      "train loss:0.08676883942295262\n",
      "train loss:0.010379107190262684\n",
      "train loss:0.0038633796938310917\n",
      "train loss:0.006903969402264566\n",
      "train loss:0.05515262542983344\n",
      "train loss:0.0061319889861552335\n",
      "train loss:0.02082528918433415\n",
      "train loss:0.04882749227655919\n",
      "train loss:0.01913261396911142\n",
      "train loss:0.01479657650305584\n",
      "train loss:0.028120438613477954\n",
      "train loss:0.02255201311921713\n",
      "train loss:0.04007901705183151\n",
      "train loss:0.007304244063413151\n",
      "train loss:0.035429666974941786\n",
      "train loss:0.035778194791898026\n",
      "train loss:0.01988103379353686\n",
      "train loss:0.01787950069666967\n",
      "train loss:0.030189914171597595\n",
      "train loss:0.015564627640296097\n",
      "train loss:0.01621751915475693\n",
      "train loss:0.01980686793437407\n",
      "train loss:0.004618765151110427\n",
      "train loss:0.04569149537791871\n",
      "train loss:0.015425422134392526\n",
      "train loss:0.03497976594021176\n",
      "train loss:0.005432008721175365\n",
      "train loss:0.002516001689647954\n",
      "train loss:0.004670243859459198\n",
      "train loss:0.014469766832494704\n",
      "train loss:0.043848353626374924\n",
      "train loss:0.010136871478547735\n",
      "train loss:0.014790100090901868\n",
      "train loss:0.06102494206248449\n",
      "train loss:0.006661894402904097\n",
      "train loss:0.020266150307330102\n",
      "train loss:0.015234858261418224\n",
      "train loss:0.005253652474725378\n",
      "train loss:0.01092258249289471\n",
      "train loss:0.024896877410342747\n",
      "train loss:0.00900462840280926\n",
      "train loss:0.023145449763908452\n",
      "train loss:0.01846559454935251\n",
      "train loss:0.0411933485289018\n",
      "train loss:0.017226922274295012\n",
      "train loss:0.0075441435545413795\n",
      "train loss:0.05058146984008412\n",
      "train loss:0.03235548829393627\n",
      "train loss:0.022930995556808297\n",
      "train loss:0.01778212637756752\n",
      "train loss:0.015804460812574698\n",
      "train loss:0.02069616001668495\n",
      "train loss:0.010443085531928582\n",
      "train loss:0.012473269392444222\n",
      "train loss:0.014613739603267306\n",
      "train loss:0.007773673316635303\n",
      "train loss:0.0057912497943949405\n",
      "train loss:0.029561706553183974\n",
      "train loss:0.029613759534888554\n",
      "train loss:0.011524157594654489\n",
      "train loss:0.003549464946597735\n",
      "train loss:0.023042060951026403\n",
      "train loss:0.020325171671893363\n",
      "train loss:0.07171924368132186\n",
      "train loss:0.01734435565319859\n",
      "train loss:0.008924174942976036\n",
      "train loss:0.057831354104832935\n",
      "train loss:0.008825576742414725\n",
      "train loss:0.02646335634774426\n",
      "train loss:0.03194371872121834\n",
      "train loss:0.08676237415366868\n",
      "train loss:0.017428433554020475\n",
      "train loss:0.022481561413536993\n",
      "train loss:0.043867316803603985\n",
      "train loss:0.007602607885961773\n",
      "train loss:0.008891820775661705\n",
      "train loss:0.0021309345557106083\n",
      "train loss:0.013257389429342688\n",
      "train loss:0.014797584447702232\n",
      "train loss:0.0140916355814726\n",
      "train loss:0.037958437291506074\n",
      "train loss:0.007311202377001503\n",
      "train loss:0.017469003685083587\n",
      "train loss:0.04191227474412209\n",
      "train loss:0.015532322368289306\n",
      "train loss:0.008309608069698842\n",
      "train loss:0.00628473980761721\n",
      "train loss:0.010222630045711237\n",
      "train loss:0.02150761369336542\n",
      "train loss:0.010196322489039013\n",
      "train loss:0.0042724336979584245\n",
      "train loss:0.009288758502936523\n",
      "train loss:0.006941147790598002\n",
      "train loss:0.008486642208134144\n",
      "train loss:0.022713117327408005\n",
      "train loss:0.016655844441147857\n",
      "train loss:0.008485840122714312\n",
      "train loss:0.02228865367056589\n",
      "train loss:0.011442349925669506\n",
      "train loss:0.020647059027424128\n",
      "train loss:0.020696260490266988\n",
      "train loss:0.014359781025382903\n",
      "train loss:0.011877860942355045\n",
      "train loss:0.05776462263278491\n",
      "train loss:0.00723258117167372\n",
      "train loss:0.04553491505634199\n",
      "train loss:0.11341737787268427\n",
      "train loss:0.012878643718910938\n",
      "train loss:0.021061906327942737\n",
      "train loss:0.007880098131403692\n",
      "train loss:0.024204761971317258\n",
      "train loss:0.006558374341708914\n",
      "train loss:0.011949665023196696\n",
      "train loss:0.00981723706870218\n",
      "train loss:0.06443813348495415\n",
      "train loss:0.025952633367941066\n",
      "train loss:0.042143896017742814\n",
      "train loss:0.006113918332447293\n",
      "train loss:0.06070675323966123\n",
      "train loss:0.011289380036333596\n",
      "train loss:0.024308504416544436\n",
      "train loss:0.02365753999476956\n",
      "train loss:0.02344144796636406\n",
      "train loss:0.03422356586034058\n",
      "train loss:0.06473246710806713\n",
      "train loss:0.008182401895498053\n",
      "train loss:0.02814410015093399\n",
      "train loss:0.014258188270991306\n",
      "train loss:0.01505742472593394\n",
      "train loss:0.026010012041165407\n",
      "train loss:0.007171226791087251\n",
      "train loss:0.03952971444593168\n",
      "train loss:0.03718896729493544\n",
      "train loss:0.021698574046132263\n",
      "train loss:0.019719164088259588\n",
      "train loss:0.03320931284707398\n",
      "train loss:0.009915884074827977\n",
      "train loss:0.08069566143687039\n",
      "train loss:0.018886423259869264\n",
      "train loss:0.009926243557646711\n",
      "train loss:0.025552460127468556\n",
      "=== epoch:6, train acc:0.987, test acc:0.986 ===\n",
      "train loss:0.04084370190909128\n",
      "train loss:0.027373598137227298\n",
      "train loss:0.009204623280315233\n",
      "train loss:0.005605349638113869\n",
      "train loss:0.054136601940416404\n",
      "train loss:0.0522820323357928\n",
      "train loss:0.00939429017939324\n",
      "train loss:0.0157002507713598\n",
      "train loss:0.01581439195552903\n",
      "train loss:0.006404749849222155\n",
      "train loss:0.009369544959922226\n",
      "train loss:0.012066793606449222\n",
      "train loss:0.01230131475979273\n",
      "train loss:0.016895893053541958\n",
      "train loss:0.03308840182895975\n",
      "train loss:0.012081025711817895\n",
      "train loss:0.011211635389044537\n",
      "train loss:0.027545707839351553\n",
      "train loss:0.022563141746941514\n",
      "train loss:0.012278612570447552\n",
      "train loss:0.0952842735422761\n",
      "train loss:0.024526108097830866\n",
      "train loss:0.03590174961890868\n",
      "train loss:0.007309388204946493\n",
      "train loss:0.013358521045875583\n",
      "train loss:0.0064638279555129284\n",
      "train loss:0.042559625763990576\n",
      "train loss:0.014271642878784288\n",
      "train loss:0.030228309288224273\n",
      "train loss:0.012978294331261646\n",
      "train loss:0.0026099337722413633\n",
      "train loss:0.009954345421560729\n",
      "train loss:0.048264250492817365\n",
      "train loss:0.009433128085924405\n",
      "train loss:0.07959891831712863\n",
      "train loss:0.004549360875544964\n",
      "train loss:0.017087320391394722\n",
      "train loss:0.006526850829510803\n",
      "train loss:0.0045965212222051684\n",
      "train loss:0.00904379697492012\n",
      "train loss:0.006458500293343216\n",
      "train loss:0.0049435478965227705\n",
      "train loss:0.02495084709652205\n",
      "train loss:0.0228346815370457\n",
      "train loss:0.04563765738422119\n",
      "train loss:0.00763951924069253\n",
      "train loss:0.03467797344567503\n",
      "train loss:0.03788463902863978\n",
      "train loss:0.03356694209569063\n",
      "train loss:0.02264840261173292\n",
      "train loss:0.010814624330329934\n",
      "train loss:0.010412586476898283\n",
      "train loss:0.009034308458821604\n",
      "train loss:0.006762877910296414\n",
      "train loss:0.04782584156388378\n",
      "train loss:0.01316741390014118\n",
      "train loss:0.03254266717223816\n",
      "train loss:0.04952698553081422\n",
      "train loss:0.011239303442000526\n",
      "train loss:0.022975344365228145\n",
      "train loss:0.059314649412670735\n",
      "train loss:0.006460909320974166\n",
      "train loss:0.017541283239141364\n",
      "train loss:0.04650835465947645\n",
      "train loss:0.012679261296476873\n",
      "train loss:0.016767933804270607\n",
      "train loss:0.0056227646313118385\n",
      "train loss:0.004614584734972357\n",
      "train loss:0.04122548722974186\n",
      "train loss:0.014628033376669845\n",
      "train loss:0.039329855985566736\n",
      "train loss:0.016957010908856825\n",
      "train loss:0.041785457071202015\n",
      "train loss:0.030269110522130063\n",
      "train loss:0.006166886866790141\n",
      "train loss:0.007888221572194565\n",
      "train loss:0.00707214914877507\n",
      "train loss:0.04866480490181239\n",
      "train loss:0.03113236851097979\n",
      "train loss:0.06597621778180193\n",
      "train loss:0.018074660473638902\n",
      "train loss:0.03844631231776448\n",
      "train loss:0.007756278269567707\n",
      "train loss:0.014063751164132499\n",
      "train loss:0.005838944097539075\n",
      "train loss:0.00549837377509754\n",
      "train loss:0.037835960109713455\n",
      "train loss:0.023891096945963638\n",
      "train loss:0.044137969674781896\n",
      "train loss:0.017925293036608263\n",
      "train loss:0.013171146182948316\n",
      "train loss:0.067817712804737\n",
      "train loss:0.05524424645435953\n",
      "train loss:0.023880587983931455\n",
      "train loss:0.030290733657404506\n",
      "train loss:0.019429637557869653\n",
      "train loss:0.08497635661407285\n",
      "train loss:0.04097528600017383\n",
      "train loss:0.03961697634103392\n",
      "train loss:0.00815717501223988\n",
      "train loss:0.021235974172704394\n",
      "train loss:0.013010740183214435\n",
      "train loss:0.009866336948119407\n",
      "train loss:0.006283401392743519\n",
      "train loss:0.006889287723771187\n",
      "train loss:0.01722125186976364\n",
      "train loss:0.008409563635573358\n",
      "train loss:0.05517774346769488\n",
      "train loss:0.025845349912775796\n",
      "train loss:0.023188723850323906\n",
      "train loss:0.005062261772820681\n",
      "train loss:0.02773448498367445\n",
      "train loss:0.1271419447255703\n",
      "train loss:0.008003113511784348\n",
      "train loss:0.041927690087926975\n",
      "train loss:0.004126392209573107\n",
      "train loss:0.04662530191864582\n",
      "train loss:0.014358113146553147\n",
      "train loss:0.009984684029575641\n",
      "train loss:0.02789053085786946\n",
      "train loss:0.019914188074322256\n",
      "train loss:0.02276997594203956\n",
      "train loss:0.040999501099721565\n",
      "train loss:0.019267828757338047\n",
      "train loss:0.023207658715534117\n",
      "train loss:0.027955266739507087\n",
      "train loss:0.010119113281353027\n",
      "train loss:0.01588506901719616\n",
      "train loss:0.025081182136532754\n",
      "train loss:0.018357315133498916\n",
      "train loss:0.018912559699799335\n",
      "train loss:0.021695013521675202\n",
      "train loss:0.024681122678792106\n",
      "train loss:0.012567240311762415\n",
      "train loss:0.013665015122728335\n",
      "train loss:0.011584253987999725\n",
      "train loss:0.026865036670210916\n",
      "train loss:0.03330832031742825\n",
      "train loss:0.015217378293331797\n",
      "train loss:0.03676199294863501\n",
      "train loss:0.01249986810361322\n",
      "train loss:0.12265888768993591\n",
      "train loss:0.014746660300475351\n",
      "train loss:0.046013625604473016\n",
      "train loss:0.011496636985855018\n",
      "train loss:0.010955063993692227\n",
      "train loss:0.03196804108240477\n",
      "train loss:0.015554001686590936\n",
      "train loss:0.02784131792526843\n",
      "train loss:0.08427529811260545\n",
      "train loss:0.05090096943941303\n",
      "train loss:0.021798903456395742\n",
      "train loss:0.004418932298808331\n",
      "train loss:0.030403250988929275\n",
      "train loss:0.019430834476300975\n",
      "train loss:0.07294045133373336\n",
      "train loss:0.023940381894061176\n",
      "train loss:0.01978543652770841\n",
      "train loss:0.020629092993499118\n",
      "train loss:0.016757492394016617\n",
      "train loss:0.0033255799235307306\n",
      "train loss:0.04661193184709173\n",
      "train loss:0.029591854559020546\n",
      "train loss:0.049134729088002496\n",
      "train loss:0.04865506901862384\n",
      "train loss:0.06449907231580682\n",
      "train loss:0.010273894720293705\n",
      "train loss:0.014373346621107381\n",
      "train loss:0.014347684411681428\n",
      "train loss:0.04091132180044352\n",
      "train loss:0.014717173084385275\n",
      "train loss:0.04783503304136879\n",
      "train loss:0.007081250326520651\n",
      "train loss:0.009701995564969892\n",
      "train loss:0.01380245129341261\n",
      "train loss:0.015417326193853768\n",
      "train loss:0.015689693843020228\n",
      "train loss:0.04762071304705962\n",
      "train loss:0.07565027641722563\n",
      "train loss:0.01903831070054531\n",
      "train loss:0.015931466397766596\n",
      "train loss:0.02334810545677977\n",
      "train loss:0.07733409750523083\n",
      "train loss:0.11524335585547246\n",
      "train loss:0.037162261690996706\n",
      "train loss:0.009601994168583039\n",
      "train loss:0.035364285260040124\n",
      "train loss:0.024027358527801995\n",
      "train loss:0.012697703592210981\n",
      "train loss:0.029617744957221935\n",
      "train loss:0.02887338604879179\n",
      "train loss:0.04267353297299423\n",
      "train loss:0.012301105451169542\n",
      "train loss:0.01512690993059495\n",
      "train loss:0.0073907117124527456\n",
      "train loss:0.027895219670435956\n",
      "train loss:0.0174352442082689\n",
      "train loss:0.008648421187469358\n",
      "train loss:0.00610017160889173\n",
      "train loss:0.004281120585734754\n",
      "train loss:0.050823795470115625\n",
      "train loss:0.018807019831044224\n",
      "train loss:0.008607245849851513\n",
      "train loss:0.09496216677967706\n",
      "train loss:0.019599074348309497\n",
      "train loss:0.015475333934384126\n",
      "train loss:0.00523122020354783\n",
      "train loss:0.01428686215066882\n",
      "train loss:0.01812008030756584\n",
      "train loss:0.1568329751229187\n",
      "train loss:0.015668221688783304\n",
      "train loss:0.014828857013069146\n",
      "train loss:0.011347102173074235\n",
      "train loss:0.037533115570582254\n",
      "train loss:0.01251286173099982\n",
      "train loss:0.027550987733818\n",
      "train loss:0.034786050691451284\n",
      "train loss:0.02116592721927483\n",
      "train loss:0.06745390776917815\n",
      "train loss:0.026794121002948246\n",
      "train loss:0.04936557697006272\n",
      "train loss:0.04582560681748446\n",
      "train loss:0.0787151878078698\n",
      "train loss:0.01780066366534229\n",
      "train loss:0.08499509970942162\n",
      "train loss:0.018492345568521095\n",
      "train loss:0.008165447582396818\n",
      "train loss:0.03974420658410049\n",
      "train loss:0.009589152461037073\n",
      "train loss:0.03214666250800724\n",
      "train loss:0.025941387885303962\n",
      "train loss:0.029873735783450296\n",
      "train loss:0.02222861276373516\n",
      "train loss:0.038895185070649874\n",
      "train loss:0.03248510802797242\n",
      "train loss:0.023641547184424763\n",
      "train loss:0.009688306998049618\n",
      "train loss:0.020753207139593582\n",
      "train loss:0.028320367730241065\n",
      "train loss:0.038764791313798536\n",
      "train loss:0.011763829627782845\n",
      "train loss:0.00947115433111747\n",
      "train loss:0.01678637239403438\n",
      "train loss:0.02229553898022553\n",
      "train loss:0.09023426239699774\n",
      "train loss:0.01761449396670787\n",
      "train loss:0.006927514988031351\n",
      "train loss:0.03336598900092443\n",
      "train loss:0.008192157987400672\n",
      "train loss:0.009101931538649884\n",
      "train loss:0.022962553960834277\n",
      "train loss:0.0035687078173134495\n",
      "train loss:0.00846893350877266\n",
      "train loss:0.013445378950235416\n",
      "train loss:0.006641111074784735\n",
      "train loss:0.008707650383166708\n",
      "train loss:0.01148513993450778\n",
      "train loss:0.0410714580151993\n",
      "train loss:0.005801670568674611\n",
      "train loss:0.019236564957114847\n",
      "train loss:0.007263516733836141\n",
      "train loss:0.04282593840850219\n",
      "train loss:0.025052076671752178\n",
      "train loss:0.023526643271924764\n",
      "train loss:0.022276578130880475\n",
      "train loss:0.02220907720149295\n",
      "train loss:0.007839746811651773\n",
      "train loss:0.011335617869193886\n",
      "train loss:0.10853781617048018\n",
      "train loss:0.020742669904496847\n",
      "train loss:0.0087367297776561\n",
      "train loss:0.051279259391669836\n",
      "train loss:0.05638145126355279\n",
      "train loss:0.0062159009129504625\n",
      "train loss:0.0056344227585211175\n",
      "train loss:0.0397770654048707\n",
      "train loss:0.02426273473874923\n",
      "train loss:0.00652447685123605\n",
      "train loss:0.019743843520427132\n",
      "train loss:0.026328685891517885\n",
      "train loss:0.0178895163653435\n",
      "train loss:0.0333809819202413\n",
      "train loss:0.007315087176439376\n",
      "train loss:0.01464594452600511\n",
      "train loss:0.027029393981659832\n",
      "train loss:0.03499735563033309\n",
      "train loss:0.0031295859888929483\n",
      "train loss:0.08572431733232352\n",
      "train loss:0.00517993302299878\n",
      "train loss:0.02972045547087245\n",
      "train loss:0.003492473218124778\n",
      "train loss:0.02493279687702253\n",
      "train loss:0.03942967945415758\n",
      "train loss:0.017880975916511898\n",
      "train loss:0.024575278395180356\n",
      "train loss:0.05993483290953835\n",
      "train loss:0.006369453836012789\n",
      "train loss:0.017599651041271012\n",
      "train loss:0.04541219672135655\n",
      "train loss:0.03498253129560383\n",
      "train loss:0.07537383853985204\n",
      "train loss:0.011192430817654208\n",
      "train loss:0.04258807664144151\n",
      "train loss:0.01764449868849304\n",
      "train loss:0.04190394052967279\n",
      "train loss:0.015292254040248978\n",
      "train loss:0.01991168585388055\n",
      "train loss:0.02447938559193181\n",
      "train loss:0.005770350218530034\n",
      "train loss:0.049952973116463406\n",
      "train loss:0.0035764070444952094\n",
      "train loss:0.01611637236722083\n",
      "train loss:0.023122666076486494\n",
      "train loss:0.02112003100011488\n",
      "train loss:0.003880478573169182\n",
      "train loss:0.0036556445020029882\n",
      "train loss:0.004269395679438907\n",
      "train loss:0.07895420611387033\n",
      "train loss:0.009583529744304905\n",
      "train loss:0.014728940869313128\n",
      "train loss:0.01755676274042505\n",
      "train loss:0.016758201248675646\n",
      "train loss:0.02724352560598566\n",
      "train loss:0.051948172939659594\n",
      "train loss:0.010069680603671917\n",
      "train loss:0.0014886035443561825\n",
      "train loss:0.03729722731319802\n",
      "train loss:0.034916915782108995\n",
      "train loss:0.014610539600165442\n",
      "train loss:0.0229823862132096\n",
      "train loss:0.0050656293881212\n",
      "train loss:0.010450311444390339\n",
      "train loss:0.013636987088492775\n",
      "train loss:0.005667475733139594\n",
      "train loss:0.01383652199074186\n",
      "train loss:0.020025918071635722\n",
      "train loss:0.005364639027144366\n",
      "train loss:0.014022582547733649\n",
      "train loss:0.003951496396175382\n",
      "train loss:0.01635764504080236\n",
      "train loss:0.06444975534466155\n",
      "train loss:0.003370046642966805\n",
      "train loss:0.05316587354086092\n",
      "train loss:0.0022171161305398392\n",
      "train loss:0.02664105454775002\n",
      "train loss:0.023443181656241346\n",
      "train loss:0.017558445163487542\n",
      "train loss:0.033394995685262885\n",
      "train loss:0.005694215852011863\n",
      "train loss:0.004850202586042388\n",
      "train loss:0.01745924683147193\n",
      "train loss:0.026836200958151472\n",
      "train loss:0.016587377014260718\n",
      "train loss:0.05425005479297336\n",
      "train loss:0.008333629489859776\n",
      "train loss:0.008918544082121374\n",
      "train loss:0.02098591070619208\n",
      "train loss:0.014307362260870234\n",
      "train loss:0.004436751027901985\n",
      "train loss:0.009705579624713684\n",
      "train loss:0.04057547035057456\n",
      "train loss:0.02270101127236467\n",
      "train loss:0.00436063675330132\n",
      "train loss:0.0053462735939538595\n",
      "train loss:0.03402188394114183\n",
      "train loss:0.014719885965671552\n",
      "train loss:0.02247914669729911\n",
      "train loss:0.00920631194280405\n",
      "train loss:0.02140679813293963\n",
      "train loss:0.02119733794829282\n",
      "train loss:0.024508557171629076\n",
      "train loss:0.0013300817846575472\n",
      "train loss:0.021095321112772614\n",
      "train loss:0.013436486853358172\n",
      "train loss:0.04999038449879282\n",
      "train loss:0.021872699724213525\n",
      "train loss:0.013246730385278875\n",
      "train loss:0.0128376234428382\n",
      "train loss:0.0017859490215353193\n",
      "train loss:0.021424547504312334\n",
      "train loss:0.02284653054027866\n",
      "train loss:0.01713743894625357\n",
      "train loss:0.01299002571064295\n",
      "train loss:0.012907957662542708\n",
      "train loss:0.01795011248973379\n",
      "train loss:0.06348666779354081\n",
      "train loss:0.0041509876885313345\n",
      "train loss:0.005197421422963637\n",
      "train loss:0.04668892785541156\n",
      "train loss:0.005880312877565062\n",
      "train loss:0.057071637049527564\n",
      "train loss:0.04973323351355337\n",
      "train loss:0.03719786621771831\n",
      "train loss:0.014240498714882074\n",
      "train loss:0.024125371655571323\n",
      "train loss:0.013386942407605169\n",
      "train loss:0.014366343440911054\n",
      "train loss:0.006819873098741055\n",
      "train loss:0.03360333938171298\n",
      "train loss:0.0020452950361283663\n",
      "train loss:0.028109598150158028\n",
      "train loss:0.0344477975632915\n",
      "train loss:0.023674277710628286\n",
      "train loss:0.020088128515821268\n",
      "train loss:0.0037046241916135515\n",
      "train loss:0.012363327667765775\n",
      "train loss:0.04029573301001542\n",
      "train loss:0.012866201975518785\n",
      "train loss:0.03185248640776754\n",
      "train loss:0.014137036407915355\n",
      "train loss:0.016333317863050038\n",
      "train loss:0.0365020568956326\n",
      "train loss:0.012747800929606923\n",
      "train loss:0.009865958261556994\n",
      "train loss:0.01167199780724347\n",
      "train loss:0.033541686173217844\n",
      "train loss:0.03644581140864532\n",
      "train loss:0.012768809860065074\n",
      "train loss:0.02110408542145456\n",
      "train loss:0.03748849876652301\n",
      "train loss:0.015062882723163664\n",
      "train loss:0.013354956938360401\n",
      "train loss:0.0351227301764707\n",
      "train loss:0.01217100571456359\n",
      "train loss:0.016108385150719842\n",
      "train loss:0.015245502241730878\n",
      "train loss:0.026256911601178955\n",
      "train loss:0.004326268537583312\n",
      "train loss:0.01216720239595682\n",
      "train loss:0.05952018206920091\n",
      "train loss:0.03897632543851275\n",
      "train loss:0.01691400679364833\n",
      "train loss:0.05176277375789501\n",
      "train loss:0.008771779180904169\n",
      "train loss:0.010468813598028627\n",
      "train loss:0.027701625967802786\n",
      "train loss:0.008889738646783975\n",
      "train loss:0.018748406226749198\n",
      "train loss:0.03432817744219621\n",
      "train loss:0.009982284696290384\n",
      "train loss:0.002066661436720919\n",
      "train loss:0.03349008905217536\n",
      "train loss:0.005269031839663937\n",
      "train loss:0.03444498280994637\n",
      "train loss:0.03147226172849946\n",
      "train loss:0.007629397648053708\n",
      "train loss:0.008351820406138256\n",
      "train loss:0.02279684103552736\n",
      "train loss:0.011623949956901115\n",
      "train loss:0.014357984908670088\n",
      "train loss:0.016942637380044995\n",
      "train loss:0.005119473909885693\n",
      "train loss:0.01585532438919864\n",
      "train loss:0.010787326550352742\n",
      "train loss:0.01063387705540058\n",
      "train loss:0.01960087330485375\n",
      "train loss:0.0012938698640330773\n",
      "train loss:0.011606497489121475\n",
      "train loss:0.06984518925858234\n",
      "train loss:0.021577838095402414\n",
      "train loss:0.029150537238071882\n",
      "train loss:0.010594299546898498\n",
      "train loss:0.04144987322539025\n",
      "train loss:0.005498186944085921\n",
      "train loss:0.04619332142215714\n",
      "train loss:0.033833318085839975\n",
      "train loss:0.006883496929836371\n",
      "train loss:0.007039679085640615\n",
      "train loss:0.010574462477333355\n",
      "train loss:0.0448371829294492\n",
      "train loss:0.09543426424132596\n",
      "train loss:0.01060132415002767\n",
      "train loss:0.010936886617478415\n",
      "train loss:0.04216323231108688\n",
      "train loss:0.023111675664766483\n",
      "train loss:0.0597815126947366\n",
      "train loss:0.007064896154417931\n",
      "train loss:0.013831603833837027\n",
      "train loss:0.017519877976293674\n",
      "train loss:0.016253640967513538\n",
      "train loss:0.002417480557826371\n",
      "train loss:0.012106109127644376\n",
      "train loss:0.016991354718326915\n",
      "train loss:0.012502512315473535\n",
      "train loss:0.02629260092340707\n",
      "train loss:0.017376204777863623\n",
      "train loss:0.006588679625680121\n",
      "train loss:0.024234242448314416\n",
      "train loss:0.03184326934796788\n",
      "train loss:0.018591301310319764\n",
      "train loss:0.03140460570871322\n",
      "train loss:0.02220987730085191\n",
      "train loss:0.009175921060039222\n",
      "train loss:0.009791502239495506\n",
      "train loss:0.0037352556395721563\n",
      "train loss:0.01367065254524815\n",
      "train loss:0.03347535095518038\n",
      "train loss:0.020186872744607672\n",
      "train loss:0.023786292581190697\n",
      "train loss:0.008175377506754806\n",
      "train loss:0.010243768342762232\n",
      "train loss:0.04067549630830384\n",
      "train loss:0.003721041080350361\n",
      "train loss:0.008425453028212381\n",
      "train loss:0.006746053110125669\n",
      "train loss:0.03256792358910872\n",
      "train loss:0.004264149834409748\n",
      "train loss:0.07372267248616964\n",
      "train loss:0.018905758382648786\n",
      "train loss:0.023369665671196364\n",
      "train loss:0.027917170370179777\n",
      "train loss:0.012123246238990448\n",
      "train loss:0.019911810030273532\n",
      "train loss:0.00150000676823015\n",
      "train loss:0.0057196934058852955\n",
      "train loss:0.009636234355711143\n",
      "train loss:0.06796991453814849\n",
      "train loss:0.027729458844503473\n",
      "train loss:0.028608129336261476\n",
      "train loss:0.011586077525744844\n",
      "train loss:0.0014920160965280003\n",
      "train loss:0.03332266546180976\n",
      "train loss:0.003713022643008248\n",
      "train loss:0.005946530505500291\n",
      "train loss:0.006365473889521537\n",
      "train loss:0.023506965337756102\n",
      "train loss:0.07090350549182617\n",
      "train loss:0.02216059956518776\n",
      "train loss:0.019364195571168075\n",
      "train loss:0.04312202819929694\n",
      "train loss:0.014990301239958459\n",
      "train loss:0.004470064128651887\n",
      "train loss:0.03352781988515104\n",
      "train loss:0.013810272223542495\n",
      "train loss:0.012543643489052639\n",
      "train loss:0.04839352163337983\n",
      "train loss:0.03683067208628955\n",
      "train loss:0.027341387937512788\n",
      "train loss:0.02900891803076679\n",
      "train loss:0.021137198294305815\n",
      "train loss:0.012233362815373653\n",
      "train loss:0.021531343799955763\n",
      "train loss:0.01611895314536524\n",
      "train loss:0.012322436929918962\n",
      "train loss:0.0036413990511994436\n",
      "train loss:0.04335226004588191\n",
      "train loss:0.03998928886650873\n",
      "train loss:0.012147669121052695\n",
      "train loss:0.008497486495123267\n",
      "train loss:0.004588367638479182\n",
      "train loss:0.006728991079839031\n",
      "train loss:0.011878818184073738\n",
      "train loss:0.008909719866621571\n",
      "train loss:0.004672962240443303\n",
      "train loss:0.007078479743734536\n",
      "train loss:0.027955704185503284\n",
      "train loss:0.009236449776154515\n",
      "train loss:0.012618738138533649\n",
      "train loss:0.05110769514946276\n",
      "train loss:0.006195354667635482\n",
      "train loss:0.0074358346526548795\n",
      "train loss:0.03291187879640384\n",
      "train loss:0.028703690369455855\n",
      "train loss:0.027672825718631295\n",
      "train loss:0.007338190115540249\n",
      "train loss:0.007712291194831484\n",
      "train loss:0.01115578746002301\n",
      "train loss:0.007336969124133632\n",
      "train loss:0.013360387151181277\n",
      "train loss:0.07997762887201479\n",
      "train loss:0.024746655766498597\n",
      "train loss:0.02541469692449062\n",
      "train loss:0.022590541305853428\n",
      "train loss:0.006353770984578229\n",
      "train loss:0.024066353418624828\n",
      "train loss:0.0015069373187168763\n",
      "train loss:0.03493280201634015\n",
      "train loss:0.01212458114419806\n",
      "train loss:0.019607904098906316\n",
      "train loss:0.013095209324835808\n",
      "train loss:0.006935488277088013\n",
      "train loss:0.016422180140495395\n",
      "train loss:0.01734651916708334\n",
      "train loss:0.012261450070261653\n",
      "train loss:0.03178521060767704\n",
      "train loss:0.009802800361299449\n",
      "train loss:0.07463193028472997\n",
      "train loss:0.0064530847172213504\n",
      "train loss:0.012208267030080258\n",
      "train loss:0.011000926748676204\n",
      "train loss:0.012174686605707094\n",
      "train loss:0.0063209229952572036\n",
      "train loss:0.012198951949972843\n",
      "train loss:0.025170348448969967\n",
      "train loss:0.06394400038354617\n",
      "train loss:0.010517984286730443\n",
      "train loss:0.015393193998690245\n",
      "train loss:0.00590600238026375\n",
      "train loss:0.03138208690815337\n",
      "train loss:0.014376863533783462\n",
      "=== epoch:7, train acc:0.991, test acc:0.979 ===\n",
      "train loss:0.04800561688624743\n",
      "train loss:0.023802944562395574\n",
      "train loss:0.030507560634226234\n",
      "train loss:0.024791674426781207\n",
      "train loss:0.029520629170131495\n",
      "train loss:0.0026936769005671286\n",
      "train loss:0.03344565375425984\n",
      "train loss:0.014163079386514187\n",
      "train loss:0.031096231816303874\n",
      "train loss:0.004651246034829551\n",
      "train loss:0.026667234470921612\n",
      "train loss:0.013636333012901998\n",
      "train loss:0.011631166856546627\n",
      "train loss:0.008883883744667136\n",
      "train loss:0.03957065146246764\n",
      "train loss:0.036336668000690374\n",
      "train loss:0.024206842081205052\n",
      "train loss:0.008793917422433623\n",
      "train loss:0.009857313728397113\n",
      "train loss:0.019103931387390943\n",
      "train loss:0.01038909604734505\n",
      "train loss:0.029762635465153797\n",
      "train loss:0.024988413973309025\n",
      "train loss:0.009698674983557762\n",
      "train loss:0.008055897109182525\n",
      "train loss:0.024795118307032547\n",
      "train loss:0.05537598340389768\n",
      "train loss:0.012096475597081345\n",
      "train loss:0.03798980595220771\n",
      "train loss:0.00996887112176557\n",
      "train loss:0.006873705359538804\n",
      "train loss:0.0044102499713758545\n",
      "train loss:0.03623078061577788\n",
      "train loss:0.03508972128577463\n",
      "train loss:0.04872125056382233\n",
      "train loss:0.008951514340129078\n",
      "train loss:0.021065203771487337\n",
      "train loss:0.02624877112399103\n",
      "train loss:0.026984592210604768\n",
      "train loss:0.019155309836023583\n",
      "train loss:0.00396439332865869\n",
      "train loss:0.009537048050581096\n",
      "train loss:0.015034190950245763\n",
      "train loss:0.007809717365183283\n",
      "train loss:0.008279826771339122\n",
      "train loss:0.06556473641661027\n",
      "train loss:0.005144960792625157\n",
      "train loss:0.025096698444607983\n",
      "train loss:0.003065215296582723\n",
      "train loss:0.007643310786724925\n",
      "train loss:0.01757050322448213\n",
      "train loss:0.009992586378534596\n",
      "train loss:0.01932380808925958\n",
      "train loss:0.003534978264540351\n",
      "train loss:0.02585450591700801\n",
      "train loss:0.003966619423213789\n",
      "train loss:0.010755123992633344\n",
      "train loss:0.0061097422465025905\n",
      "train loss:0.013965609784917557\n",
      "train loss:0.08173154753497736\n",
      "train loss:0.040137095855098545\n",
      "train loss:0.030075529170228057\n",
      "train loss:0.02766689181034764\n",
      "train loss:0.0333944610970347\n",
      "train loss:0.015228836248806481\n",
      "train loss:0.01679100589327653\n",
      "train loss:0.04186976804222632\n",
      "train loss:0.025241368613917764\n",
      "train loss:0.07483810190796625\n",
      "train loss:0.021839049038490824\n",
      "train loss:0.026363631549604194\n",
      "train loss:0.03154987647371649\n",
      "train loss:0.020338916535942643\n",
      "train loss:0.010358510366780465\n",
      "train loss:0.04816619921055104\n",
      "train loss:0.01481852785369132\n",
      "train loss:0.003818953642294452\n",
      "train loss:0.01370864273824978\n",
      "train loss:0.019142712341411426\n",
      "train loss:0.034699515320615174\n",
      "train loss:0.020858816058464978\n",
      "train loss:0.07789185792473019\n",
      "train loss:0.007551349420695615\n",
      "train loss:0.01433582464589641\n",
      "train loss:0.11152127632750922\n",
      "train loss:0.003930692064415313\n",
      "train loss:0.009536774618792748\n",
      "train loss:0.03195703087709014\n",
      "train loss:0.024552022791562593\n",
      "train loss:0.03420655347504983\n",
      "train loss:0.011539759153648412\n",
      "train loss:0.002652831452593502\n",
      "train loss:0.003671476066075891\n",
      "train loss:0.00729033157133062\n",
      "train loss:0.02978922932229796\n",
      "train loss:0.007047291427013853\n",
      "train loss:0.012965190647518112\n",
      "train loss:0.005346852971866486\n",
      "train loss:0.0021967656852847693\n",
      "train loss:0.027291116552178828\n",
      "train loss:0.027623646309628422\n",
      "train loss:0.011664409743986779\n",
      "train loss:0.011096521208285151\n",
      "train loss:0.0128273565371071\n",
      "train loss:0.009767932801715302\n",
      "train loss:0.013136872100189245\n",
      "train loss:0.04032785435468054\n",
      "train loss:0.0018028961221091095\n",
      "train loss:0.05550159698220633\n",
      "train loss:0.010393798651548896\n",
      "train loss:0.016024605841360683\n",
      "train loss:0.0054219461050652425\n",
      "train loss:0.015444717418187513\n",
      "train loss:0.06886501343586429\n",
      "train loss:0.014124120131629765\n",
      "train loss:0.09855182725631437\n",
      "train loss:0.009234271867724197\n",
      "train loss:0.00977974055234294\n",
      "train loss:0.008999962179730443\n",
      "train loss:0.027821012625251707\n",
      "train loss:0.015873068416005106\n",
      "train loss:0.003449084149175735\n",
      "train loss:0.04802033978250487\n",
      "train loss:0.04012174471344704\n",
      "train loss:0.020691278741462676\n",
      "train loss:0.016398702061680568\n",
      "train loss:0.01788721430958678\n",
      "train loss:0.023018634787803537\n",
      "train loss:0.009561922757410319\n",
      "train loss:0.0036824852448379547\n",
      "train loss:0.01514004018324936\n",
      "train loss:0.009758431397533596\n",
      "train loss:0.011492575563050505\n",
      "train loss:0.0026888495221008227\n",
      "train loss:0.004261097322028997\n",
      "train loss:0.01671460790769709\n",
      "train loss:0.008832327975786727\n",
      "train loss:0.01708318377250434\n",
      "train loss:0.01955835118785139\n",
      "train loss:0.03678867632639014\n",
      "train loss:0.007559065515316134\n",
      "train loss:0.012938207189323645\n",
      "train loss:0.006680787877758063\n",
      "train loss:0.002003337410823227\n",
      "train loss:0.03346934026727352\n",
      "train loss:0.024285088460186937\n",
      "train loss:0.010015417004517588\n",
      "train loss:0.025238940422155496\n",
      "train loss:0.03346404981946516\n",
      "train loss:0.033331358728981436\n",
      "train loss:0.019572676314723314\n",
      "train loss:0.033644746621123246\n",
      "train loss:0.038790267382185724\n",
      "train loss:0.008744515049639077\n",
      "train loss:0.033567665843403226\n",
      "train loss:0.009125819757461011\n",
      "train loss:0.041583490794141094\n",
      "train loss:0.01230219564295982\n",
      "train loss:0.012058456251691703\n",
      "train loss:0.03742143588360101\n",
      "train loss:0.011007201837730216\n",
      "train loss:0.05120488411385096\n",
      "train loss:0.005805788642912243\n",
      "train loss:0.017981101123399366\n",
      "train loss:0.020691864330400996\n",
      "train loss:0.03184454164933732\n",
      "train loss:0.07180442040620433\n",
      "train loss:0.013840537562225707\n",
      "train loss:0.004139752827457616\n",
      "train loss:0.0060359631508785875\n",
      "train loss:0.00841267341785358\n",
      "train loss:0.006223056566917907\n",
      "train loss:0.006169389871045163\n",
      "train loss:0.010476942732573888\n",
      "train loss:0.013897394168339785\n",
      "train loss:0.01970912529120675\n",
      "train loss:0.0074414935743919155\n",
      "train loss:0.011196127967203722\n",
      "train loss:0.0221672093832016\n",
      "train loss:0.01477549524682695\n",
      "train loss:0.0008084148064956579\n",
      "train loss:0.011494122039787544\n",
      "train loss:0.00896955792254478\n",
      "train loss:0.008623654870123149\n",
      "train loss:0.05520373260470961\n",
      "train loss:0.0018117902454020032\n",
      "train loss:0.0035479262560706827\n",
      "train loss:0.10791769832203599\n",
      "train loss:0.0018358420804767542\n",
      "train loss:0.023351398278353672\n",
      "train loss:0.04359076073316814\n",
      "train loss:0.008418991436272439\n",
      "train loss:0.027455277189078395\n",
      "train loss:0.03859393418589342\n",
      "train loss:0.08088551245625193\n",
      "train loss:0.0038972528856756183\n",
      "train loss:0.029024920943443534\n",
      "train loss:0.07675220253807354\n",
      "train loss:0.07755795078924665\n",
      "train loss:0.01741586858637413\n",
      "train loss:0.011754813581258303\n",
      "train loss:0.02460777120122906\n",
      "train loss:0.010334711987154101\n",
      "train loss:0.008067770143543386\n",
      "train loss:0.009055815851997611\n",
      "train loss:0.016392338986046806\n",
      "train loss:0.09907144331544991\n",
      "train loss:0.01368227763836805\n",
      "train loss:0.026981357338332054\n",
      "train loss:0.007082569837201715\n",
      "train loss:0.008303554585324216\n",
      "train loss:0.04917341512395256\n",
      "train loss:0.007910192243958414\n",
      "train loss:0.014413774533569696\n",
      "train loss:0.05354744267293406\n",
      "train loss:0.01632719852876584\n",
      "train loss:0.0082198496465517\n",
      "train loss:0.025602847456988927\n",
      "train loss:0.002774664578276731\n",
      "train loss:0.015661223034800106\n",
      "train loss:0.004038175686721067\n",
      "train loss:0.03299435245460857\n",
      "train loss:0.011503145834863466\n",
      "train loss:0.014522267440300636\n",
      "train loss:0.01814058932968703\n",
      "train loss:0.004559124247035706\n",
      "train loss:0.009463098776605474\n",
      "train loss:0.031608458077382745\n",
      "train loss:0.006183624476036961\n",
      "train loss:0.00719226546119058\n",
      "train loss:0.004855434905854621\n",
      "train loss:0.0069478437242962545\n",
      "train loss:0.011737115566216427\n",
      "train loss:0.010396209827066622\n",
      "train loss:0.008443783568178929\n",
      "train loss:0.022182312280654978\n",
      "train loss:0.014676322187028279\n",
      "train loss:0.006572502257602504\n",
      "train loss:0.009196445458476888\n",
      "train loss:0.01561290448114066\n",
      "train loss:0.0029243101924373766\n",
      "train loss:0.022678099844444945\n",
      "train loss:0.03445859429093582\n",
      "train loss:0.007321309415624439\n",
      "train loss:0.01455147646818527\n",
      "train loss:0.01217871490603433\n",
      "train loss:0.023237385333823184\n",
      "train loss:0.023805783650549407\n",
      "train loss:0.005183671671648662\n",
      "train loss:0.012047103770870688\n",
      "train loss:0.008571461056069615\n",
      "train loss:0.014138725719099203\n",
      "train loss:0.003434810286677206\n",
      "train loss:0.006164439668813184\n",
      "train loss:0.012909201689572922\n",
      "train loss:0.0065264741657010085\n",
      "train loss:0.02864579713637058\n",
      "train loss:0.025533697334888587\n",
      "train loss:0.0263038281498554\n",
      "train loss:0.0036719586402409543\n",
      "train loss:0.015191773705998867\n",
      "train loss:0.0023520871208484177\n",
      "train loss:0.03690275270080328\n",
      "train loss:0.03551971370349634\n",
      "train loss:0.0109887926864835\n",
      "train loss:0.03126659721555037\n",
      "train loss:0.038230230121521186\n",
      "train loss:0.012395987533852888\n",
      "train loss:0.03615840881332473\n",
      "train loss:0.11072371175512671\n",
      "train loss:0.006129293786965908\n",
      "train loss:0.03524200100054534\n",
      "train loss:0.006225514434946356\n",
      "train loss:0.009569929487288336\n",
      "train loss:0.03516071560781709\n",
      "train loss:0.012618819894288489\n",
      "train loss:0.08951730393666607\n",
      "train loss:0.028815420343527284\n",
      "train loss:0.0034471618806843495\n",
      "train loss:0.006307465688309993\n",
      "train loss:0.0068154730989437905\n",
      "train loss:0.015421392137537494\n",
      "train loss:0.01959693438061515\n",
      "train loss:0.008224258869066508\n",
      "train loss:0.01515355188313283\n",
      "train loss:0.012283977051824484\n",
      "train loss:0.006396262010164641\n",
      "train loss:0.016343293791922425\n",
      "train loss:0.00877939668176514\n",
      "train loss:0.003796055855448857\n",
      "train loss:0.007886869307130367\n",
      "train loss:0.006434356267457466\n",
      "train loss:0.020396007882323416\n",
      "train loss:0.08204165248997185\n",
      "train loss:0.0032915138949015377\n",
      "train loss:0.0034829857410333897\n",
      "train loss:0.020714447128318013\n",
      "train loss:0.009656978501362982\n",
      "train loss:0.004774369196774305\n",
      "train loss:0.008784244786635259\n",
      "train loss:0.024760932958877126\n",
      "train loss:0.05236327138283236\n",
      "train loss:0.057981467775942715\n",
      "train loss:0.007319273779069943\n",
      "train loss:0.01036851579787388\n",
      "train loss:0.008321835783660768\n",
      "train loss:0.0068268670460073545\n",
      "train loss:0.020962467566134412\n",
      "train loss:0.01247298717334962\n",
      "train loss:0.004919823667438256\n",
      "train loss:0.004308123417155458\n",
      "train loss:0.02245249152105687\n",
      "train loss:0.01338210423412409\n",
      "train loss:0.004842564234870167\n",
      "train loss:0.0029101826076858585\n",
      "train loss:0.0026175553800114226\n",
      "train loss:0.008221166534035079\n",
      "train loss:0.024196219089814376\n",
      "train loss:0.003947471572339604\n",
      "train loss:0.009036518870595416\n",
      "train loss:0.008271536057921143\n",
      "train loss:0.009492355523035756\n",
      "train loss:0.015130474463064996\n",
      "train loss:0.015945957023734407\n",
      "train loss:0.009516638200234823\n",
      "train loss:0.01288833129724446\n",
      "train loss:0.022268136131612114\n",
      "train loss:0.014129467903453135\n",
      "train loss:0.016053339909091073\n",
      "train loss:0.006503647016607019\n",
      "train loss:0.00933910089363818\n",
      "train loss:0.023371816892764657\n",
      "train loss:0.006620896291449368\n",
      "train loss:0.01099030074361597\n",
      "train loss:0.07025273311854562\n",
      "train loss:0.02779808181779849\n",
      "train loss:0.00488885811770904\n",
      "train loss:0.02580851000271353\n",
      "train loss:0.022205582893879285\n",
      "train loss:0.008468188998835247\n",
      "train loss:0.003112305830541944\n",
      "train loss:0.0058838905616197534\n",
      "train loss:0.007348862524057572\n",
      "train loss:0.02770108391873329\n",
      "train loss:0.02690206235796496\n",
      "train loss:0.0764622974943708\n",
      "train loss:0.06594244957986799\n",
      "train loss:0.021050398750596597\n",
      "train loss:0.0028080044947322406\n",
      "train loss:0.020511457801083637\n",
      "train loss:0.00474282766827664\n",
      "train loss:0.03327043592298067\n",
      "train loss:0.03698625238002409\n",
      "train loss:0.03755256801156593\n",
      "train loss:0.0029206997893630672\n",
      "train loss:0.02997855197211767\n",
      "train loss:0.012686607068513371\n",
      "train loss:0.010435067822231978\n",
      "train loss:0.012369698689349362\n",
      "train loss:0.03967161925786831\n",
      "train loss:0.03156258250122986\n",
      "train loss:0.0020379309693470305\n",
      "train loss:0.023394019235794716\n",
      "train loss:0.00612926729346414\n",
      "train loss:0.008509348253787226\n",
      "train loss:0.03622380752414001\n",
      "train loss:0.030381838528268586\n",
      "train loss:0.007966330172522408\n",
      "train loss:0.07267331534115103\n",
      "train loss:0.006603545763125223\n",
      "train loss:0.03485762270351905\n",
      "train loss:0.06072967889860752\n",
      "train loss:0.020399155460189323\n",
      "train loss:0.01192941589973847\n",
      "train loss:0.015776321754980248\n",
      "train loss:0.020295356212258288\n",
      "train loss:0.004985877306399918\n",
      "train loss:0.006348037021758596\n",
      "train loss:0.016219451228582402\n",
      "train loss:0.020354057311340726\n",
      "train loss:0.005498493065770344\n",
      "train loss:0.02017799689727461\n",
      "train loss:0.014689252568535023\n",
      "train loss:0.006173509974735599\n",
      "train loss:0.03785345658242606\n",
      "train loss:0.009509321254337743\n",
      "train loss:0.009413452385111378\n",
      "train loss:0.007838674540850493\n",
      "train loss:0.048978433676065566\n",
      "train loss:0.02351932777143135\n",
      "train loss:0.076750278219288\n",
      "train loss:0.005334926107658874\n",
      "train loss:0.006217886671176636\n",
      "train loss:0.024044085277807343\n",
      "train loss:0.00928256871933104\n",
      "train loss:0.0041733339323306905\n",
      "train loss:0.057259946874418016\n",
      "train loss:0.01713343551358902\n",
      "train loss:0.04829064851929215\n",
      "train loss:0.0034373220464953285\n",
      "train loss:0.007028669505866878\n",
      "train loss:0.009977140390340321\n",
      "train loss:0.022207375643162913\n",
      "train loss:0.013648193813965728\n",
      "train loss:0.024659624438505227\n",
      "train loss:0.001415291273622569\n",
      "train loss:0.033943539237991344\n",
      "train loss:0.04038692591202081\n",
      "train loss:0.005278888699421751\n",
      "train loss:0.004787655346725809\n",
      "train loss:0.013763190248682658\n",
      "train loss:0.01626603095111279\n",
      "train loss:0.016720569533743016\n",
      "train loss:0.010993115355770973\n",
      "train loss:0.019814385753297227\n",
      "train loss:0.015336758972209043\n",
      "train loss:0.02317143320203772\n",
      "train loss:0.006061695855092153\n",
      "train loss:0.008635565994255131\n",
      "train loss:0.013799551271868899\n",
      "train loss:0.023398431968007918\n",
      "train loss:0.015606853662154615\n",
      "train loss:0.007032524717549984\n",
      "train loss:0.004453642459189503\n",
      "train loss:0.0017144198826901191\n",
      "train loss:0.0348632354295151\n",
      "train loss:0.006431910068691886\n",
      "train loss:0.0017737101121969125\n",
      "train loss:0.00904338832257073\n",
      "train loss:0.011222241932665607\n",
      "train loss:0.01195564079357573\n",
      "train loss:0.003420064718671438\n",
      "train loss:0.009411843332859804\n",
      "train loss:0.009256317639226186\n",
      "train loss:0.00484716766429562\n",
      "train loss:0.009983469602553814\n",
      "train loss:0.009203305090935124\n",
      "train loss:0.017712700435851134\n",
      "train loss:0.024746323917281706\n",
      "train loss:0.007730721802030248\n",
      "train loss:0.0032721890629991723\n",
      "train loss:0.014330606989240427\n",
      "train loss:0.019466289088849946\n",
      "train loss:0.001749918637563356\n",
      "train loss:0.0043990762473193066\n",
      "train loss:0.005677212600387869\n",
      "train loss:0.046175394183719416\n",
      "train loss:0.001488081561077256\n",
      "train loss:0.0036978734922140134\n",
      "train loss:0.03387795376076776\n",
      "train loss:0.013121183271187203\n",
      "train loss:0.012833302024610783\n",
      "train loss:0.03417209158199461\n",
      "train loss:0.0032450701762979273\n",
      "train loss:0.05879564022403374\n",
      "train loss:0.01012222030885143\n",
      "train loss:0.011289856803593332\n",
      "train loss:0.0037475165747399885\n",
      "train loss:0.003286581307225146\n",
      "train loss:0.015238230591035698\n",
      "train loss:0.047459416706079074\n",
      "train loss:0.02032093914114727\n",
      "train loss:0.012717217380037012\n",
      "train loss:0.0050118390521640774\n",
      "train loss:0.005951133128104373\n",
      "train loss:0.004287299123352411\n",
      "train loss:0.007050918351825709\n",
      "train loss:0.03502458889865291\n",
      "train loss:0.027261703181104227\n",
      "train loss:0.005880812275453193\n",
      "train loss:0.0133109112783764\n",
      "train loss:0.007696136868956833\n",
      "train loss:0.034677943427295535\n",
      "train loss:0.004168142644380323\n",
      "train loss:0.008785013313332302\n",
      "train loss:0.01279058500775344\n",
      "train loss:0.023085161998044657\n",
      "train loss:0.009679972522906498\n",
      "train loss:0.010946986376550187\n",
      "train loss:0.03864104127818208\n",
      "train loss:0.03216144702591018\n",
      "train loss:0.0021815083846870504\n",
      "train loss:0.005617281859608\n",
      "train loss:0.0016908939001059806\n",
      "train loss:0.021255745319307507\n",
      "train loss:0.011241264442763483\n",
      "train loss:0.028777778819676896\n",
      "train loss:0.016406441203615306\n",
      "train loss:0.005332122612279354\n",
      "train loss:0.016154534304791825\n",
      "train loss:0.0487358385798632\n",
      "train loss:0.012749475598713178\n",
      "train loss:0.01861149068173213\n",
      "train loss:0.012129424215010976\n",
      "train loss:0.003620619983697024\n",
      "train loss:0.07555749145501421\n",
      "train loss:0.007946366812980273\n",
      "train loss:0.0030624446835057282\n",
      "train loss:0.019499062857367674\n",
      "train loss:0.0629446349809101\n",
      "train loss:0.012869761759310991\n",
      "train loss:0.0035118986940767356\n",
      "train loss:0.007314992332717219\n",
      "train loss:0.00602282254094396\n",
      "train loss:0.019866128061467606\n",
      "train loss:0.025678649981491216\n",
      "train loss:0.015622850711534469\n",
      "train loss:0.0014912351213548908\n",
      "train loss:0.0024087085191448776\n",
      "train loss:0.009443728842953088\n",
      "train loss:0.003984694951197185\n",
      "train loss:0.024657238409372503\n",
      "train loss:0.03437338088325044\n",
      "train loss:0.014500781335073432\n",
      "train loss:0.014262108427120411\n",
      "train loss:0.03915498743182318\n",
      "train loss:0.01924942281141226\n",
      "train loss:0.016882732831449775\n",
      "train loss:0.002744252708597223\n",
      "train loss:0.02913878032579782\n",
      "train loss:0.00984691284090976\n",
      "train loss:0.04521249093291054\n",
      "train loss:0.022731552929761187\n",
      "train loss:0.014234448374634015\n",
      "train loss:0.030346396725697642\n",
      "train loss:0.004522383847953285\n",
      "train loss:0.0033251532004546624\n",
      "train loss:0.009567197208124994\n",
      "train loss:0.005150878002786614\n",
      "train loss:0.013339368449868026\n",
      "train loss:0.05726719727776521\n",
      "train loss:0.008062713043521004\n",
      "train loss:0.007546619106244764\n",
      "train loss:0.02328211668582501\n",
      "train loss:0.0033200598774643943\n",
      "train loss:0.006781268206470852\n",
      "train loss:0.02588669958680131\n",
      "train loss:0.0076275755732639694\n",
      "train loss:0.005679975981901565\n",
      "train loss:0.012114634750309456\n",
      "train loss:0.00239902317276428\n",
      "train loss:0.023669876440352646\n",
      "train loss:0.003079857430647557\n",
      "train loss:0.017993039226011615\n",
      "train loss:0.0032082319380125103\n",
      "train loss:0.043979487494412633\n",
      "train loss:0.00501738252675251\n",
      "train loss:0.010797892134870576\n",
      "train loss:0.026990205535307895\n",
      "train loss:0.008168126804617249\n",
      "train loss:0.012178854075310542\n",
      "train loss:0.021781410935386596\n",
      "train loss:0.002294347489545453\n",
      "train loss:0.029720430837121156\n",
      "train loss:0.03207336582631283\n",
      "train loss:0.009015500247970442\n",
      "train loss:0.011143820221165213\n",
      "train loss:0.013297027003304563\n",
      "train loss:0.025588640509175295\n",
      "train loss:0.0030593487712605224\n",
      "train loss:0.010331918966462577\n",
      "train loss:0.005711384471798377\n",
      "train loss:0.07842780924145343\n",
      "train loss:0.0024487047233463176\n",
      "train loss:0.005855076916942458\n",
      "train loss:0.003560255966741307\n",
      "train loss:0.0031066788154064102\n",
      "train loss:0.008357428068035909\n",
      "train loss:0.015380702047582812\n",
      "train loss:0.034897097266209556\n",
      "train loss:0.023645254377549243\n",
      "train loss:0.018571593558408456\n",
      "train loss:0.006202155735975439\n",
      "train loss:0.01715528398898636\n",
      "train loss:0.002594212537195832\n",
      "train loss:0.0038373432334534176\n",
      "train loss:0.011146124017961273\n",
      "train loss:0.02515671346431005\n",
      "train loss:0.014818406192570632\n",
      "train loss:0.01342895834924947\n",
      "train loss:0.0033929410594103616\n",
      "train loss:0.003987582140102101\n",
      "train loss:0.0076352925920900065\n",
      "train loss:0.017158095798464845\n",
      "train loss:0.004768292340031945\n",
      "train loss:0.00595325432632577\n",
      "train loss:0.005157415620265227\n",
      "train loss:0.008278416193590144\n",
      "train loss:0.01077786100700347\n",
      "train loss:0.005743439430820599\n",
      "train loss:0.004333135976340509\n",
      "train loss:0.009817665343507921\n",
      "train loss:0.005386519855865449\n",
      "train loss:0.007338300150650634\n",
      "train loss:0.015545353292948894\n",
      "train loss:0.15146019986797923\n",
      "train loss:0.038648791945358536\n",
      "train loss:0.004270564278320681\n",
      "train loss:0.022891901917570737\n",
      "train loss:0.003318529939606566\n",
      "=== epoch:8, train acc:0.994, test acc:0.988 ===\n",
      "train loss:0.013993427050852887\n",
      "train loss:0.006750902911703216\n",
      "train loss:0.006220648729868359\n",
      "train loss:0.010914826439506769\n",
      "train loss:0.00823068416557089\n",
      "train loss:0.003351826165830712\n",
      "train loss:0.008286699487595701\n",
      "train loss:0.04270112163546841\n",
      "train loss:0.004201114954251172\n",
      "train loss:0.0302334273538367\n",
      "train loss:0.006523213234399732\n",
      "train loss:0.007575976716614914\n",
      "train loss:0.0023673552237059308\n",
      "train loss:0.009240179692299531\n",
      "train loss:0.009113412003717309\n",
      "train loss:0.002968019948021844\n",
      "train loss:0.016361862762406663\n",
      "train loss:0.014747372149056468\n",
      "train loss:0.005345644159253419\n",
      "train loss:0.002637468166915533\n",
      "train loss:0.009440638510456898\n",
      "train loss:0.0052814829978987754\n",
      "train loss:0.013079109800317701\n",
      "train loss:0.020870090850555773\n",
      "train loss:0.055368893605810834\n",
      "train loss:0.019926295870201057\n",
      "train loss:0.0175620717443099\n",
      "train loss:0.0014015516679820824\n",
      "train loss:0.0161334218610124\n",
      "train loss:0.011506828983691797\n",
      "train loss:0.011139212849929914\n",
      "train loss:0.006929747301251636\n",
      "train loss:0.01505952121326016\n",
      "train loss:0.026818636177133905\n",
      "train loss:0.012903580015528816\n",
      "train loss:0.01433723193059641\n",
      "train loss:0.011174874608993446\n",
      "train loss:0.024901195589890335\n",
      "train loss:0.030220060538733245\n",
      "train loss:0.059795883132470244\n",
      "train loss:0.004622130234001143\n",
      "train loss:0.034679335359286495\n",
      "train loss:0.011337999810743968\n",
      "train loss:0.033098729581108766\n",
      "train loss:0.02339942865133555\n",
      "train loss:0.07064613221268667\n",
      "train loss:0.005322006146948094\n",
      "train loss:0.009853745494650325\n",
      "train loss:0.012027107973508679\n",
      "train loss:0.004565274269538447\n",
      "train loss:0.01209689458443986\n",
      "train loss:0.01112007948563303\n",
      "train loss:0.02473220692589825\n",
      "train loss:0.02387556703550501\n",
      "train loss:0.016489829062410758\n",
      "train loss:0.04696776776743272\n",
      "train loss:0.009789041233816676\n",
      "train loss:0.010437240426948187\n",
      "train loss:0.032852942251329356\n",
      "train loss:0.004696712593987459\n",
      "train loss:0.010846235858737221\n",
      "train loss:0.010587222007898417\n",
      "train loss:0.005384954295226496\n",
      "train loss:0.01618040222653354\n",
      "train loss:0.011302130635010836\n",
      "train loss:0.004920831321014954\n",
      "train loss:0.007960035220891802\n",
      "train loss:0.03833335400159839\n",
      "train loss:0.0012124369427410132\n",
      "train loss:0.02438912135880731\n",
      "train loss:0.03504943263719006\n",
      "train loss:0.006328812866415253\n",
      "train loss:0.008415247167779388\n",
      "train loss:0.04594340224922742\n",
      "train loss:0.04861842704648096\n",
      "train loss:0.00468087168760595\n",
      "train loss:0.011423193259461365\n",
      "train loss:0.01034725820151096\n",
      "train loss:0.02500655141861464\n",
      "train loss:0.000912013450282225\n",
      "train loss:0.0071713840788474904\n",
      "train loss:0.007982332417405697\n",
      "train loss:0.04745880877011279\n",
      "train loss:0.006356401546818436\n",
      "train loss:0.008006531840972409\n",
      "train loss:0.005830977141229263\n",
      "train loss:0.024449934678334766\n",
      "train loss:0.017245632893768938\n",
      "train loss:0.011278662183887855\n",
      "train loss:0.007928908819021559\n",
      "train loss:0.02670989014488653\n",
      "train loss:0.008848085279837145\n",
      "train loss:0.005702495391431959\n",
      "train loss:0.002302225466068141\n",
      "train loss:0.01490358300203861\n",
      "train loss:0.017888971136217627\n",
      "train loss:0.018458180383710224\n",
      "train loss:0.017233484760221584\n",
      "train loss:0.009009157114114527\n",
      "train loss:0.016022552824117017\n",
      "train loss:0.0029920707208102026\n",
      "train loss:0.006539635352824286\n",
      "train loss:0.020084841977169626\n",
      "train loss:0.014379792439773775\n",
      "train loss:0.02349646071400589\n",
      "train loss:0.005719284766893231\n",
      "train loss:0.023029839952061936\n",
      "train loss:0.010584654341810867\n",
      "train loss:0.05558452313643831\n",
      "train loss:0.037130430851820016\n",
      "train loss:0.00869297337223385\n",
      "train loss:0.00883554501318302\n",
      "train loss:0.0059163699830880314\n",
      "train loss:0.0022069633093810465\n",
      "train loss:0.011332160570848175\n",
      "train loss:0.004075952136286376\n",
      "train loss:0.00960434092199241\n",
      "train loss:0.03220232611703541\n",
      "train loss:0.042565554857264695\n",
      "train loss:0.020472724727186847\n",
      "train loss:0.0026859513793629584\n",
      "train loss:0.004614925378697759\n",
      "train loss:0.006886668160892474\n",
      "train loss:0.030247692455902787\n",
      "train loss:0.0065664118485261455\n",
      "train loss:0.0033942399777998566\n",
      "train loss:0.011309635138521757\n",
      "train loss:0.0075885308435310805\n",
      "train loss:0.009434925175085335\n",
      "train loss:0.021291884336679077\n",
      "train loss:0.02487554060397912\n",
      "train loss:0.006073599553244175\n",
      "train loss:0.025515077689240617\n",
      "train loss:0.07342133147812584\n",
      "train loss:0.0028953769306525557\n",
      "train loss:0.00921937985816586\n",
      "train loss:0.0043339710482392\n",
      "train loss:0.003470651275954386\n",
      "train loss:0.007404413047353502\n",
      "train loss:0.017040243333114345\n",
      "train loss:0.011464080522291363\n",
      "train loss:0.00776970001074248\n",
      "train loss:0.04685981266842551\n",
      "train loss:0.007410234703484795\n",
      "train loss:0.015410318511961276\n",
      "train loss:0.017274826676670962\n",
      "train loss:0.03337141234764157\n",
      "train loss:0.01765986582029977\n",
      "train loss:0.007074941193966129\n",
      "train loss:0.06766323933680839\n",
      "train loss:0.008253662910104575\n",
      "train loss:0.023070325642585633\n",
      "train loss:0.009370831644757526\n",
      "train loss:0.034748357961765446\n",
      "train loss:0.0047548787136657165\n",
      "train loss:0.07753493537376459\n",
      "train loss:0.00562669039865565\n",
      "train loss:0.0100040349083333\n",
      "train loss:0.0029229361367225054\n",
      "train loss:0.013245540127643125\n",
      "train loss:0.015390887504738502\n",
      "train loss:0.009048708068837077\n",
      "train loss:0.0026828401370511544\n",
      "train loss:0.025944054822382337\n",
      "train loss:0.002498160971590316\n",
      "train loss:0.05782395591845325\n",
      "train loss:0.0128215374076976\n",
      "train loss:0.01089129622947717\n",
      "train loss:0.004796762188808131\n",
      "train loss:0.04649331157791767\n",
      "train loss:0.007298477710647143\n",
      "train loss:0.006558969919331367\n",
      "train loss:0.039242998384024064\n",
      "train loss:0.03223725578404448\n",
      "train loss:0.013065639610167525\n",
      "train loss:0.009322516227779163\n",
      "train loss:0.004745924934505967\n",
      "train loss:0.00860292918059338\n",
      "train loss:0.057714124975582426\n",
      "train loss:0.015804427005625322\n",
      "train loss:0.006845512872197007\n",
      "train loss:0.007350871636737861\n",
      "train loss:0.0019342915622306632\n",
      "train loss:0.019654224238214238\n",
      "train loss:0.011851499070607518\n",
      "train loss:0.003253725797990244\n",
      "train loss:0.008911744504951455\n",
      "train loss:0.006705623080939038\n",
      "train loss:0.02412319092400066\n",
      "train loss:0.011433291340192634\n",
      "train loss:0.005412934362976391\n",
      "train loss:0.002793346615372788\n",
      "train loss:0.006152949921126149\n",
      "train loss:0.005207788589896337\n",
      "train loss:0.013922290321817918\n",
      "train loss:0.0037411612799891137\n",
      "train loss:0.017896694730629402\n",
      "train loss:0.0047757332138788485\n",
      "train loss:0.021481461861761555\n",
      "train loss:0.0005124170690254037\n",
      "train loss:0.015024614459466965\n",
      "train loss:0.04428654356902492\n",
      "train loss:0.001185538186335801\n",
      "train loss:0.037224123678796094\n",
      "train loss:0.006002532257673751\n",
      "train loss:0.008453045743225633\n",
      "train loss:0.01244715148824356\n",
      "train loss:0.005472535427797789\n",
      "train loss:0.0023548191490534403\n",
      "train loss:0.004827852122750099\n",
      "train loss:0.012211267360498651\n",
      "train loss:0.004570777725512581\n",
      "train loss:0.010583881226368767\n",
      "train loss:0.005329613968627477\n",
      "train loss:0.009044703230019088\n",
      "train loss:0.002455833609018198\n",
      "train loss:0.004529873317818449\n",
      "train loss:0.007376740308086576\n",
      "train loss:0.01478069531490316\n",
      "train loss:0.018140193694099385\n",
      "train loss:0.005960491414548875\n",
      "train loss:0.011509782966727024\n",
      "train loss:0.0370471656866819\n",
      "train loss:0.017337617896781815\n",
      "train loss:0.008199481889106736\n",
      "train loss:0.007059348002075792\n",
      "train loss:0.002214632772789833\n",
      "train loss:0.022071919831527245\n",
      "train loss:0.021520590363538896\n",
      "train loss:0.010559194579450704\n",
      "train loss:0.012072504761386896\n",
      "train loss:0.0029333380549547627\n",
      "train loss:0.005613470963997164\n",
      "train loss:0.0031906473553869126\n",
      "train loss:0.0077890972243642356\n",
      "train loss:0.0124770516987555\n",
      "train loss:0.002515396048472099\n",
      "train loss:0.0008168829428319532\n",
      "train loss:0.029836771657962568\n",
      "train loss:0.0037029741436199015\n",
      "train loss:0.0006028650307038548\n",
      "train loss:0.008550403360524319\n",
      "train loss:0.007053872402577013\n",
      "train loss:0.008746811088331185\n",
      "train loss:0.004154815545133561\n",
      "train loss:0.007562223194103445\n",
      "train loss:0.0188355265744177\n",
      "train loss:0.03207163329804116\n",
      "train loss:0.08684264649750639\n",
      "train loss:0.002419962440420938\n",
      "train loss:0.02101602439315228\n",
      "train loss:0.006638754556923434\n",
      "train loss:0.015014493452242698\n",
      "train loss:0.016580755738552944\n",
      "train loss:0.06674660325973474\n",
      "train loss:0.005411168164227067\n",
      "train loss:0.004383918155222699\n",
      "train loss:0.057744869472676034\n",
      "train loss:0.01979815167181703\n",
      "train loss:0.0062237074845790975\n",
      "train loss:0.020282872802635965\n",
      "train loss:0.021519338855052184\n",
      "train loss:0.018622119958197444\n",
      "train loss:0.0012402751096059147\n",
      "train loss:0.014005262526707219\n",
      "train loss:0.014205439592548186\n",
      "train loss:0.09343515495450276\n",
      "train loss:0.017351644248490474\n",
      "train loss:0.025455073567107803\n",
      "train loss:0.0193560208246481\n",
      "train loss:0.002995206279838248\n",
      "train loss:0.0037720552279588504\n",
      "train loss:0.02376284764867127\n",
      "train loss:0.014949408970286966\n",
      "train loss:0.0021874727346029633\n",
      "train loss:0.01032523358796081\n",
      "train loss:0.029739770703121424\n",
      "train loss:0.00846819005481557\n",
      "train loss:0.019105343980646016\n",
      "train loss:0.020439387093957543\n",
      "train loss:0.0047808680201451665\n",
      "train loss:0.07123005750860424\n",
      "train loss:0.05392794821194205\n",
      "train loss:0.019745019694371355\n",
      "train loss:0.17173911065057296\n",
      "train loss:0.01548720752926891\n",
      "train loss:0.00579201231807232\n",
      "train loss:0.010599606287397739\n",
      "train loss:0.01008764585793444\n",
      "train loss:0.017817347424096127\n",
      "train loss:0.03488747442827425\n",
      "train loss:0.002411489577860483\n",
      "train loss:0.06814911488008983\n",
      "train loss:0.011551953694990456\n",
      "train loss:0.005965247497560297\n",
      "train loss:0.002992738004347747\n",
      "train loss:0.002028767275814211\n",
      "train loss:0.025776167435794254\n",
      "train loss:0.0028171509698160842\n",
      "train loss:0.0384121383654636\n",
      "train loss:0.02853360128396915\n",
      "train loss:0.004102216423026626\n",
      "train loss:0.004839711456866851\n",
      "train loss:0.004387102814736712\n",
      "train loss:0.013610463143671385\n",
      "train loss:0.0061656264384063915\n",
      "train loss:0.018137747964807466\n",
      "train loss:0.005703943229859839\n",
      "train loss:0.018191342430908242\n",
      "train loss:0.001075430006261137\n",
      "train loss:0.005336934652605742\n",
      "train loss:0.011477748250876258\n",
      "train loss:0.016328349140182295\n",
      "train loss:0.012203814730323344\n",
      "train loss:0.002925114153697972\n",
      "train loss:0.004550400114538263\n",
      "train loss:0.015495835261821841\n",
      "train loss:0.017973584469515528\n",
      "train loss:0.003535751959046013\n",
      "train loss:0.030182056304022556\n",
      "train loss:0.007692336744320374\n",
      "train loss:0.017176562587423186\n",
      "train loss:0.01914447634617221\n",
      "train loss:0.007477779193697595\n",
      "train loss:0.019729867758262555\n",
      "train loss:0.011221240417395473\n",
      "train loss:0.012896397924878155\n",
      "train loss:0.04300876431376137\n",
      "train loss:0.01282638028198052\n",
      "train loss:0.008252940098650187\n",
      "train loss:0.055782014928903695\n",
      "train loss:0.021265499308255303\n",
      "train loss:0.0034414250178653994\n",
      "train loss:0.001901523382281988\n",
      "train loss:0.015246301144638099\n",
      "train loss:0.006530952102546056\n",
      "train loss:0.021082196850748483\n",
      "train loss:0.0024183773632880713\n",
      "train loss:0.022963843603235556\n",
      "train loss:0.00406461437903438\n",
      "train loss:0.009157357078357412\n",
      "train loss:0.0036102032942342665\n",
      "train loss:0.014309299090690281\n",
      "train loss:0.007950969773920643\n",
      "train loss:0.004693034058814094\n",
      "train loss:0.014397311208711723\n",
      "train loss:0.0032521239522006035\n",
      "train loss:0.006389447289488179\n",
      "train loss:0.008224612373840253\n",
      "train loss:0.14518655165081457\n",
      "train loss:0.00208929660406939\n",
      "train loss:0.0016787035814590482\n",
      "train loss:0.012187491700556045\n",
      "train loss:0.008639453590964984\n",
      "train loss:0.03297275188423928\n",
      "train loss:0.006824836741475461\n",
      "train loss:0.01974895471944316\n",
      "train loss:0.010157149047524995\n",
      "train loss:0.016815309068516516\n",
      "train loss:0.006953774542310779\n",
      "train loss:0.012922902697134624\n",
      "train loss:0.0032276441722429443\n",
      "train loss:0.017270156570849182\n",
      "train loss:0.016747341930594083\n",
      "train loss:0.006229470253690035\n",
      "train loss:0.010041847078693749\n",
      "train loss:0.011949689595749918\n",
      "train loss:0.001903417588764261\n",
      "train loss:0.03819102939898383\n",
      "train loss:0.017305921003538165\n",
      "train loss:0.0011657021335437735\n",
      "train loss:0.017953799190166528\n",
      "train loss:0.011458095831391311\n",
      "train loss:0.002776856462185362\n",
      "train loss:0.0037871834365716343\n",
      "train loss:0.010571206921082786\n",
      "train loss:0.007797963324017313\n",
      "train loss:0.011078938237032772\n",
      "train loss:0.002757603648207345\n",
      "train loss:0.00544687575924737\n",
      "train loss:0.0038745507550158836\n",
      "train loss:0.007327145145144741\n",
      "train loss:0.016503359846510107\n",
      "train loss:0.015121894529645307\n",
      "train loss:0.014834835259472191\n",
      "train loss:0.0006558110191559525\n",
      "train loss:0.012351904391411437\n",
      "train loss:0.02671724759747525\n",
      "train loss:0.019967675807421467\n",
      "train loss:0.013527722969378968\n",
      "train loss:0.0034080084104160086\n",
      "train loss:0.011091580194622553\n",
      "train loss:0.018965925590049417\n",
      "train loss:0.019509260779168893\n",
      "train loss:0.0012964934093700016\n",
      "train loss:0.02435004348245157\n",
      "train loss:0.012256589342853626\n",
      "train loss:0.002810409076990174\n",
      "train loss:0.004743483803636333\n",
      "train loss:0.02827596199090209\n",
      "train loss:0.006397317235773223\n",
      "train loss:0.0019163398674655763\n",
      "train loss:0.005422007939901622\n",
      "train loss:0.0013680215582155424\n",
      "train loss:0.008726018143225133\n",
      "train loss:0.023325444292972907\n",
      "train loss:0.01626254275527253\n",
      "train loss:0.005609031149156688\n",
      "train loss:0.08078019929252075\n",
      "train loss:0.004004735387037993\n",
      "train loss:0.01572147054470105\n",
      "train loss:0.0034140627502579064\n",
      "train loss:0.010611628739090252\n",
      "train loss:0.004597270954340253\n",
      "train loss:0.0027491134333584065\n",
      "train loss:0.013430116826319257\n",
      "train loss:0.014912577937316976\n",
      "train loss:0.0056930749100203345\n",
      "train loss:0.004183605502848978\n",
      "train loss:0.01195900202195904\n",
      "train loss:0.017275187986009286\n",
      "train loss:0.005027643526846926\n",
      "train loss:0.001403141787692769\n",
      "train loss:0.009579217288564203\n",
      "train loss:0.04071517151748059\n",
      "train loss:0.0038039066057783534\n",
      "train loss:0.022356620843566998\n",
      "train loss:0.028506145544221498\n",
      "train loss:0.010402475890936173\n",
      "train loss:0.003732041760784937\n",
      "train loss:0.0041475973862642925\n",
      "train loss:0.0029791659332735316\n",
      "train loss:0.008961163441375642\n",
      "train loss:0.002785274204439361\n",
      "train loss:0.003791064612848219\n",
      "train loss:0.03228923373009371\n",
      "train loss:0.010050874805949808\n",
      "train loss:0.0038460725275097207\n",
      "train loss:0.013045087191245364\n",
      "train loss:0.0019241758445755512\n",
      "train loss:0.01625370222578607\n",
      "train loss:0.005041954748265454\n",
      "train loss:0.004277856377335976\n",
      "train loss:0.009656077128697404\n",
      "train loss:0.0021180013100660007\n",
      "train loss:0.002006972185846213\n",
      "train loss:0.0023318031746232984\n",
      "train loss:0.0656015843287996\n",
      "train loss:0.008799433825242165\n",
      "train loss:0.002240823086039436\n",
      "train loss:0.010025763628464133\n",
      "train loss:0.0015533344274590616\n",
      "train loss:0.0012685003924027126\n",
      "train loss:0.004598913031540504\n",
      "train loss:0.005379263408840045\n",
      "train loss:0.028518477714851834\n",
      "train loss:0.0022647420177743073\n",
      "train loss:0.0024856688565710588\n",
      "train loss:0.00932110871442183\n",
      "train loss:0.016765811242400543\n",
      "train loss:0.00612170535748662\n",
      "train loss:0.0037205095913704768\n",
      "train loss:0.007978347519309191\n",
      "train loss:0.004292361770789939\n",
      "train loss:0.011769062505103078\n",
      "train loss:0.007609810010541166\n",
      "train loss:0.0026029845503242406\n",
      "train loss:0.002702802817542389\n",
      "train loss:0.0075017890782754235\n",
      "train loss:0.005590384446012219\n",
      "train loss:0.003083715838596034\n",
      "train loss:0.016143365909640148\n",
      "train loss:0.0031099155896779857\n",
      "train loss:0.007276096359269783\n",
      "train loss:0.011010281697031792\n",
      "train loss:0.015499104567744004\n",
      "train loss:0.002714611041281973\n",
      "train loss:0.056122575948685034\n",
      "train loss:0.013314962701614372\n",
      "train loss:0.009794855636547835\n",
      "train loss:0.0029447131957898026\n",
      "train loss:0.009888374475160215\n",
      "train loss:0.01808094411060684\n",
      "train loss:0.013062110585310205\n",
      "train loss:0.004630368867541354\n",
      "train loss:0.004482737108885515\n",
      "train loss:0.007595259427115123\n",
      "train loss:0.004237381998112002\n",
      "train loss:0.014293384458622221\n",
      "train loss:0.003790155230128142\n",
      "train loss:0.0065395320004500886\n",
      "train loss:0.008532916631071679\n",
      "train loss:0.0029693860254073052\n",
      "train loss:0.010604100980478998\n",
      "train loss:0.006404307866190329\n",
      "train loss:0.02592121853024482\n",
      "train loss:0.011729210806839016\n",
      "train loss:0.0008920972806878208\n",
      "train loss:0.0075435534995107545\n",
      "train loss:0.0010456896647738586\n",
      "train loss:0.006403811448555768\n",
      "train loss:0.003133439126206277\n",
      "train loss:0.019824097954474953\n",
      "train loss:0.014904507502422832\n",
      "train loss:0.036818827781144925\n",
      "train loss:0.0025898338783719266\n",
      "train loss:0.009485595673897373\n",
      "train loss:0.0004818024289537814\n",
      "train loss:0.0032612117352259786\n",
      "train loss:0.004079528136988827\n",
      "train loss:0.012931891228518655\n",
      "train loss:0.003873137806239467\n",
      "train loss:0.0010639945173535248\n",
      "train loss:0.0006804832591913579\n",
      "train loss:0.008965983539819995\n",
      "train loss:0.0016161174277759974\n",
      "train loss:0.009735455813558632\n",
      "train loss:0.0032082385460693663\n",
      "train loss:0.01151193212322202\n",
      "train loss:0.0026316992444308813\n",
      "train loss:0.004674850541635545\n",
      "train loss:0.03190515340900715\n",
      "train loss:0.005692144733170646\n",
      "train loss:0.018648144451804936\n",
      "train loss:0.006025494802015061\n",
      "train loss:0.029787220626332007\n",
      "train loss:0.0069648244458362365\n",
      "train loss:0.0033230931811924587\n",
      "train loss:0.01557487748504829\n",
      "train loss:0.005021775368271693\n",
      "train loss:0.006049548187250864\n",
      "train loss:0.004368917783687682\n",
      "train loss:0.030285512006283155\n",
      "train loss:0.02989083684264079\n",
      "train loss:0.026335035233379343\n",
      "train loss:0.0025556919307208083\n",
      "train loss:0.007617039243995763\n",
      "train loss:0.007427396260504562\n",
      "train loss:0.011985932547423387\n",
      "train loss:0.023132320182029598\n",
      "train loss:0.0023425652727397587\n",
      "train loss:0.021738665590498852\n",
      "train loss:0.08172480979973351\n",
      "train loss:0.01676140229790654\n",
      "train loss:0.002635254264663936\n",
      "train loss:0.010540166071042871\n",
      "train loss:0.0009618045359841981\n",
      "train loss:0.01773868162758593\n",
      "train loss:0.010664236369265017\n",
      "train loss:0.011949816906770501\n",
      "train loss:0.05202565163367737\n",
      "train loss:0.0069195996922302595\n",
      "train loss:0.006380482733723649\n",
      "train loss:0.010832129365438843\n",
      "train loss:0.000733924673245319\n",
      "train loss:0.07032537828784484\n",
      "train loss:0.0010530249724982168\n",
      "train loss:0.009408943414655348\n",
      "train loss:0.010050952793567927\n",
      "train loss:0.011292102972041864\n",
      "train loss:0.03265073377800831\n",
      "train loss:0.018935266319195378\n",
      "train loss:0.012128655609822205\n",
      "train loss:0.05140326435045026\n",
      "train loss:0.004271090117974803\n",
      "train loss:0.0028047468981063223\n",
      "train loss:0.006028827620769947\n",
      "train loss:0.015688953620920976\n",
      "train loss:0.012060084446871679\n",
      "train loss:0.013549649781530866\n",
      "train loss:0.002985269815510805\n",
      "train loss:0.011506348799082865\n",
      "train loss:0.007047325972297188\n",
      "train loss:0.005063271107121511\n",
      "train loss:0.03367884607821382\n",
      "train loss:0.027160095580616786\n",
      "train loss:0.014532418114232835\n",
      "train loss:0.019677152949578017\n",
      "train loss:0.04274683903121158\n",
      "train loss:0.004173317148821391\n",
      "train loss:0.0011926061446320508\n",
      "train loss:0.07784221265278524\n",
      "train loss:0.00819882092886283\n",
      "train loss:0.001404045264368462\n",
      "train loss:0.003874917179457203\n",
      "train loss:0.007476336184921986\n",
      "train loss:0.01645395698689511\n",
      "train loss:0.00856388851219348\n",
      "train loss:0.0070996836642759865\n",
      "train loss:0.007769546921170558\n",
      "train loss:0.005768857650234687\n",
      "train loss:0.001070286636460793\n",
      "train loss:0.01702975914687617\n",
      "train loss:0.06142253664389147\n",
      "train loss:0.012879862584952953\n",
      "train loss:0.0010383243251437149\n",
      "train loss:0.004218475270978061\n",
      "train loss:0.0032724994096933525\n",
      "train loss:0.003980117464879585\n",
      "train loss:0.008323909662491078\n",
      "=== epoch:9, train acc:0.989, test acc:0.989 ===\n",
      "train loss:0.0005720533702304882\n",
      "train loss:0.08253673956432336\n",
      "train loss:0.06913107375515029\n",
      "train loss:0.05001933453889601\n",
      "train loss:0.008730063791544833\n",
      "train loss:0.004952111356821351\n",
      "train loss:0.005829369827157498\n",
      "train loss:0.00809912926102174\n",
      "train loss:0.008477689295765652\n",
      "train loss:0.0007226223734818321\n",
      "train loss:0.008290902096360447\n",
      "train loss:0.003840851915787525\n",
      "train loss:0.00583032140553711\n",
      "train loss:0.015543578345001786\n",
      "train loss:0.01270775578260288\n",
      "train loss:0.0011478463884553726\n",
      "train loss:0.011761782843806237\n",
      "train loss:0.005555826144446861\n",
      "train loss:0.00982450567314468\n",
      "train loss:0.0032538588410160264\n",
      "train loss:0.015481887306424741\n",
      "train loss:0.002712040016784352\n",
      "train loss:0.0321660110937786\n",
      "train loss:0.001885122628801856\n",
      "train loss:0.007727591207833464\n",
      "train loss:0.018245163758294946\n",
      "train loss:0.002591518698385026\n",
      "train loss:0.013193374051461258\n",
      "train loss:0.004714363244722251\n",
      "train loss:0.0009089130874614035\n",
      "train loss:0.0008406869516089331\n",
      "train loss:0.006593619518925914\n",
      "train loss:0.009108919009745826\n",
      "train loss:0.0037427694629401593\n",
      "train loss:0.027438149186430484\n",
      "train loss:0.0070131894664444624\n",
      "train loss:0.024696061133875388\n",
      "train loss:0.024085258277537644\n",
      "train loss:0.004193289697954016\n",
      "train loss:0.024411512845151206\n",
      "train loss:0.014515426217609206\n",
      "train loss:0.017429917459925993\n",
      "train loss:0.02039936883658603\n",
      "train loss:0.00411614460621041\n",
      "train loss:0.005258989045073723\n",
      "train loss:0.015115945661977138\n",
      "train loss:0.003342366715457932\n",
      "train loss:0.0061345036307251235\n",
      "train loss:0.0038820768215704084\n",
      "train loss:0.010331752241410953\n",
      "train loss:0.0026788809105480066\n",
      "train loss:0.040538352312848594\n",
      "train loss:0.03222670597065509\n",
      "train loss:0.004726041852252404\n",
      "train loss:0.011095401148970563\n",
      "train loss:0.011553233208444313\n",
      "train loss:0.0089943747788437\n",
      "train loss:0.0010228517461011166\n",
      "train loss:0.002421348860510814\n",
      "train loss:0.02015224685182563\n",
      "train loss:0.00846436560478515\n",
      "train loss:0.005645947864607113\n",
      "train loss:0.016671245632774747\n",
      "train loss:0.013323635234928778\n",
      "train loss:0.019005280714597464\n",
      "train loss:0.06061406485315464\n",
      "train loss:0.0076903365059939836\n",
      "train loss:0.017775783269533336\n",
      "train loss:0.002241804930912859\n",
      "train loss:0.00344863826168951\n",
      "train loss:0.0035836023197576335\n",
      "train loss:0.0037407037673094297\n",
      "train loss:0.009801922982181289\n",
      "train loss:0.014186927354198638\n",
      "train loss:0.012302060536580233\n",
      "train loss:0.004450775194519992\n",
      "train loss:0.024215322338881354\n",
      "train loss:0.004654654668194231\n",
      "train loss:0.010233257397888355\n",
      "train loss:0.009931432519452664\n",
      "train loss:0.005571810326578064\n",
      "train loss:0.0038323033737871558\n",
      "train loss:0.0019695071955961496\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 27\u001B[39m\n\u001B[32m     19\u001B[39m network = SimpleConvNet(input_dim=(\u001B[32m1\u001B[39m,\u001B[32m28\u001B[39m,\u001B[32m28\u001B[39m),\n\u001B[32m     20\u001B[39m                         conv_param = {\u001B[33m'\u001B[39m\u001B[33mfilter_num\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m30\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mfilter_size\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m5\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mpad\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m0\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mstride\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m1\u001B[39m},\n\u001B[32m     21\u001B[39m                         hidden_size=\u001B[32m100\u001B[39m, output_size=\u001B[32m10\u001B[39m, weight_init_std=\u001B[32m0.01\u001B[39m)\n\u001B[32m     23\u001B[39m trainer = Trainer(network, x_train, t_train, x_test, t_test,\n\u001B[32m     24\u001B[39m                   epochs=max_epochs, mini_batch_size=\u001B[32m100\u001B[39m,\n\u001B[32m     25\u001B[39m                   optimizer=\u001B[33m'\u001B[39m\u001B[33mAdam\u001B[39m\u001B[33m'\u001B[39m, optimizer_param={\u001B[33m'\u001B[39m\u001B[33mlr\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m0.001\u001B[39m},\n\u001B[32m     26\u001B[39m                   evaluate_sample_num_per_epoch=\u001B[32m1000\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[38;5;66;03m# 保存参数\u001B[39;00m\n\u001B[32m     30\u001B[39m network.save_params(\u001B[33m\"\u001B[39m\u001B[33mparams.pkl\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\Pycharm_workspace\\DeepLearningFromScratch\\common\\trainer.py:71\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     69\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtrain\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m     70\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m.max_iter):\n\u001B[32m---> \u001B[39m\u001B[32m71\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     73\u001B[39m     test_acc = \u001B[38;5;28mself\u001B[39m.network.accuracy(\u001B[38;5;28mself\u001B[39m.x_test, \u001B[38;5;28mself\u001B[39m.t_test)\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\Pycharm_workspace\\DeepLearningFromScratch\\common\\trainer.py:47\u001B[39m, in \u001B[36mTrainer.train_step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     44\u001B[39m grads = \u001B[38;5;28mself\u001B[39m.network.gradient(x_batch, t_batch)\n\u001B[32m     45\u001B[39m \u001B[38;5;28mself\u001B[39m.optimizer.update(\u001B[38;5;28mself\u001B[39m.network.params, grads)\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m loss = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[38;5;28mself\u001B[39m.train_loss_list.append(loss)\n\u001B[32m     49\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose: \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mtrain loss:\u001B[39m\u001B[33m\"\u001B[39m + \u001B[38;5;28mstr\u001B[39m(loss))\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\Pycharm_workspace\\DeepLearningFromScratch\\ch07\\simple_convnet.py:71\u001B[39m, in \u001B[36mSimpleConvNet.loss\u001B[39m\u001B[34m(self, x, t)\u001B[39m\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mloss\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, t):\n\u001B[32m     68\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"求损失函数\u001B[39;00m\n\u001B[32m     69\u001B[39m \u001B[33;03m    参数x是输入数据、t是教师标签\u001B[39;00m\n\u001B[32m     70\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m71\u001B[39m     y = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     72\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.last_layer.forward(y, t)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\Pycharm_workspace\\DeepLearningFromScratch\\ch07\\simple_convnet.py:63\u001B[39m, in \u001B[36mSimpleConvNet.predict\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.layers.values():\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m         x = \u001B[43mlayer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     65\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\Pycharm_workspace\\DeepLearningFromScratch\\common\\layers.py:264\u001B[39m, in \u001B[36mPooling.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    261\u001B[39m col = im2col(x, \u001B[38;5;28mself\u001B[39m.pool_h, \u001B[38;5;28mself\u001B[39m.pool_w, \u001B[38;5;28mself\u001B[39m.stride, \u001B[38;5;28mself\u001B[39m.pad)\n\u001B[32m    262\u001B[39m col = col.reshape(-\u001B[32m1\u001B[39m, \u001B[38;5;28mself\u001B[39m.pool_h*\u001B[38;5;28mself\u001B[39m.pool_w)\n\u001B[32m--> \u001B[39m\u001B[32m264\u001B[39m arg_max = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43margmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    265\u001B[39m out = np.max(col, axis=\u001B[32m1\u001B[39m)\n\u001B[32m    266\u001B[39m out = out.reshape(N, out_h, out_w, C).transpose(\u001B[32m0\u001B[39m, \u001B[32m3\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:1229\u001B[39m, in \u001B[36margmax\u001B[39m\u001B[34m(a, axis, out, keepdims)\u001B[39m\n\u001B[32m   1142\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1143\u001B[39m \u001B[33;03mReturns the indices of the maximum values along an axis.\u001B[39;00m\n\u001B[32m   1144\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   1226\u001B[39m \u001B[33;03m(2, 1, 4)\u001B[39;00m\n\u001B[32m   1227\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1228\u001B[39m kwds = {\u001B[33m'\u001B[39m\u001B[33mkeepdims\u001B[39m\u001B[33m'\u001B[39m: keepdims} \u001B[38;5;28;01mif\u001B[39;00m keepdims \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np._NoValue \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[32m-> \u001B[39m\u001B[32m1229\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43margmax\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:59\u001B[39m, in \u001B[36m_wrapfunc\u001B[39m\u001B[34m(obj, method, *args, **kwds)\u001B[39m\n\u001B[32m     56\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, *args, **kwds)\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbound\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m     61\u001B[39m     \u001B[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001B[39;00m\n\u001B[32m     62\u001B[39m     \u001B[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     66\u001B[39m     \u001B[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001B[39;00m\n\u001B[32m     67\u001B[39m     \u001B[38;5;66;03m# exception has a traceback chain.\u001B[39;00m\n\u001B[32m     68\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
